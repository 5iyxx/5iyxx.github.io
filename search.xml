<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[POJO与JavaBean的区别]]></title>
    <url>%2F2017%2F10%2F01%2FPOJO%E4%B8%8EJavaBean%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[POJO往往被称为Data对象，而JavaBean更是一个组件技术。 POJO（Plain Ordinary Java Object）简单的Java对象，实际就是普通JavaBeans，是为了避免和EJB混淆所创造的简称。 使用POJO名称是为了避免和EJB混淆起来, 而且简称比较直接. 其中有一些属性及其getter、setter方法的类,没有业务逻辑，有时可以作为VO(value -object)或dto(Data Transform Object)来使用.当然,如果你有一个简单的运算属性也是可以的,但不允许有业务方法,也不能携带有connection之类的方法。 POJO对象有时也被称为Data对象，大量应用于表现现实中的对象。如果项目中使用了Hibernate框架，有一个关联的xml文件，使对象与数据库中的表对应，对象的属性与表中的字段相对应。 POJO 和JavaBean是我们常见的两个关键字，一般容易混淆，POJO全称是Plain Ordinary Java Object / Pure Old Java Object，中文可以翻译成：普通Java类，具有一部分getter/setter方法的那种类就可以称作POJO，但是JavaBean则比 POJO复杂很多， Java Bean 是可复用的组件，对 Java Bean 并没有严格的规范，理论上讲，任何一个 Java 类都可以是一个 Bean 。但通常情况下，由于 Java Bean 是被容器所创建（如 Tomcat) 的，所以 Java Bean 应具有一个无参的构造器，另外，通常 Java Bean 还要实现 Serializable 接口用于实现 Bean 的持久性。 Java Bean 是不能被跨进程访问的。 JavaBean是一种组件技术，就好像你做了一个扳子，而这个扳子会在很多地方被拿去用，这个扳子也提供多种功能(你可以拿这个扳子扳、锤、撬等等)，而这个扳子就是一个组件。一般在web应用程序中建立一个数据库的映射对象时，我们只能称它为POJO。POJO(Plain Old Java Object)这个名字用来强调它是一个普通java对象，而不是一个特殊的对象，其主要用来指代那些没有遵从特定的Java对象模型、约定或框架（如EJB）的Java对象。理想地讲，一个POJO是一个不受任何限制的Java对象（除了Java语言规范）。 POJO是一个简单的普通的Java对象，它不包含业务逻辑或持久逻辑等，但不是JavaBean、EntityBean等，不具有任何特殊角色和不继承或不实现任何其它Java框架的类或接口。 转载于：http://www.cnblogs.com/Nickzerui/p/4596956.html]]></content>
      <categories>
        <category>The Basic Of Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Red Hat 7 安装后环境配置]]></title>
    <url>%2F2017%2F06%2F22%2FRed%20Hat%207%20%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Red Hat 7 安装后环境配置 配置静态的ip地址 查看系统的使用的网卡ifconfig 我本地网卡为eno16777736 打开配置文件vi /etc/sysconfig/network-scripts/ifcfg-eno16777736 静态ip设置，需要根据自己的网络参数修改配置文件BOOTPROTO=static 指定地址的获取方式IPADDR=192.168.0.225 ip地址NETMASK=255.255.255.0 子网掩码GATEWAY=192.168.0.1 网关 重启服务systemctl restart network ping测试ping 8.8.8.8PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.64 bytes from 8.8.8.8: icmp_seq=1 ttl=45 time=241 ms测试如上结果，成功！]]></content>
      <categories>
        <category>Operations</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Maven中Tomcat热部署]]></title>
    <url>%2F2017%2F05%2F11%2F%E5%9C%A8maven%E4%B8%ADTomcat%E7%83%AD%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[在Maven中Tomcat热部署，下面为一个简单做法流程，一共有三步。第一步：修改tomcat-users.xml配置文件，配置用户、密码和权限。123&lt;role rolename=&quot;manager-gui&quot; /&gt;&lt;role rolename=&quot;manager-script&quot; /&gt;&lt;user username=&quot;tomcat&quot; password=&quot;tomcat&quot; roles=&quot;manager-gui, manager-script&quot;/&gt; 启动tomcat后，可以进入后台,如图1. 图1 后台页面 第二步：修改ip访问权限对于IP访问权限在设置在/tomcat/webapps/manager/META-INF/context.xml中。早期版本Tomcat默认是没有限制的，如图2所示。 图2 早期IP限制默认配置 现在Tomcat对于默认是对IP进行限制的，如果不需要进行限制可以模仿早期Tomcat默认配置，去掉IP限制，默认如图3所示。 图3 现在IP限制默认配置 第三步：在pom文件中配置tomcat插件。12345678910111213&lt;!-- 配置Tomcat插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;8080&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;url&gt;http://119.29.160.64/manager/text&lt;/url&gt; &lt;username&gt;tomcat&lt;/username&gt; &lt;password&gt;tomcat20170928&lt;/password&gt; &lt;/configuration&gt; &lt;/plugin&gt; 第四步：部署初次部署可以使用 “tomcat7:deploy” 命令如果已经部署过使用 “tomcat7:redeploy” 命令（如果第一次部署到根目录，可以直接用“tomcat7:redeploy”）启动过程如图4、图5. 图4 Maven build…图5 运行插件]]></content>
      <categories>
        <category>Operations</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么要使用SocketAddress来管理网络地址]]></title>
    <url>%2F2017%2F05%2F10%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8SocketAddress%E6%9D%A5%E7%AE%A1%E7%90%86%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[在使用Socket来连接服务器时最简单的方式就是直接使用IP和端口，但Socket类中的connect方法并未提供这种方式，而是使用SocketAddress类来向connect方法传递服务器的IP和端口。虽然这种方式从表面上看要麻烦一些，但它会给我们带来另外一个好处，那就是网络地址的重用。 所谓网络地址的重用表现在两个方面： 通过建立一个SocketAddress对象，可以在多次连接同一个服务器时使用这个SocketAddress对象。 在Socket类中提供了两个方法：getRemoteSocketAddress和getLocalSocketAddress，通过这两个方法可以得到服务器和本机的网络地址。而且所得到的网络地址在相应的Socket对象关闭后任然可以使用。下面是这两个方法的声明： 12public SocketAddress getRemoteSocketAddress()public SocketAddress getLocalSocketAddress() 不管在使用Socket类连接服务器时是直接使用IP和端口，还是使用SocketAddress，这两个方法都返回SocketAddress形式的网络地址。当Socket对象未连接时这两个方法返回null，但要注意的是只有在Socket对象未连接时这两个方法才返回null，而当已经连接成功的Socket对象关闭后仍可使用这两个方法得到相应的网络地址。 虽然上面曾多次提到SocketAddress，但SocketAddress只是个抽象类，它除了有一个默认的构造方法外，其它的方法都是abstract的，因此，我们必须使用SocketAddress的子类来建立SocketAddress对象。在JDK1.4中J只为我们提供了IP网络地址的实现类：java.net.InetSocketAddress。这个类是从SocketAddress继承的，我们可以通过如下的方法来建立SocketAddress对象。 1SocketAddress socketAddress = new InetSocketAddress(host, ip); 下面的代码演示了如何通过SocketAddress来共享网络地址： 123456789101112131415161718192021222324252627282930313233343536package mynet;import java.net.*;public class MySocketAddress&#123; public static void main(String[] args) &#123; try &#123; Socket socket1 = new Socket(&quot;www.ptpress.com.cn&quot;, 80); SocketAddress socketAddress = socket1.getRemoteSocketAddress(); socket1.close(); Socket socket2 = new Socket(); // socket2.bind(new InetSocketAddress(&quot;192.168.18.252&quot;, 0)); socket2.connect(socketAddress); socket2.close(); InetSocketAddress inetSocketAddress1 = (InetSocketAddress) socketAddress; System.out.println(&quot;服务器域名:&quot; + inetSocketAddress1.getAddress().getHostName()); System.out.println(&quot;服务器IP:&quot; + inetSocketAddress1.getAddress().getHostAddress()); System.out.println(&quot;服务器端口:&quot; + inetSocketAddress1.getPort()); InetSocketAddress inetSocketAddress2 = (InetSocketAddress) socket2 .getLocalSocketAddress(); System.out.println(&quot;本地IP:&quot; + inetSocketAddress2.getAddress().getLocalHost() .getHostAddress()); System.out.println(&quot;本地端口:&quot; + inetSocketAddress2.getPort()); &#125; catch (Exception e) &#123; System.out.println(e.getMessage()); &#125; &#125;&#125; 输出结果： 服务器域名:www.ptpress.com.cn服务器IP:219.238.168.74服务器端口:80本地IP:192.168.18.253本地端口:4250 如果多次运行后，本地端口的值可能在每次都不一样。这是因为在socket2在连接时并未使用bind来绑定本地的端口，而这个本地端口是由系统在1024至65，535中随机选取的，因此，在每次运行程序时这个本地端口不一定相同。 本文出自 “李宁的极客世界”博客， http://androidguy.blog.51cto.com/974126/214448]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>NIO</tag>
        <tag>Socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaBean总结]]></title>
    <url>%2F2017%2F04%2F01%2FJavaBean%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[符合一定规范编写的Java类，不是一种技术，而是一种规范。大家针对这种规范，总结了很多开发技巧、工具函数。符合这种规范的类，可以被其它的程序员或者框架使用。 javabean 是什么？Bean的中文含义是“豆子”，顾名思义，JavaBean是指一段特殊的Java类，就是有默然构造方法,只有get,set的方法的java类的对象. 专业点解释是： JavaBean定义了一组规则JavaBean就是遵循此规则的平常的Java对象 满足这三个条件:1.实现序列化接口2.提供无参数的构造器3.提供getter 和 setter方法访问它的属性. 简单地说，JavaBean是用Java语言描述的软件组件模型，其实际上是一个类。这些类遵循一个接口格式，以便于使函数命名、底层行为以及继承或实现的行为，可以把类看作标准的JavaBean组件进行构造和应用。JavaBean一般分为可视化组件和非可视化组件两种。可视化组件可以是简单的GUI元素，如按钮或文本框，也可以是复杂的，如报表组件；非可视化组件没有GUI表现形式，用于封装业务逻辑、数据库操作等。其最大的优点在于可以实现代码的可重用性。JavaBean又同时具有以下特性。 易于维护、使用、编写。 可实现代码的重用性。 可移植性强，但仅限于Java工作平台。 便于传输，不限于本地还是网络。 可以以其他部件的模式进行工作。 对于有过其他语言编程经验的读者，可以将其看作类似微软的ActiveX的编程组件。但是区别在于JavaBean是跨平台的，而ActiveX组件则仅局限于Windows系统。总之，JavaBean比较适合于那些需要跨平台的、并具有可视化操作和定制特性的软件组件。 JavaBean组件与EJB（Enterprise JavaBean，企业级JavaBean）组件完全不同。EJB 是J2EE的核心，是一个用来创建分布式应用、服务器端以及基于Java应用的功能强大的组件模型。JavaBean组件主要用于存储状态信息，而EJB组件可以存储业务逻辑。 使用JavaBean的原因程序中往往有重复使用的段落，JavaBean就是为了能够重复使用而设计的程序段落，而且这些段落并不只服务于某一个程序，而且每个JavaBean都具有特定功能，当需要这个功能的时候就可以调用相应的JavaBean。从这个意义上来讲，JavaBean大大简化了程序的设计过程，也方便了其他程序的重复使用。JavaBean传统应用于可视化领域，如AWT（窗口工具集）下的应用。而现在，JavaBean更多地应用于非可视化领域，同时，JavaBean在服务器端的应用也表现出强大的优势。非可视化的JavaBean可以很好地实现业务逻辑、控制逻辑和显示页面的分离，现在多用于后台处理，使得系统具有更好的健壮性和灵活性。JSP + JavaBean和JSP + JavaBean + Servlet成为当前开发Web应用的主流模式。 JavaBean的开发在程序设计的过程中，JavaBean不是独立的。为了能够更好地封装事务逻辑、数据库操作而便于实现业务逻辑和前台程序的分离，操作的过程往往是先开发需要的JavaBean，再在适当的时候进行调用。但一个完整有效的JavaBean必然会包含一个属性，伴随若干个get/set（只读/只写）函数的变量来设计和运行的。JavaBean作为一个特殊的类，具有自己独有的特性。应该注意以下3个方面。 JavaBean类必须有一个没有参数的构造函数。 JavaBean类所有的属性最好定义为私有的。 JavaBean类中定义函数setXxx() 和getXxx()来对属性进行操作。其中Xxx是首字母大写的私有变量名称。 转载于：http://blog.csdn.net/zdwzzu2006/article/details/5151788/]]></content>
      <categories>
        <category>The Basic Of Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring中每个jar包的作用]]></title>
    <url>%2F2017%2F03%2F10%2FSpring%E4%B8%AD%E6%AF%8F%E4%B8%AAjar%E5%8C%85%E7%9A%84%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[一个工程需要很多个关于spring的jar包，下面详细说明每个jar的作用。 spring.jar包含有完整发布模块的单个jar 包。但是不包括mock.jar, aspects.jar, spring-portlet.jar, and spring-hibernate2.jar。 spring-src.zip就是所有的源代码压缩包。 除了spring.jar 文件，Spring 还包括有其它21 个独立的jar 包，各自包含着对应的Spring组件，用户可以根据自己的需要来选择组合自己的jar 包，而不必引入整个spring.jar 的所有类文件。 spring-core.jar这个jar 文件包含Spring 框架基本的核心工具类。Spring 其它组件要都要使用到这个包里的类，是其它组件的基本核心，当然你也可以在自己的应用系统中使用这些工具类。外部依赖Commons Logging， (Log4J)。 spring-beans.jar这个jar 文件是所有应用都要用到的，它包含访问配置文件、创建和管理bean 以及进行Inversion of Control / Dependency Injection（IoC/DI）操作相关的所有类。如果应用只需基本的IoC/DI 支持，引入spring-core.jar 及spring-beans.jar 文件就可以了。外部依赖spring-core，(CGLIB)。 spring-aop.jar这个jar 文件包含在应用中使用Spring 的AOP 特性时所需的类和源码级元数据支持。使用基于AOP 的Spring特性，如声明型事务管理（Declarative Transaction Management），也要在应用里包含这个jar包。外部依赖spring-core， (spring-beans，AOP Alliance， CGLIB，Commons Attributes)。 spring-context.jar这个jar 文件为Spring 核心提供了大量扩展。可以找到使用Spring ApplicationContext特性时所需的全部类，JDNI 所需的全部类，instrumentation组件以及校验Validation 方面的相关类。外部依赖spring-beans, (spring-aop)。 spring-dao.jar这个jar 文件包含Spring DAO、Spring Transaction 进行数据访问的所有类。为了使用声明型事务支持，还需在自己的应用里包含spring-aop.jar。外部依赖spring-core，(spring-aop， spring-context， JTA API)。 spring-jdbc.jar这个jar 文件包含对Spring 对JDBC 数据访问进行封装的所有类。外部依赖spring-beans，spring-dao。 spring-support.jar这个jar 文件包含支持UI模版（Velocity，FreeMarker，JasperReports），邮件服务，脚本服务(JRuby)，缓存Cache（EHCache），任务计划Scheduling（uartz）方面的类。外部依赖spring-context, (spring-jdbc, Velocity, FreeMarker, JasperReports, BSH, Groovy, JRuby, Quartz, EHCache) spring-web.jar这个jar 文件包含Web 应用开发时，用到Spring 框架时所需的核心类，包括自动载入Web Application Context 特性的类、Struts 与JSF 集成类、文件上传的支持类、Filter 类和大量工具辅助类。外部依赖spring-context, Servlet API, (JSP API, JSTL, Commons FileUpload, COS)。 spring-webmvc.jar这个jar 文件包含Spring MVC 框架相关的所有类。包括框架的Servlets，Web MVC框架，控制器和视图支持。当然，如果你的应用使用了独立的MVC 框架，则无需这个JAR 文件里的任何类。外部依赖spring-web, (spring-support，Tiles，iText，POI)。 spring-portlet.jarspring自己实现的一个类似Spring MVC的框架。包括一个MVC框架和控制器。外部依赖spring-web， Portlet API，(spring-webmvc)。 spring-struts.jarStruts框架支持，可以更方便更容易的集成Struts框架。外部依赖spring-web，Struts。 spring-remoting.jar这个jar 文件包含支持EJB、远程调用Remoting（RMI、Hessian、Burlap、Http Invoker、JAX-RPC）方面的类。外部依赖spring-aop， (spring-context，spring-web，Hessian，Burlap，JAX-RPC，EJB API)。 spring-jmx.jar这个jar包提供了对JMX 1.0/1.2的支持类。外部依赖spring-beans，spring-aop， JMX API。 spring-jms.jar这个jar包提供了对JMS 1.0.2/1.1的支持类。外部依赖spring-beans，spring-dao，JMS API。 spring-jca.jar对JCA 1.0的支持。外部依赖spring-beans，spring-dao， JCA API。 spring-jdo.jar对JDO 1.0/2.0的支持。外部依赖spring-jdbc， JDO API， (spring-web)。 spring-jpa.jar对JPA 1.0的支持。外部依赖spring-jdbc， JPA API， (spring-web)。 spring-hibernate2.jar对Hibernate 2.1的支持，已经不建议使用。外部依赖spring-jdbc，Hibernate2，(spring-web)。 spring-hibernate3.jar对Hibernate 3.0/3.1/3.2的支持。外部依赖spring-jdbc，Hibernate3，(spring-web)。 spring-toplink.jar对TopLink框架的支持。外部依赖spring-jdbc，TopLink。 spring-ibatis.jar对iBATIS SQL Maps的支持。外部依赖spring-jdbc，iBATIS SQL Maps。 另外的两个包。 spring-mock.jar这个jar 文件包含Spring 一整套mock 类来辅助应用的测试。Spring 测试套件使用了其中大量mock 类，这样测试就更加简单。模拟HttpServletRequest 和HttpServletResponse 类在Web 应用单元测试是很方便的。并且提供了对JUnit的支持。外部依赖spring-core。 spring-aspects.jar提供对AspectJ的支持，以便可以方便的将面向方面的功能集成进IDE中，比如Eclipse AJDT。外部依赖。 WEAVER JARS (dist/weavers)说明。 spring-agent.jarSpring的InstrumentationSavingAgent (为InstrumentationLoadTimeWeaver)，一个设备代理包，可以参考JDK1.5的Instrumentation功能获得更多信息。外部依赖none (for use at JVM startup: “-javaagent:spring-agent.jar”)。 spring-tomcat-weaver.jar扩展Tomcat的ClassLoader，使其可以使用instrumentation（设备）类。外部依赖none (for deployment into Tomcat’s “server/lib” directory)。]]></content>
      <categories>
        <category>Spring In Action</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven中pom标签详解]]></title>
    <url>%2F2017%2F03%2F08%2FMaven%E4%B8%ADpom%E6%A0%87%E7%AD%BE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[pom作为项目对象模型。通过xml表示maven项目，使用pom.xml来实现。主要描述了项目：包括配置文件；开发者需要遵循的规则，缺陷管理系统，组织和licenses，项目的url，项目的依赖性，以及其他所有的项目相关因素。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;!--父项目的坐标。如果项目中没有规定某个元素的值，那么父项目中的对应值即为项目的默认值。 坐标包括group ID，artifact ID和 version。--&gt; &lt;parent&gt; &lt;!--被继承的父项目的构件标识符--&gt; &lt;artifactId/&gt; &lt;!--被继承的父项目的全球唯一标识符--&gt; &lt;groupId/&gt; &lt;!--被继承的父项目的版本--&gt; &lt;version/&gt; &lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项 目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。--&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;!--声明项目描述符遵循哪一个POM模型版本。模型本身的版本很少改变，虽然如此，但它仍然是必不可少的，这是为了当Maven引入了新的特性或者其他模型变更的时候，确保稳定性。--&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.mycompany.app生成的相对路径为：/com/mycompany/app--&gt; &lt;groupId&gt;asia.banseon&lt;/groupId&gt; &lt;!-- 构件的标识符，它和group ID一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的artifact ID和groupID；在某个 特定的group ID下，artifact ID也必须是唯一的。构件是项目产生的或使用的一个东西，Maven为项目产生的构件包括：JARs，源 码，二进制发布和WARs等。--&gt; &lt;artifactId&gt;banseon-maven2&lt;/artifactId&gt; &lt;!--项目产生的构件类型，例如jar、war、ear、pom。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型--&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;!--项目当前版本，格式为:主版本.次版本.增量版本-限定版本号--&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--项目的名称, Maven产生的文档用--&gt; &lt;name&gt;banseon-maven&lt;/name&gt; &lt;!--项目主页的URL, Maven产生的文档用--&gt; &lt;url&gt;http://www.baidu.com/banseon&lt;/url&gt; &lt;!-- 项目的详细描述, Maven 产生的文档用。 当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标 签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。--&gt; &lt;description&gt;A maven project to study maven.&lt;/description&gt; &lt;!--描述了这个项目构建环境中的前提条件。--&gt; &lt;prerequisites&gt; &lt;!--构建该项目或使用该插件所需要的Maven的最低版本--&gt; &lt;maven/&gt; &lt;/prerequisites&gt; &lt;!--项目的问题管理系统(Bugzilla, Jira, Scarab,或任何你喜欢的问题管理系统)的名称和URL，本例为 jira--&gt; &lt;issueManagement&gt; &lt;!--问题管理系统（例如jira）的名字，--&gt; &lt;system&gt;jira&lt;/system&gt; &lt;!--该项目使用的问题管理系统的URL--&gt; &lt;url&gt;http://jira.baidu.com/banseon&lt;/url&gt; &lt;/issueManagement&gt; &lt;!--项目持续集成信息--&gt; &lt;ciManagement&gt; &lt;!--持续集成系统的名字，例如continuum--&gt; &lt;system/&gt; &lt;!--该项目使用的持续集成系统的URL（如果持续集成系统有web接口的话）。--&gt; &lt;url/&gt; &lt;!--构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告）--&gt; &lt;notifiers&gt; &lt;!--配置一种方式，当构建中断时，以该方式通知用户/开发者--&gt; &lt;notifier&gt; &lt;!--传送通知的途径--&gt; &lt;type/&gt; &lt;!--发生错误时是否通知--&gt; &lt;sendOnError/&gt; &lt;!--构建失败时是否通知--&gt; &lt;sendOnFailure/&gt; &lt;!--构建成功时是否通知--&gt; &lt;sendOnSuccess/&gt; &lt;!--发生警告时是否通知--&gt; &lt;sendOnWarning/&gt; &lt;!--不赞成使用。通知发送到哪里--&gt; &lt;address/&gt; &lt;!--扩展配置项--&gt; &lt;configuration/&gt; &lt;/notifier&gt; &lt;/notifiers&gt; &lt;/ciManagement&gt; &lt;!--项目创建年份，4位数字。当产生版权信息时需要使用这个值。--&gt; &lt;inceptionYear/&gt; &lt;!--项目相关邮件列表信息--&gt; &lt;mailingLists&gt; &lt;!--该元素描述了项目相关的所有邮件列表。自动产生的网站引用这些信息。--&gt; &lt;mailingList&gt; &lt;!--邮件的名称--&gt; &lt;name&gt;Demo&lt;/name&gt; &lt;!--发送邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--&gt; &lt;post&gt;banseon@126.com&lt;/post&gt; &lt;!--订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--&gt; &lt;subscribe&gt;banseon@126.com&lt;/subscribe&gt; &lt;!--取消订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--&gt; &lt;unsubscribe&gt;banseon@126.com&lt;/unsubscribe&gt; &lt;!--你可以浏览邮件信息的URL--&gt; &lt;archive&gt;http:/hi.baidu.com/banseon/demo/dev/&lt;/archive&gt; &lt;/mailingList&gt; &lt;/mailingLists&gt; &lt;!--项目开发者列表--&gt; &lt;developers&gt; &lt;!--某个项目开发者的信息--&gt; &lt;developer&gt; &lt;!--SCM里项目开发者的唯一标识符--&gt; &lt;id&gt;HELLO WORLD&lt;/id&gt; &lt;!--项目开发者的全名--&gt; &lt;name&gt;banseon&lt;/name&gt; &lt;!--项目开发者的email--&gt; &lt;email&gt;banseon@126.com&lt;/email&gt; &lt;!--项目开发者的主页的URL--&gt; &lt;url/&gt; &lt;!--项目开发者在项目中扮演的角色，角色元素描述了各种角色--&gt; &lt;roles&gt; &lt;role&gt;Project Manager&lt;/role&gt; &lt;role&gt;Architect&lt;/role&gt; &lt;/roles&gt; &lt;!--项目开发者所属组织--&gt; &lt;organization&gt;demo&lt;/organization&gt; &lt;!--项目开发者所属组织的URL--&gt; &lt;organizationUrl&gt;http://hi.baidu.com/banseon&lt;/organizationUrl&gt; &lt;!--项目开发者属性，如即时消息如何处理等--&gt; &lt;properties&gt; &lt;dept&gt;No&lt;/dept&gt; &lt;/properties&gt; &lt;!--项目开发者所在时区， -11到12范围内的整数。--&gt; &lt;timezone&gt;-5&lt;/timezone&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;!--项目的其他贡献者列表--&gt; &lt;contributors&gt; &lt;!--项目的其他贡献者。参见developers/developer元素--&gt; &lt;contributor&gt; &lt;name/&gt;&lt;email/&gt;&lt;url/&gt;&lt;organization/&gt;&lt;organizationUrl/&gt;&lt;roles/&gt;&lt;timezone/&gt;&lt;properties/&gt; &lt;/contributor&gt; &lt;/contributors&gt; &lt;!--该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。--&gt; &lt;licenses&gt; &lt;!--描述了项目的license，用于生成项目的web站点的license页面，其他一些报表和validation也会用到该元素。--&gt; &lt;license&gt; &lt;!--license用于法律上的名称--&gt; &lt;name&gt;Apache 2&lt;/name&gt; &lt;!--官方的license正文页面的URL--&gt; &lt;url&gt;http://www.baidu.com/banseon/LICENSE-2.0.txt&lt;/url&gt; &lt;!--项目分发的主要方式： repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖--&gt; &lt;distribution&gt;repo&lt;/distribution&gt; &lt;!--关于license的补充信息--&gt; &lt;comments&gt;A business-friendly OSS license&lt;/comments&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;!--SCM(Source Control Management)标签允许你配置你的代码库，供Maven web站点和其它插件使用。--&gt; &lt;scm&gt; &lt;!--SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。--&gt; &lt;connection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk) &lt;/connection&gt; &lt;!--给开发者使用的，类似connection元素。即该连接不仅仅只读--&gt; &lt;developerConnection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk &lt;/developerConnection&gt; &lt;!--当前代码的标签，在开发阶段默认为HEAD--&gt; &lt;tag/&gt; &lt;!--指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。--&gt; &lt;url&gt;http://svn.baidu.com/banseon&lt;/url&gt; &lt;/scm&gt; &lt;!--描述项目所属组织的各种属性。Maven产生的文档用--&gt; &lt;organization&gt; &lt;!--组织的全名--&gt; &lt;name&gt;demo&lt;/name&gt; &lt;!--组织主页的URL--&gt; &lt;url&gt;http://www.baidu.com/banseon&lt;/url&gt; &lt;/organization&gt; &lt;!--构建项目需要的信息--&gt; &lt;build&gt; &lt;!--该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--&gt; &lt;sourceDirectory/&gt; &lt;!--该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。--&gt; &lt;scriptSourceDirectory/&gt; &lt;!--该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--&gt; &lt;testSourceDirectory/&gt; &lt;!--被编译过的应用程序class文件存放的目录。--&gt; &lt;outputDirectory/&gt; &lt;!--被编译过的测试class文件存放的目录。--&gt; &lt;testOutputDirectory/&gt; &lt;!--使用来自该项目的一系列构建扩展--&gt; &lt;extensions&gt; &lt;!--描述使用到的构建扩展。--&gt; &lt;extension&gt; &lt;!--构建扩展的groupId--&gt; &lt;groupId/&gt; &lt;!--构建扩展的artifactId--&gt; &lt;artifactId/&gt; &lt;!--构建扩展的版本--&gt; &lt;version/&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;!--当项目没有规定目标（Maven2 叫做阶段）时的默认值--&gt; &lt;defaultGoal/&gt; &lt;!--这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。--&gt; &lt;resources&gt; &lt;!--这个元素描述了项目相关或测试相关的所有资源路径--&gt; &lt;resource&gt; &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如$&#123;project.build.outputDirectory&#125;）。举个例 子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven /messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。--&gt; &lt;targetPath/&gt; &lt;!--是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。--&gt; &lt;filtering/&gt; &lt;!--描述存放资源的目录，该路径相对POM路径--&gt; &lt;directory/&gt; &lt;!--包含的模式列表，例如**/*.xml.--&gt; &lt;includes/&gt; &lt;!--排除的模式列表，例如**/*.xml--&gt; &lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!--这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。--&gt; &lt;testResources&gt; &lt;!--这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明--&gt; &lt;testResource&gt; &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;!--构建产生的所有文件存放的目录--&gt; &lt;directory/&gt; &lt;!--产生的构件的文件名，默认值是$&#123;artifactId&#125;-$&#123;version&#125;。--&gt; &lt;finalName/&gt; &lt;!--当filtering开关打开时，使用到的过滤器属性文件列表--&gt; &lt;filters/&gt; &lt;!--子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置--&gt; &lt;pluginManagement&gt; &lt;!--使用的插件列表 。--&gt; &lt;plugins&gt; &lt;!--plugin元素包含描述插件所需要的信息。--&gt; &lt;plugin&gt; &lt;!--插件在仓库里的group ID--&gt; &lt;groupId/&gt; &lt;!--插件在仓库里的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--被使用的插件的版本（或版本范围）--&gt; &lt;version/&gt; &lt;!--是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。--&gt; &lt;extensions/&gt; &lt;!--在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。--&gt; &lt;executions&gt; &lt;!--execution元素包含了插件执行需要的信息--&gt; &lt;execution&gt; &lt;!--执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标--&gt; &lt;id/&gt; &lt;!--绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段--&gt; &lt;phase/&gt; &lt;!--配置的执行目标--&gt; &lt;goals/&gt; &lt;!--配置是否被传播到子POM--&gt; &lt;inherited/&gt; &lt;!--作为DOM对象的配置--&gt; &lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;!--项目引入插件所需要的额外依赖--&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--任何配置是否被传播到子项目--&gt; &lt;inherited/&gt; &lt;!--作为DOM对象的配置--&gt; &lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!--使用的插件列表--&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt; &lt;plugin&gt; &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!--在列的项目构建profile，如果被激活，会修改构建处理--&gt; &lt;profiles&gt; &lt;!--根据环境参数或命令行参数激活某个构建处理--&gt; &lt;profile&gt; &lt;!--构建配置的唯一标识符。即用于命令行激活，也用于在继承时合并具有相同标识符的profile。--&gt; &lt;id/&gt; &lt;!--自动触发profile的条件逻辑。Activation是profile的开启钥匙。profile的力量来自于它 能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。--&gt; &lt;activation&gt; &lt;!--profile默认是否激活的标志--&gt; &lt;activeByDefault/&gt; &lt;!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。--&gt; &lt;jdk/&gt; &lt;!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。--&gt; &lt;os&gt; &lt;!--激活profile的操作系统的名字--&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;!--激活profile的操作系统所属家族(如 &apos;windows&apos;)--&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;!--激活profile的操作系统体系结构 --&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;!--激活profile的操作系统版本--&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;!--如果Maven检测到某一个属性（其值可以在POM中通过$&#123;名称&#125;引用），其拥有对应的名称和值，Profile就会被激活。如果值 字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段--&gt; &lt;property&gt; &lt;!--激活profile的属性的名称--&gt; &lt;name&gt;mavenVersion&lt;/name&gt; &lt;!--激活profile的属性的值--&gt; &lt;value&gt;2.0.3&lt;/value&gt; &lt;/property&gt; &lt;!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活 profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。--&gt; &lt;file&gt; &lt;!--如果指定的文件存在，则激活profile。--&gt; &lt;exists&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/exists&gt; &lt;!--如果指定的文件不存在，则激活profile。--&gt; &lt;missing&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/missing&gt; &lt;/file&gt; &lt;/activation&gt; &lt;!--构建项目所需要的信息。参见build元素--&gt; &lt;build&gt; &lt;defaultGoal/&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;directory/&gt;&lt;finalName/&gt;&lt;filters/&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt; &lt;plugin&gt; &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt; &lt;plugin&gt; &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径--&gt; &lt;modules/&gt; &lt;!--发现依赖和扩展的远程仓库列表。--&gt; &lt;repositories&gt; &lt;!--参见repositories/repository元素--&gt; &lt;repository&gt; &lt;releases&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;id/&gt;&lt;name/&gt;&lt;url/&gt;&lt;layout/&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表--&gt; &lt;pluginRepositories&gt; &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素--&gt; &lt;pluginRepository&gt; &lt;releases&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;id/&gt;&lt;name/&gt;&lt;url/&gt;&lt;layout/&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。--&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--不赞成使用. 现在Maven忽略该元素.--&gt; &lt;reports/&gt; &lt;!--该元素包括使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。参见reporting元素--&gt; &lt;reporting&gt; ...... &lt;/reporting&gt; &lt;!--参见dependencyManagement元素--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--参见distributionManagement元素--&gt; &lt;distributionManagement&gt; ...... &lt;/distributionManagement&gt; &lt;!--参见properties元素--&gt; &lt;properties/&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径--&gt; &lt;modules/&gt; &lt;!--发现依赖和扩展的远程仓库列表。--&gt; &lt;repositories&gt; &lt;!--包含需要连接到远程仓库的信息--&gt; &lt;repository&gt; &lt;!--如何处理远程仓库里发布版本的下载--&gt; &lt;releases&gt; &lt;!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --&gt; &lt;enabled/&gt; &lt;!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。--&gt; &lt;updatePolicy/&gt; &lt;!--当Maven验证构件校验文件失败时该怎么做：ignore（忽略），fail（失败），或者warn（警告）。--&gt; &lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;!-- 如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的 策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --&gt; &lt;snapshots&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;!--远程仓库唯一标识符。可以用来匹配在settings.xml文件里配置的远程仓库--&gt; &lt;id&gt;banseon-repository-proxy&lt;/id&gt; &lt;!--远程仓库名称--&gt; &lt;name&gt;banseon-repository-proxy&lt;/name&gt; &lt;!--远程仓库URL，按protocol://hostname/path形式--&gt; &lt;url&gt;http://192.168.1.169:9999/repository/&lt;/url&gt; &lt;!-- 用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然 而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。--&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表--&gt; &lt;pluginRepositories&gt; &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素--&gt; &lt;pluginRepository&gt; ...... &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!--依赖的group ID--&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;!--依赖的artifact ID--&gt; &lt;artifactId&gt;maven-artifact&lt;/artifactId&gt; &lt;!--依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。--&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应， 尽管这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true，就可以在 plugin里定义新的类型。所以前面的类型的例子不完整。--&gt; &lt;type&gt;jar&lt;/type&gt; &lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成 JAR，一个使用Java 1.4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。--&gt; &lt;classifier&gt;&lt;/classifier&gt; &lt;!--依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。 - compile ：默认范围，用于编译 - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath - runtime: 在执行时需要使用 - test: 用于test任务时使用 - system: 需要外在提供相应的元素。通过systemPath来取得 - systemPath: 仅用于范围为system。提供相应的路径 - optional: 当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用--&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;!--仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例如$&#123;java.home&#125;。--&gt; &lt;systemPath&gt;&lt;/systemPath&gt; &lt;!--当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;!--可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。--&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--不赞成使用. 现在Maven忽略该元素.--&gt; &lt;reports&gt;&lt;/reports&gt; &lt;!--该元素描述使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。--&gt; &lt;reporting&gt; &lt;!--true，则，网站不包括默认的报表。这包括“项目信息”菜单中的报表。--&gt; &lt;excludeDefaults/&gt; &lt;!--所有产生的报表存放到哪里。默认值是$&#123;project.build.directory&#125;/site。--&gt; &lt;outputDirectory/&gt; &lt;!--使用的报表插件和他们的配置。--&gt; &lt;plugins&gt; &lt;!--plugin元素包含描述报表插件需要的信息--&gt; &lt;plugin&gt; &lt;!--报表插件在仓库里的group ID--&gt; &lt;groupId/&gt; &lt;!--报表插件在仓库里的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--被使用的报表插件的版本（或版本范围）--&gt; &lt;version/&gt; &lt;!--任何配置是否被传播到子项目--&gt; &lt;inherited/&gt; &lt;!--报表插件的配置--&gt; &lt;configuration/&gt; &lt;!--一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标--&gt; &lt;reportSets&gt; &lt;!--表示报表的一个集合，以及产生该集合的配置--&gt; &lt;reportSet&gt; &lt;!--报表集合的唯一标识符，POM继承时用到--&gt; &lt;id/&gt; &lt;!--产生报表集合时，被使用的报表的配置--&gt; &lt;configuration/&gt; &lt;!--配置是否被继承到子POMs--&gt; &lt;inherited/&gt; &lt;!--这个集合里使用到哪些报表--&gt; &lt;reports/&gt; &lt;/reportSet&gt; &lt;/reportSets&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt; &lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和 artifact ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID 匹配到这里的依赖，并使用这里的依赖信息。--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。--&gt; &lt;distributionManagement&gt; &lt;!--部署项目产生的构件到远程仓库需要的信息--&gt; &lt;repository&gt; &lt;!--是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素--&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;banseon maven2&lt;/name&gt; &lt;url&gt;file://$&#123;basedir&#125;/target/deploy&lt;/url&gt; &lt;layout/&gt; &lt;/repository&gt; &lt;!--构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素--&gt; &lt;snapshotRepository&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;Banseon-maven2 Snapshot Repository&lt;/name&gt; &lt;url&gt;scp://svn.baidu.com/banseon:/usr/local/maven-snapshot&lt;/url&gt; &lt;layout/&gt; &lt;/snapshotRepository&gt; &lt;!--部署项目的网站需要的信息--&gt; &lt;site&gt; &lt;!--部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置--&gt; &lt;id&gt;banseon-site&lt;/id&gt; &lt;!--部署位置的名称--&gt; &lt;name&gt;business api website&lt;/name&gt; &lt;!--部署位置的URL，按protocol://hostname/path形式--&gt; &lt;url&gt; scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web &lt;/url&gt; &lt;/site&gt; &lt;!--项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。--&gt; &lt;downloadUrl/&gt; &lt;!--如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。--&gt; &lt;relocation&gt; &lt;!--构件新的group ID--&gt; &lt;groupId/&gt; &lt;!--构件新的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--构件新的版本号--&gt; &lt;version/&gt; &lt;!--显示给用户的，关于移动的额外信息，例如原因。--&gt; &lt;message/&gt; &lt;/relocation&gt; &lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从 Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部 署），verified（被核实时正确的和最终的）。--&gt; &lt;status/&gt; &lt;/distributionManagement&gt; &lt;!--以值替代名称，Properties可以在整个POM中使用，也可以作为触发条件（见settings.xml配置文件里activation元素的说明）。格式是&lt;name&gt;value&lt;/name&gt;。--&gt; &lt;properties/&gt; &lt;/project&gt;]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jar包添加到maven本地仓库]]></title>
    <url>%2F2017%2F03%2F07%2FJar%E5%8C%85%E6%B7%BB%E5%8A%A0%E5%88%B0maven%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[maven在应用的过程中，有 maven在应用的过程中，有些jar包在仓库上面是没法找到的，这需要我们自己手动导入到仓库中，些jar包在仓库上面是没法找到的，这需要我们自己手动导入到仓库中。 例子zxing-3.21.jar是根据github上面项目ZXing Project自己生成的jar包，该包主要应用于二维码生成，下面讲述怎么把怎么把zxing-3.21.jar添加到本地的maven仓库中。 环境要求需要配置JDK和maven环境，完成后以管理员身份打开命令提示符窗口(cmd),再输入下面相关的语法。 语法1234567891011121314151617181920212223mvn install:install-file -Dfile=jar包的位置(参数一) -DgroupId=groupId(参数二) -DartifactId=artifactId(参数三) -Dversion=version(参数四) -Dpackaging=jareg:mvn install:install-file -Dfile=&quot;C:\Users\eric\Desktop\zxing\3.21\zxing-3.21.jar&quot; -DgroupId=com.eric -DartifactId=zxing -Dversion=3.21 -Dpackaging=jarresult：[INFO] Scanning for projects...[INFO][INFO] ------------------------------------------------------------------------[INFO] Building Maven Stub Project (No POM) 1[INFO] ------------------------------------------------------------------------[INFO][INFO] --- maven-install-plugin:2.4:install-file (default-cli) @ standalone-pom ---[INFO] Installing C:\Users\eric\Desktop\zxing\3.21\zxing-3.21.jar to C:\Users\eric\.m2\repository\com\eric\zxing\3.21\zxing-3.21.jar[INFO] Installing C:\Users\eric\AppData\Local\Temp\mvninstall6543969167446403883.pom to C:\Users\eric\.m2\repository\com\eric\zxing\3.21\zxing-3.21.pom[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 0.836 s[INFO] Finished at: 2017-03-08T00:24:12+08:00[INFO] Final Memory: 7M/117M[INFO] ------------------------------------------------------------------------(添加成功！) 注意：地址+jar包名,即C:\Users\eric\Desktop\zxing\3.21\zxing-3.21.jar要加引号””,”参数二\参数三\参数四”这也是jar包在仓库中的地址。 查看生成的依赖查看添加的zxing-3.21.jar的dependency 通过设置的对应参数获取.即 1-DgroupId=groupId(参数二) -DartifactId=artifactId(参数三) -Dversion=version(参数四) 参看本地仓库中pom文件C:\Users\eric.m2\repository\com\eric\zxing\3.21\zxing-3.21.pom，可以看到: 123&lt;groupId&gt;com.eric&lt;/groupId&gt;&lt;artifactId&gt;zxing&lt;/artifactId&gt;&lt;version&gt;3.21&lt;/version&gt;]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据类型--SortedSet（有序集合）]]></title>
    <url>%2F2017%2F03%2F06%2FRedis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B--SortedSet%EF%BC%88%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88%EF%BC%89%2F</url>
    <content type="text"><![CDATA[有序集合和散列一样，都用于存储键值对：有序集合的键被称为成员（member），每个成员都是各不相同；而有序集合的值则被称为分值（score），分值必须为浮点数。有序集合是Redis里面唯一一个既可以根据成员访问元素（这一点和散列一样），又可以根据分值以及分值的排列顺序来访问元素的结构。字符串成员（member）与浮点数分值（score）之间的有序映射，元素的排列顺序由分值的大小决定。结构的读写： 添加、获取、删除单个元素 根据分值范围（range）或者成员来获取元素 ZADDZADD key score member [[score member] [score member] …]  将一个或多个 member 元素及其 score 值加入到有序集 key 当中。 如果某个 member 已经是有序集的成员，那么更新这个 member 的 score 值，并通过重新插入这个 member 元素，来保证该 member 在正确的位置上。 score 值可以是整数值或双精度浮点数。 如果 key 不存在，则创建一个空的有序集并执行 ZADD 操作。 当 key 存在但不是有序集类型时，返回一个错误。 在 Redis 2.4 版本以前， ZADD 每次只能添加一个元素。 可用版本版本&gt;= 1.2.0 时间复杂度O(M*log(N))， N 是有序集的基数， M 为成功添加的新成员的数量。 返回值被成功添加的新成员的数量，不包括那些被更新的、已经存在的成员。 示例123456789101112131415161718192021222324252627282930313233# 添加单个元素redis&gt; ZADD page_rank 10 google.com(integer) 1# 添加多个元素redis&gt; ZADD page_rank 9 baidu.com 8 bing.com(integer) 2redis&gt; ZRANGE page_rank 0 -1 WITHSCORES1) &quot;bing.com&quot;2) &quot;8&quot;3) &quot;baidu.com&quot;4) &quot;9&quot;5) &quot;google.com&quot;6) &quot;10&quot;# 添加已存在元素，且 score 值不变redis&gt; ZADD page_rank 10 google.com(integer) 0redis&gt; ZRANGE page_rank 0 -1 WITHSCORES # 没有改变1) &quot;bing.com&quot;2) &quot;8&quot;3) &quot;baidu.com&quot;4) &quot;9&quot;5) &quot;google.com&quot;6) &quot;10&quot;# 添加已存在元素，但是改变 score 值redis&gt; ZADD page_rank 6 bing.com(integer) 0redis&gt; ZRANGE page_rank 0 -1 WITHSCORES # bing.com 元素的 score 值被改变1) &quot;bing.com&quot;2) &quot;6&quot;3) &quot;baidu.com&quot;4) &quot;9&quot;5) &quot;google.com&quot;6) &quot;10&quot; ZCARDZCARD key  返回有序集 key 的基数。 可用版本版本&gt;= 1.2.0 时间复杂度O(1) 返回值当 key 存在且是有序集类型时，返回有序集的基数。当 key 不存在时，返回 0 。 示例123456789101112redis &gt; ZADD salary 2000 tom # 添加一个成员(integer) 1redis &gt; ZCARD salary(integer) 1redis &gt; ZADD salary 5000 jack # 再添加一个成员(integer) 1redis &gt; ZCARD salary(integer) 2redis &gt; EXISTS non_exists_key # 对不存在的 key 进行 ZCARD 操作(integer) 0redis &gt; ZCARD non_exists_key(integer) 0 ZCOUNTZCOUNT key min max  返回有序集 key 中， score 值在 min 和 max 之间(默认包括 score 值等于 min 或 max )的成员的数量。 可用版本版本&gt;= 2.0.0 时间复杂度O(log(N)+M)， N 为有序集的基数， M 为值在 min 和 max 之间的元素的数量。 返回值score 值在 min 和 max 之间的成员的数量。 示例1234567891011redis&gt; ZRANGE salary 0 -1 WITHSCORES # 测试数据1) &quot;jack&quot;2) &quot;2000&quot;3) &quot;peter&quot;4) &quot;3500&quot;5) &quot;tom&quot;6) &quot;5000&quot;redis&gt; ZCOUNT salary 2000 5000 # 计算薪水在 2000-5000 之间的人数(integer) 3redis&gt; ZCOUNT salary 3000 5000 # 计算薪水在 3000-5000 之间的人数(integer) 2 ZINCRBYZINCRBY key increment member  为有序集 key 的成员 member 的 score 值加上增量 increment 。 可以通过传递一个负数值 increment ，让 score 减去相应的值，比如 ZINCRBY key -5 member ，就是让 member 的 score 值减去 5 。 当 key 不存在，或 member 不是 key 的成员时， ZINCRBY key increment member 等同于 ZADD key increment member 。 当 key 不是有序集类型时，返回一个错误。 score 值可以是整数值或双精度浮点数。 可用版本版本&gt;= 1.2.0 时间复杂度O(log(N)) 返回值member 成员的新 score 值，以字符串形式表示。 示例1234redis&gt; ZSCORE salary tom&quot;2000&quot;redis&gt; ZINCRBY salary 2000 tom # tom 加薪啦！&quot;4000&quot; ZRANGEZRANGE key start stop [WITHSCORES]  返回有序集 key 中，指定区间内的成员。 其中成员的位置按 score 值递增(从小到大)来排序。 具有相同 score 值的成员按字典序(lexicographical order )来排列。 如果你需要成员按 score 值递减(从大到小)来排列，请使用 ZREVRANGE 命令。 下标参数 start 和 stop 都以 0 为底，也就是说，以 0 表示有序集第一个成员，以 1 表示有序集第二个成员，以此类推。你也可以使用负数下标，以 -1 表示最后一个成员， -2 表示倒数第二个成员，以此类推。 超出范围的下标并不会引起错误。 比如说，当 start 的值比有序集的最大下标还要大，或是 start &gt; stop 时， ZRANGE 命令只是简单地返回一个空列表。 另一方面，假如 stop 参数的值比有序集的最大下标还要大，那么 Redis 将 stop 当作最大下标来处理。  可以通过使用 WITHSCORES 选项，来让成员和它的 score 值一并返回，返回列表以 value1,score1, …, valueN,scoreN 的格式表示。 客户端库可能会返回一些更复杂的数据类型，比如数组、元组等。 可用版本版本&gt;= 1.2.0 时间复杂度O(log(N)+M)， N 为有序集的基数，而 M 为结果集的基数。 返回值指定区间内，带有 score 值(可选)的有序集成员的列表。 示例123456789101112131415161718192021redis &gt; ZRANGE salary 0 -1 WITHSCORES # 显示整个有序集成员1) &quot;jack&quot;2) &quot;3500&quot;3) &quot;tom&quot;4) &quot;5000&quot;5) &quot;boss&quot;6) &quot;10086&quot;redis &gt; ZRANGE salary 1 2 WITHSCORES # 显示有序集下标区间 1 至 2 的成员1) &quot;tom&quot;2) &quot;5000&quot;3) &quot;boss&quot;4) &quot;10086&quot;redis &gt; ZRANGE salary 0 200000 WITHSCORES # 测试 end 下标超出最大下标时的情况1) &quot;jack&quot;2) &quot;3500&quot;3) &quot;tom&quot;4) &quot;5000&quot;5) &quot;boss&quot;6) &quot;10086&quot;redis &gt; ZRANGE salary 200000 3000000 WITHSCORES # 测试当给定区间不存在于有序集时的情况(empty list or set) ZRANGEBYSCOREZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]  返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。 具有相同 score 值的成员按字典序(lexicographical order)来排列(该属性是有序集提供的，不需要额外的计算)。 可选的 LIMIT 参数指定返回结果的数量及区间(就像SQL中的 SELECT LIMIT offset, count )，注意当 offset 很大时，定位 offset 的操作可能需要遍历整个有序集，此过程最坏复杂度为 O(N) 时间。 可选的 WITHSCORES 参数决定结果集是单单返回有序集的成员，还是将有序集成员及其 score 值一起返回。 该选项自 Redis 2.0 版本起可用。 区间及无限  min 和 max 可以是 -inf 和 +inf ，这样一来，你就可以在不知道有序集的最低和最高 score 值的情况下，使用 ZRANGEBYSCORE 这类命令。 默认情况下，区间的取值使用闭区间 (小于等于或大于等于)，你也可以通过给参数前增加 ( 符号来使用可选的开区间 (小于或大于)。 举个例子  ZRANGEBYSCORE zset (1 5 返回所有符合条件 1 &lt; score &lt;= 5 的成员，而 ZRANGEBYSCORE zset (5 (10 则返回所有符合条件 5 &lt; score &lt; 10 的成员。 可用版本版本&gt;= 1.0.5 时间复杂度O(log(N)+M)， N 为有序集的基数， M 为被结果集的基数。 返回值指定区间内，带有 score 值(可选)的有序集成员的列表。 示例123456789101112131415161718192021222324redis&gt; ZADD salary 2500 jack # 测试数据(integer) 0redis&gt; ZADD salary 5000 tom(integer) 0redis&gt; ZADD salary 12000 peter(integer) 0redis&gt; ZRANGEBYSCORE salary -inf +inf # 显示整个有序集1) &quot;jack&quot;2) &quot;tom&quot;3) &quot;peter&quot;redis&gt; ZRANGEBYSCORE salary -inf +inf WITHSCORES # 显示整个有序集及成员的 score 值1) &quot;jack&quot;2) &quot;2500&quot;3) &quot;tom&quot;4) &quot;5000&quot;5) &quot;peter&quot;6) &quot;12000&quot;redis&gt; ZRANGEBYSCORE salary -inf 5000 WITHSCORES # 显示工资 &lt;=5000 的所有成员1) &quot;jack&quot;2) &quot;2500&quot;3) &quot;tom&quot;4) &quot;5000&quot;redis&gt; ZRANGEBYSCORE salary (5000 400000 # 显示工资大于 5000 小于等于 400000 的成员1) &quot;peter&quot; ZRANKZRANK key member  返回有序集 key 中成员 member 的排名。其中有序集成员按 score 值递增(从小到大)顺序排列。 排名以 0 为底，也就是说， score 值最小的成员排名为 0 。 使用 ZREVRANK 命令可以获得成员按 score 值递减(从大到小)排列的排名。 可用版本版本&gt;= 2.0.0 时间复杂度O(log(N)) 返回值如果 member 是有序集 key 的成员，返回 member 的排名。如果 member 不是有序集 key 的成员，返回 nil 。 示例123456789redis&gt; ZRANGE salary 0 -1 WITHSCORES # 显示所有成员及其 score 值1) &quot;peter&quot;2) &quot;3500&quot;3) &quot;tom&quot;4) &quot;4000&quot;5) &quot;jack&quot;6) &quot;5000&quot;redis&gt; ZRANK salary tom # 显示 tom 的薪水排名，第二(integer) 1 ZREMZREM key member [member …]  移除有序集 key 中的一个或多个成员，不存在的成员将被忽略。 当 key 存在但不是有序集类型时，返回一个错误。 在 Redis 2.4 版本以前， ZREM 每次只能删除一个元素。 可用版本 = 1.2.0 时间复杂度O(M*log(N))， N 为有序集的基数， M 为被成功移除的成员的数量。 返回值被成功移除的成员的数量，不包括被忽略的成员。 示例123456789101112131415161718192021222324# 测试数据redis&gt; ZRANGE page_rank 0 -1 WITHSCORES1) &quot;bing.com&quot;2) &quot;8&quot;3) &quot;baidu.com&quot;4) &quot;9&quot;5) &quot;google.com&quot;6) &quot;10&quot;# 移除单个元素redis&gt; ZREM page_rank google.com(integer) 1redis&gt; ZRANGE page_rank 0 -1 WITHSCORES1) &quot;bing.com&quot;2) &quot;8&quot;3) &quot;baidu.com&quot;4) &quot;9&quot;# 移除多个元素redis&gt; ZREM page_rank baidu.com bing.com(integer) 2redis&gt; ZRANGE page_rank 0 -1 WITHSCORES(empty list or set)# 移除不存在元素redis&gt; ZREM page_rank non-exists-element(integer) 0 ZREMRANGEBYRANKZREMRANGEBYRANK key start stop  移除有序集 key 中，指定排名(rank)区间内的所有成员。 区间分别以下标参数 start 和 stop 指出，包含 start 和 stop 在内。 下标参数 start 和 stop 都以 0 为底，也就是说，以 0 表示有序集第一个成员，以 1 表示有序集第二个成员，以此类推。 你也可以使用负数下标，以 -1 表示最后一个成员， -2 表示倒数第二个成员，以此类推。 可用版本版本&gt;= 2.0.0 时间复杂度O(log(N)+M)， N 为有序集的基数，而 M 为被移除成员的数量。 返回值被移除成员的数量。 示例1234567891011redis&gt; ZADD salary 2000 jack(integer) 1redis&gt; ZADD salary 5000 tom(integer) 1redis&gt; ZADD salary 3500 peter(integer) 1redis&gt; ZREMRANGEBYRANK salary 0 1 # 移除下标 0 至 1 区间内的成员(integer) 2redis&gt; ZRANGE salary 0 -1 WITHSCORES # 有序集只剩下一个成员1) &quot;tom&quot;2) &quot;5000&quot; ZREMRANGEBYSCOREZREMRANGEBYSCORE key min max  移除有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。 自版本2.1.6开始， score 值等于 min 或 max 的成员也可以不包括在内，详情请参见 ZRANGEBYSCORE 命令。 可用版本版本&gt;= 1.2.0 时间复杂度O(log(N)+M)， N 为有序集的基数，而 M 为被移除成员的数量。 返回值被移除成员的数量。 示例123456789101112redis&gt; ZRANGE salary 0 -1 WITHSCORES # 显示有序集内所有成员及其 score 值1) &quot;tom&quot;2) &quot;2000&quot;3) &quot;peter&quot;4) &quot;3500&quot;5) &quot;jack&quot;6) &quot;5000&quot;redis&gt; ZREMRANGEBYSCORE salary 1500 3500 # 移除所有薪水在 1500 到 3500 内的员工(integer) 2redis&gt; ZRANGE salary 0 -1 WITHSCORES # 剩下的有序集成员1) &quot;jack&quot;2) &quot;5000&quot; ZREVRANGEZREVRANGE key start stop [WITHSCORES]  返回有序集 key 中，指定区间内的成员。 其中成员的位置按 score 值递减(从大到小)来排列。 具有相同 score 值的成员按字典序的逆序(reverse lexicographical order)排列。 除了成员按 score 值递减的次序排列这一点外， ZREVRANGE 命令的其他方面和 ZRANGE 命令一样。 可用版本版本&gt;= 1.2.0 时间复杂度O(log(N)+M)， N 为有序集的基数，而 M 为结果集的基数。 返回值指定区间内，带有 score 值(可选)的有序集成员的列表。 示例1234567891011121314redis&gt; ZRANGE salary 0 -1 WITHSCORES # 递增排列1) &quot;peter&quot;2) &quot;3500&quot;3) &quot;tom&quot;4) &quot;4000&quot;5) &quot;jack&quot;6) &quot;5000&quot;redis&gt; ZREVRANGE salary 0 -1 WITHSCORES # 递减排列1) &quot;jack&quot;2) &quot;5000&quot;3) &quot;tom&quot;4) &quot;4000&quot;5) &quot;peter&quot;6) &quot;3500&quot; ZREVRANGEBYSCOREZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count]  返回有序集 key 中， score 值介于 max 和 min 之间(默认包括等于 max 或 min )的所有的成员。有序集成员按 score 值递减(从大到小)的次序排列。 具有相同 score 值的成员按字典序的逆序(reverse lexicographical order )排列。 除了成员按 score 值递减的次序排列这一点外， ZREVRANGEBYSCORE 命令的其他方面和 ZRANGEBYSCORE 命令一样。 可用版本版本&gt;= 2.2.0 时间复杂度O(log(N)+M)， N 为有序集的基数， M 为结果集的基数。 返回值指定区间内，带有 score 值(可选)的有序集成员的列表。 示例1234567891011121314151617redis &gt; ZADD salary 10086 jack(integer) 1redis &gt; ZADD salary 5000 tom(integer) 1redis &gt; ZADD salary 7500 peter(integer) 1redis &gt; ZADD salary 3500 joe(integer) 1redis &gt; ZREVRANGEBYSCORE salary +inf -inf # 逆序排列所有成员1) &quot;jack&quot;2) &quot;peter&quot;3) &quot;tom&quot;4) &quot;joe&quot;redis &gt; ZREVRANGEBYSCORE salary 10000 2000 # 逆序排列薪水介于 10000 和 2000 之间的成员1) &quot;peter&quot;2) &quot;tom&quot;3) &quot;joe&quot; ZREVRANKZREVRANK key member  返回有序集 key 中成员 member 的排名。其中有序集成员按 score 值递减(从大到小)排序。 排名以 0 为底，也就是说， score 值最大的成员排名为 0 。 使用 ZRANK 命令可以获得成员按 score 值递增(从小到大)排列的排名。 可用版本版本&gt;= 2.0.0 时间复杂度O(log(N)) 返回值如果 member 是有序集 key 的成员，返回 member 的排名。如果 member 不是有序集 key 的成员，返回 nil 。 示例1234567891011redis 127.0.0.1:6379&gt; ZRANGE salary 0 -1 WITHSCORES # 测试数据1) &quot;jack&quot;2) &quot;2000&quot;3) &quot;peter&quot;4) &quot;3500&quot;5) &quot;tom&quot;6) &quot;5000&quot;redis&gt; ZREVRANK salary peter # peter 的工资排第二(integer) 1redis&gt; ZREVRANK salary tom # tom 的工资最高(integer) 0 ZSCOREZSCORE key member  返回有序集 key 中，成员 member 的 score 值。 如果 member 元素不是有序集 key 的成员，或 key 不存在，返回 nil 。 可用版本版本&gt;= 1.2.0 时间复杂度O(1) 返回值member 成员的 score 值，以字符串形式表示。 示例123456789redis&gt; ZRANGE salary 0 -1 WITHSCORES # 测试数据1) &quot;tom&quot;2) &quot;2000&quot;3) &quot;peter&quot;4) &quot;3500&quot;5) &quot;jack&quot;6) &quot;5000&quot;redis&gt; ZSCORE salary peter # 注意返回值是字符串&quot;3500&quot; ZUNIONSTOREZUNIONSTORE destination numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX]  计算给定的一个或多个有序集的并集，其中给定 key 的数量必须以 numkeys 参数指定，并将该并集(结果集)储存到 destination 。 默认情况下，结果集中某个成员的 score 值是所有给定集下该成员 score 值之 和 。 WEIGHTS  使用 WEIGHTS 选项，你可以为 每个 给定有序集 分别 指定一个乘法因子(multiplication factor)，每个给定有序集的所有成员的 score 值在传递给聚合函数(aggregation function)之前都要先乘以该有序集的因子。 如果没有指定 WEIGHTS 选项，乘法因子默认设置为 1 。 AGGREGATE  使用 AGGREGATE 选项，你可以指定并集的结果集的聚合方式。 默认使用的参数 SUM ，可以将所有集合中某个成员的 score 值之 和 作为结果集中该成员的 score 值；使用参数 MIN ，可以将所有集合中某个成员的 最小 score 值作为结果集中该成员的 score 值；而参数 MAX 则是将所有集合中某个成员的 最大 score 值作为结果集中该成员的 score 值。 可用版本版本&gt;= 2.0.0 时间复杂度O(N)+O(M log(M))， N 为给定有序集基数的总和， M 为结果集的基数。 返回值保存到 destination 的结果集的基数。 示例1234567891011121314151617181920212223242526272829redis&gt; ZRANGE programmer 0 -1 WITHSCORES1) &quot;peter&quot;2) &quot;2000&quot;3) &quot;jack&quot;4) &quot;3500&quot;5) &quot;tom&quot;6) &quot;5000&quot;redis&gt; ZRANGE manager 0 -1 WITHSCORES1) &quot;herry&quot;2) &quot;2000&quot;3) &quot;mary&quot;4) &quot;3500&quot;5) &quot;bob&quot;6) &quot;4000&quot;redis&gt; ZUNIONSTORE salary 2 programmer manager WEIGHTS 1 3 # 公司决定加薪。。。除了程序员。。。(integer) 6redis&gt; ZRANGE salary 0 -1 WITHSCORES1) &quot;peter&quot;2) &quot;2000&quot;3) &quot;jack&quot;4) &quot;3500&quot;5) &quot;tom&quot;6) &quot;5000&quot;7) &quot;herry&quot;8) &quot;6000&quot;9) &quot;mary&quot;10) &quot;10500&quot;11) &quot;bob&quot;12) &quot;12000&quot; ZINTERSTOREZINTERSTORE destination numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX]  计算给定的一个或多个有序集的交集，其中给定 key 的数量必须以 numkeys 参数指定，并将该交集(结果集)储存到 destination 。 默认情况下，结果集中某个成员的 score 值是所有给定集下该成员 score 值之和. 关于 WEIGHTS 和 AGGREGATE 选项的描述，参见 ZUNIONSTORE 命令。 可用版本版本&gt;= 2.0.0 时间复杂度O(NK)+O(Mlog(M))， N 为给定 key 中基数最小的有序集， K 为给定有序集的数量， M 为结果集的基数。 返回值保存到 destination 的结果集的基数。 示例123456789101112131415161718192021redis &gt; ZADD mid_test 70 &quot;Li Lei&quot;(integer) 1redis &gt; ZADD mid_test 70 &quot;Han Meimei&quot;(integer) 1redis &gt; ZADD mid_test 99.5 &quot;Tom&quot;(integer) 1redis &gt; ZADD fin_test 88 &quot;Li Lei&quot;(integer) 1redis &gt; ZADD fin_test 75 &quot;Han Meimei&quot;(integer) 1redis &gt; ZADD fin_test 99.5 &quot;Tom&quot;(integer) 1redis &gt; ZINTERSTORE sum_point 2 mid_test fin_test(integer) 3redis &gt; ZRANGE sum_point 0 -1 WITHSCORES # 显示有序集内所有成员及其 score 值1) &quot;Han Meimei&quot;2) &quot;145&quot;3) &quot;Li Lei&quot;4) &quot;158&quot;5) &quot;Tom&quot;6) &quot;199&quot; ZSCANZSCAN key cursor [MATCH pattern] [COUNT count]  详细信息请参考 SCAN 命令。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据类型--Set（集合）]]></title>
    <url>%2F2017%2F03%2F06%2FRedis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B--Set%EF%BC%88%E9%9B%86%E5%90%88%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Redis的集合和列表都可以存储多个字符串，它们之间的不同在于，列表可以存储多个不同的字符串，而集合则通过使用散列来保证自己存储的每个字符串都是各不相同的。包含字符串的无序收集器（unordered collection）,并且被包含的每个字符串都是独一无二、各不相同的。结构的读写： 添加、读取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合中随机获取元素 SADDSADD key member [member …] 将一个或多个 member 元素加入到集合 key 当中，已经存在于集合的 member 元素将被忽略。 假如 key 不存在，则创建一个只包含 member 元素作成员的集合。 当 key 不是集合类型时，返回一个错误。 在Redis2.4版本以前， SADD 只接受单个 member 值。 可用版本版本&gt;= 1.0.0 时间复杂度O(N)， N 是被添加的元素的数量。 返回值被添加到集合中的新元素的数量，不包括被忽略的元素。 示例12345678910111213# 添加单个元素redis&gt; SADD bbs &quot;discuz.net&quot;(integer) 1# 添加重复元素redis&gt; SADD bbs &quot;discuz.net&quot;(integer) 0# 添加多个元素redis&gt; SADD bbs &quot;tianya.cn&quot; &quot;groups.google.com&quot;(integer) 2redis&gt; SMEMBERS bbs1) &quot;discuz.net&quot;2) &quot;groups.google.com&quot;3) &quot;tianya.cn&quot; SCARDSCARD key 返回集合 key 的基数(集合中元素的数量)。 可用版本版本&gt;= 1.0.0 时间复杂度O(1) 返回值集合的基数。当 key 不存在时，返回 0 。 示例12345678redis&gt; SADD tool pc printer phone(integer) 3redis&gt; SCARD tool # 非空集合(integer) 3redis&gt; DEL tool(iredis&gt; SCARD tool # 空集合(integer) 0 SDIFFSDIFF key [key …] 返回一个集合的全部成员，该集合是所有给定集合之间的差集。 不存在的 key 被视为空集。 可用版本版本&gt;= 1.0.0 时间复杂度O(N)， N 是所有给定集合的成员数量之和。 返回值交集成员的列表。 示例1234567891011redis&gt; SMEMBERS peter&apos;s_movies1) &quot;bet man&quot;2) &quot;start war&quot;3) &quot;2012&quot;redis&gt; SMEMBERS joe&apos;s_movies1) &quot;hi, lady&quot;2) &quot;Fast Five&quot;3) &quot;2012&quot;redis&gt; SDIFF peter&apos;s_movies joe&apos;s_movies1) &quot;bet man&quot;2) &quot;start war&quot; SDIFFSTORESDIFFSTORE destination key [key …] 这个命令的作用和 SDIFF 类似，但它将结果保存到 destination 集合，而不是简单地返回结果集。 如果 destination 集合已经存在，则将其覆盖。 destination 可以是 key 本身。 可用版本版本&gt;= 1.0.0 时间复杂度O(N)， N 是所有给定集合的成员数量之和。 返回值结果集中的元素数量。 示例12345678910111213redis&gt; SMEMBERS joe&apos;s_movies1) &quot;hi, lady&quot;2) &quot;Fast Five&quot;3) &quot;2012&quot;redis&gt; SMEMBERS peter&apos;s_movies1) &quot;bet man&quot;2) &quot;start war&quot;3) &quot;2012&quot;redis&gt; SDIFFSTORE joe_diff_peter joe&apos;s_movies peter&apos;s_movies(integer) 2redis&gt; SMEMBERS joe_diff_peter1) &quot;hi, lady&quot;2) &quot;Fast Five&quot; SINTERSINTER key [key …] 返回一个集合的全部成员，该集合是所有给定集合的交集。 不存在的 key 被视为空集。 当给定集合当中有一个空集时，结果也为空集(根据集合运算定律)。 可用版本版本&gt;= 1.0.0 时间复杂度O(N * M)， N 为给定集合当中基数最小的集合， M 为给定集合的个数。 返回值交集成员的列表。 示例123456789redis&gt; SMEMBERS group_11) &quot;LI LEI&quot;2) &quot;TOM&quot;3) &quot;JACK&quot;redis&gt; SMEMBERS group_21) &quot;HAN MEIMEI&quot;2) &quot;JACK&quot;redis&gt; SINTER group_1 group_21) &quot;JACK&quot; SINTERSTORESINTERSTORE destination key [key …]  这个命令类似于 SINTER 命令，但它将结果保存到 destination 集合，而不是简单地返回结果集。 如果 destination 集合已经存在，则将其覆盖。 destination 可以是 key 本身。 可用版本版本&gt;= 1.0.0 时间复杂度O(N * M)， N 为给定集合当中基数最小的集合， M 为给定集合的个数。 返回值结果集中的成员数量。 示例12345678910redis&gt; SMEMBERS songs1) &quot;good bye joe&quot;2) &quot;hello,peter&quot;redis&gt; SMEMBERS my_songs1) &quot;good bye joe&quot;2) &quot;falling&quot;redis&gt; SINTERSTORE song_interset songs my_songs(integer) 1redis&gt; SMEMBERS song_interset1) &quot;good bye joe&quot; SISMEMBERSISMEMBER key member 判断 member 元素是否集合 key 的成员。 可用版本版本&gt;= 1.0.0 时间复杂度O(1) 返回值如果 member 元素是集合的成员，返回 1 。如果 member 元素不是集合的成员，或 key 不存在，返回 0 。 示例12345678redis&gt; SMEMBERS joe&apos;s_movies1) &quot;hi, lady&quot;2) &quot;Fast Five&quot;3) &quot;2012&quot;redis&gt; SISMEMBER joe&apos;s_movies &quot;bet man&quot;(integer) 0redis&gt; SISMEMBER joe&apos;s_movies &quot;Fast Five&quot;(integer) 1 SMEMBERSSMEMBERS key 返回集合 key 中的所有成员。 不存在的 key 被视为空集合。 可用版本版本&gt;= 1.0.0 时间复杂度O(N)， N 为集合的基数。 返回值集合中的所有成员。 示例123456789101112# key 不存在或集合为空redis&gt; EXISTS not_exists_key(integer) 0redis&gt; SMEMBERS not_exists_key(empty list or set)# 非空集合redis&gt; SADD language Ruby Python Clojure(integer) 3redis&gt; SMEMBERS language1) &quot;Python&quot;2) &quot;Ruby&quot;3) &quot;Clojure&quot; SMOVESMOVE source destination member 将 member 元素从 source 集合移动到 destination 集合。 SMOVE 是原子性操作。 如果 source 集合不存在或不包含指定的 member 元素，则 SMOVE 命令不执行任何操作，仅返回 0 。否则， member 元素从 source 集合中被移除，并添加到 destination 集合中去。 当 destination 集合已经包含 member 元素时， SMOVE 命令只是简单地将 source 集合中的 member 元素删除。 当 source 或 destination 不是集合类型时，返回一个错误。 可用版本版本&gt;= 1.0.0 时间复杂度O(1) 返回值如果 member 元素被成功移除，返回 1 。如果 member 元素不是 source 集合的成员，并且没有任何操作对 destination 集合执行，那么返回 0 。 示例1234567891011redis&gt; SMEMBERS songs1) &quot;Billie Jean&quot;2) &quot;Believe Me&quot;redis&gt; SMEMBERS my_songs(empty list or set)redis&gt; SMOVE songs my_songs &quot;Believe Me&quot;(integer) 1redis&gt; SMEMBERS songs1) &quot;Billie Jean&quot;redis&gt; SMEMBERS my_songs1) &quot;Believe Me&quot; SPOPSPOP key 移除并返回集合中的一个随机元素。 如果只想获取一个随机元素，但不想该元素从集合中被移除的话，可以使用 SRANDMEMBER 命令。 可用版本版本&gt;= 1.0.0 时间复杂度O(1) 返回值被移除的随机元素。当 key 不存在或 key 是空集时，返回 nil 。 示例12345678910111213redis&gt; SMEMBERS db1) &quot;MySQL&quot;2) &quot;MongoDB&quot;3) &quot;Redis&quot;redis&gt; SPOP db&quot;Redis&quot;redis&gt; SMEMBERS db1) &quot;MySQL&quot;2) &quot;MongoDB&quot;redis&gt; SPOP db&quot;MySQL&quot;redis&gt; SMEMBERS db1) &quot;MongoDB&quot; SRANDMEMBERSRANDMEMBER key [count]  如果命令执行时，只提供了 key 参数，那么返回集合中的一个随机元素。  从 Redis 2.6 版本开始， SRANDMEMBER 命令接受可选的 count 参数： 如果 count 为正数，且小于集合基数，那么命令返回一个包含 count 个元素的数组，数组中的元素各不相同。如果 count大于等于集合基数，那么返回整个集合。 如果 count 为负数，那么命令返回一个数组，数组中的元素可能会重复出现多次，而数组的长度为 count 的绝对值。  该操作和 SPOP 相似，但 SPOP 将随机元素从集合中移除并返回，而 SRANDMEMBER 则仅仅返回随机元素，而不对集合进行任何改动。 可用版本版本&gt;= 1.0.0 时间复杂度只提供 key 参数时为 O(1) 。如果提供了 count 参数，那么为 O(N) ，N 为返回数组的元素个数。 返回值只提供 key 参数时，返回一个元素；如果集合为空，返回 nil 。如果提供了 count 参数，那么返回一个数组；如果集合为空，返回空数组。 示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 添加元素redis&gt; SADD fruit apple banana cherry(integer) 3# 只给定 key 参数，返回一个随机元素redis&gt; SRANDMEMBER fruit&quot;cherry&quot;redis&gt; SRANDMEMBER fruit&quot;apple&quot;# 给定 3 为 count 参数，返回 3 个随机元素# 每个随机元素都不相同redis&gt; SRANDMEMBER fruit 31) &quot;apple&quot;2) &quot;banana&quot;3) &quot;cherry&quot;# 给定 -3 为 count 参数，返回 3 个随机元素# 元素可能会重复出现多次redis&gt; SRANDMEMBER fruit -31) &quot;banana&quot;2) &quot;cherry&quot;3) &quot;apple&quot;redis&gt; SRANDMEMBER fruit -31) &quot;apple&quot;2) &quot;apple&quot;3) &quot;cherry&quot;# 如果 count 是整数，且大于等于集合基数，那么返回整个集合redis&gt; SRANDMEMBER fruit 101) &quot;apple&quot;2) &quot;banana&quot;3) &quot;cherry&quot;# 如果 count 是负数，且 count 的绝对值大于集合的基数# 那么返回的数组的长度为 count 的绝对值redis&gt; SRANDMEMBER fruit -101) &quot;banana&quot;2) &quot;apple&quot;3) &quot;banana&quot;4) &quot;cherry&quot;5) &quot;apple&quot;6) &quot;apple&quot;7) &quot;cherry&quot;8) &quot;apple&quot;9) &quot;apple&quot;10) &quot;banana&quot;# SRANDMEMBER 并不会修改集合内容redis&gt; SMEMBERS fruit1) &quot;apple&quot;2) &quot;cherry&quot;3) &quot;banana&quot;# 集合为空时返回 nil 或者空数组redis&gt; SRANDMEMBER not-exists(nil)redis&gt; SRANDMEMBER not-eixsts 10(empty list or set) SREMSREM key member [member …] 移除集合 key 中的一个或多个 member 元素，不存在的 member 元素会被忽略。 当 key 不是集合类型，返回一个错误。 在 Redis 2.4 版本以前， SREM 只接受单个 member 值。 可用版本版本&gt;= 1.0.0 时间复杂度O(N)， N 为给定 member 元素的数量。 返回值被成功移除的元素的数量，不包括被忽略的元素。 示例1234567891011121314151617# 测试数据redis&gt; SMEMBERS languages1) &quot;c&quot;2) &quot;lisp&quot;3) &quot;python&quot;4) &quot;ruby&quot;# 移除单个元素redis&gt; SREM languages ruby(integer) 1# 移除不存在元素redis&gt; SREM languages non-exists-language(integer) 0# 移除多个元素redis&gt; SREM languages lisp python c(integer) 3redis&gt; SMEMBERS languages(empty list or set) SUNIONSUNION key [key …] 返回一个集合的全部成员，该集合是所有给定集合的并集。 不存在的 key 被视为空集。 可用版本版本&gt;= 1.0.0 时间复杂度O(N)， N 是所有给定集合的成员数量之和。 返回值并集成员的列表。 示例1234567redis&gt; SMEMBERS songs1) &quot;Billie Jean&quot;redis&gt; SMEMBERS my_songs1) &quot;Believe Me&quot;redis&gt; SUNION songs my_songs1) &quot;Billie Jean&quot;2) &quot;Believe Me&quot; SUNIONSTORESUNIONSTORE destination key [key …] 这个命令类似于 SUNION 命令，但它将结果保存到 destination 集合，而不是简单地返回结果集。 如果 destination 已经存在，则将其覆盖。 destination 可以是 key 本身。 可用版本版本&gt;= 1.0.0 时间复杂度O(N)， N 是所有给定集合的成员数量之和。 返回值结果集中的元素数量。 示例12345678910111213redis&gt; SMEMBERS NoSQL1) &quot;MongoDB&quot;2) &quot;Redis&quot;redis&gt; SMEMBERS SQL1) &quot;sqlite&quot;2) &quot;MySQL&quot;redis&gt; SUNIONSTORE db NoSQL SQL(integer) 4redis&gt; SMEMBERS db1) &quot;MySQL&quot;2) &quot;sqlite&quot;3) &quot;MongoDB&quot;4) &quot;Redis&quot; SSCANSSCAN key cursor [MATCH pattern] [COUNT count] 详细信息请参考 SCAN 命令。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据类型--String（字符串）]]></title>
    <url>%2F2017%2F03%2F06%2FRedis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B--String%EF%BC%88%E5%AD%97%E7%AC%A6%E4%B8%B2%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Redis的字符串和其他编程语言或者其他键值存储提供的字符串非常相似。一个key对应一个value。string类型是二进制安全的，可以包含任何数据，比如jpg图片或者序列化的对象。从内部实现来看其实string可以看作byte数组，最大上限1G字节。另外string类型可以被部分命令按int处理，比如incr等命令。文档目前描述的内容以 Redis 2.8 版本为准。 SETSET key value [EX seconds] [PX milliseconds] [NX|XX] 将字符串值 value 关联到 key 。 如果 key 已经持有其他值， SET 就覆写旧值，无视类型。 对于某个原本带有生存时间（TTL）的键来说， 当 SET 命令成功在这个键上执行时， 这个键原有的 TTL 将被清除。 可选参数 EX second ：设置键的过期时间为 second 秒。 SET key value EX second 效果等同于 SETEX key second value 。 PX millisecond ：设置键的过期时间为 millisecond 毫秒。 SET key value PX millisecond 效果等同于 PSETEX key millisecond value 。 NX ：只在键不存在时，才对键进行设置操作。 SET key value NX 效果等同于 SETNX key value 。 XX ：只在键已经存在时，才对键进行设置操作。 返回值 SET 在设置操作成功完成时，才返回 OK 。如果设置了 NX 或者 XX ，但因为条件没达到而造成设置操作未执行，那么命令返回空批量回复（NULL Bulk Reply）。 示例123456127.0.0.1:6379&gt; SET key &quot;value&quot;OK127.0.0.1:6379&gt; SET key &quot;value1&quot; EX 10086 XXOK127.0.0.1:6379&gt; SET key &quot;value1&quot; PX 10086 NX(nil) SETBITSETBIT key offset value 对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。 位的设置或清除取决于 value 参数，可以是 0 也可以是 1 。 当 key 不存在时，自动生成一个新的字符串值。 字符串会进行伸展(grown)以确保它可以将 value 保存在指定的偏移量上。当字符串值进行伸展时，空白位置以 0 填充。 offset 参数必须大于或等于 0 ，小于 2^32 (bit 映射被限制在 512 MB 之内)。 返回值指定偏移量原来储存的位。 示例123456127.0.0.1:6379&gt; SETBIT bit 50 1(integer) 0127.0.0.1:6379&gt; GETBIT bit 50(integer) 1127.0.0.1:6379&gt; GETBIT bit 40(integer) 0 SETEXSETEX key seconds value 将值 value 关联到 key ，并将 key 的生存时间设为 seconds (以秒为单位)。 如果 key 已经存在， SETEX 命令将覆写旧值。 返回值设置成功时返回 OK 。当 seconds 参数不合法时，返回一个错误。 示例123456127.0.0.1:6379&gt; SETEX key 50 &quot;value&quot;OK127.0.0.1:6379&gt; GET key&quot;value&quot;127.0.0.1:6379&gt; TTL key(integer) 29 SETNXSETNX key value 将 key 的值设为 value ，当且仅当 key 不存在。 若给定的 key 已经存在，则 SETNX 不做任何动作。 SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。 返回值设置成功，返回 1 。设置失败，返回 0 。 示例1234127.0.0.1:6379&gt; SETNX key &quot;value&quot;(integer) 1127.0.0.1:6379&gt; SETNX key &quot;value1&quot;(integer) 0 SETRANGESETRANGE key offset value 用 value 参数覆写(overwrite)给定 key 所储存的字符串值，从偏移量 offset 开始。 不存在的 key 当作空白字符串处理。 SETRANGE 命令会确保字符串足够长以便将 value 设置在指定的偏移量上，如果给定 key 原来储存的字符串长度比偏移量小(比如字符串只有 5 个字符长，但你设置的 offset 是 10 )，那么原字符和偏移量之间的空白将用零字节(zerobytes, “\x00” )来填充。 注意你能使用的最大偏移量是 2^29-1(536870911) ，因为 Redis 字符串的大小被限制在 512 兆(megabytes)以内。如果你需要使用比这更大的空间，你可以使用多个 key 。 注意：当生成一个很长的字符串时，Redis 需要分配内存空间，该操作有时候可能会造成服务器阻塞(block)。在2010年的Macbook Pro上，设置偏移量为 536870911(512MB 内存分配)，耗费约 300 毫秒， 设置偏移量为 134217728(128MB 内存分配)，耗费约 80 毫秒，设置偏移量 33554432(32MB 内存分配)，耗费约 30 毫秒，设置偏移量为 8388608(8MB 内存分配)，耗费约 8 毫秒。 注意若首次内存分配成功之后，再对同一个 key 调用 SETRANGE 操作，无须再重新内存。 返回值被 SETRANGE 修改之后，字符串的长度。 示例1234567127.0.0.1:6379&gt; EXISTS empty_key(integer) 0127.0.0.1:6379&gt; SETRANGE empty_key 5 &quot;Redis!&quot;(integer) 11127.0.0.1:6379&gt; GET empty_key&quot;\x00\x00\x00\x00\x00Redis!&quot;127.0.0.1:6379&gt; GETGET key 返回 key 所关联的字符串值。 如果 key 不存在那么返回特殊值 nil 。 假如 key 储存的值不是字符串类型，返回一个错误，因为 GET 只能用于处理字符串值。 返回值当 key 不存在时，返回 nil ，否则，返回 key 的值。如果 key 不是字符串类型，那么返回一个错误。 示例1234127.0.0.1:6379&gt; SET key &quot;value&quot;OK127.0.0.1:6379&gt; GET key&quot;value&quot; GETBITGETBIT key offset 对 key 所储存的字符串值，获取指定偏移量上的位(bit)。 当 offset 比字符串值的长度大，或者 key 不存在时，返回 0 。 返回值字符串值指定偏移量上的位(bit)。对不存在的 key 或者不存在的 offset 进行 GETBIT， 返回 0。 示例12345678127.0.0.1:6379&gt; EXISTS bits(integer) 0127.0.0.1:6379&gt; GETBIT bits 100(integer) 0127.0.0.1:6379&gt; SETBIT bits 101 1(integer) 0127.0.0.1:6379&gt; GETBIT bits 101(integer) 1 GETRANGEGETRANGE key start end 返回 key 中字符串值的子字符串，字符串的截取范围由 start 和 end 两个偏移量决定(包括 start 和 end 在内)。 负数偏移量表示从字符串最后开始计数， -1 表示最后一个字符， -2 表示倒数第二个，以此类推。 GETRANGE 通过保证子字符串的值域(range)不超过实际字符串的值域来处理超出范围的值域请求。 返回值截取得出的子字符串。 示例123456789101112127.0.0.1:6379&gt; SET greeting &quot;hello, my friend&quot;OK127.0.0.1:6379&gt; GETRANGE greeting 0 4 # 返回索引0-4的字符，包括4。&quot;hello&quot;127.0.0.1:6379&gt; GETRANGE greeting -1 -5 # 不支持回绕操作&quot;&quot;127.0.0.1:6379&gt; GETRANGE greeting -3 -1 # 负数索引&quot;end&quot;127.0.0.1:6379&gt; GETRANGE greeting 0 -1 # 从第一个到最后一个&quot;hello, my friend&quot;127.0.0.1:6379&gt; GETRANGE greeting 0 1008611 # 值域超出部分被符略&quot;hello, my friend&quot; GETSETGETSET key value 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。 当 key 存在但不是字符串类型时，返回一个错误。 可用版本 版本&gt;= 1.0.0 时间复杂度O(1) 返回值 返回给定 key 的旧值。 当 key 没有旧值时，也即是， key 不存在时，返回 nil 。 示例12345678redis&gt; GETSET db mongodb # 没有旧值，返回 nil(nil)redis&gt; GET db&quot;mongodb&quot;redis&gt; GETSET db redis # 返回旧值 mongodb&quot;mongodb&quot;redis&gt; GET db&quot;redis&quot; APPENDAPPEND key value 如果 key 已经存在并且是一个字符串， APPEND 命令将 value 追加到 key 原来的值的末尾。 如果 key 不存在， APPEND 就简单地将给定 key 设为 value ，就像执行 SET key value 一样。 可用版本 = 2.0.0 时间复杂度平摊O(1) 返回值追加 value 之后， key 中字符串的长度。 示例12345678910# 对不存在的 key 执行 APPENDredis&gt; EXISTS myphone # 确保 myphone 不存在(integer) 0redis&gt; APPEND myphone &quot;nokia&quot; # 对不存在的 key 进行 APPEND ，等同于 SET myphone &quot;nokia&quot;(integer) 5 # 字符长度# 对已存在的字符串进行 APPENDredis&gt; APPEND myphone &quot; - 1110&quot; # 长度从 5 个字符增加到 12 个字符(integer) 12redis&gt; GET myphone&quot;nokia - 1110&quot; BITCOUNTBITCOUNT key [start] [end] 计算给定字符串中，被设置为 1 的比特位的数量。 一般情况下，给定的整个字符串都会被进行计数，通过指定额外的 start 或 end 参数，可以让计数只在特定的位上进行。 start 和 end 参数的设置和 GETRANGE 命令类似，都可以使用负数值：比如 -1 表示最后一个位，而 -2 表示倒数第二个位，以此类推。 不存在的 key 被当成是空字符串来处理，因此对一个不存在的 key 进行 BITCOUNT 操作，结果为 0 。 可用版本版本&gt;= 2.6.0 时间复杂度O(N) 返回值被设置为 1 的位的数量。 示例12345678910redis&gt; BITCOUNT bits(integer) 0redis&gt; SETBIT bits 0 1 # 0001(integer) 0redis&gt; BITCOUNT bits(integer) 1redis&gt; SETBIT bits 3 1 # 1001(integer) 0redis&gt; BITCOUNT bits(integer) 2 BITOPBITOP operation destkey key [key …] 对一个或多个保存二进制位的字符串 key 进行位元操作，并将结果保存到 destkey 上。 operation 可以是 AND 、 OR 、 NOT 、 XOR 这四种操作中的任意一种： BITOP AND destkey key [key …] ，对一个或多个 key 求逻辑并，并将结果保存到 destkey 。 BITOP OR destkey key [key …] ，对一个或多个 key 求逻辑或，并将结果保存到 destkey 。 BITOP XOR destkey key [key …] ，对一个或多个 key 求逻辑异或，并将结果保存到 destkey 。 BITOP NOT destkey key ，对给定 key 求逻辑非，并将结果保存到 destkey 。  除了 NOT 操作之外，其他操作都可以接受一个或多个 key 作为输入。 处理不同长度的字符串当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 0 。空的 key 也被看作是包含 0 的字符串序列。 可用版本版本&gt;= 2.6.0 时间复杂度O(N) 返回值保存到 destkey 的字符串的长度，和输入 key 中最长的字符串长度相等。 注意： BITOP 的复杂度为 O(N) ，当处理大型矩阵(matrix)或者进行大数据量的统计时，最好将任务指派到附属节点(slave)进行，避免阻塞主节点。 示例1234567891011121314151617181920redis&gt; SETBIT bits-1 0 1 # bits-1 = 1001(integer) 0redis&gt; SETBIT bits-1 3 1(integer) 0redis&gt; SETBIT bits-2 0 1 # bits-2 = 1011(integer) 0redis&gt; SETBIT bits-2 1 1(integer) 0redis&gt; SETBIT bits-2 3 1(integer) 0redis&gt; BITOP AND and-result bits-1 bits-2(integer) 1redis&gt; GETBIT and-result 0 # and-result = 1001(integer) 1redis&gt; GETBIT and-result 1(integer) 0redis&gt; GETBIT and-result 2(integer) 0redis&gt; GETBIT and-result 3(integer) 1 DECRDECR key 将 key 中储存的数字值减一。 如果 key 不存在，那么 key 的值会先被初始化为 0 ，然后再执行 DECR 操作。 如果值包含错误的类型，或字符串类型的值不能表示为数字，那么返回一个错误。 本操作的值限制在 64 位(bit)有符号数字表示之内。 可用版本版本&gt;= 1.0.0 时间复杂度O(1) 返回值执行 DECR 命令之后 key 的值。 示例123456789101112131415# 对存在的数字值 key 进行 DECRredis&gt; SET failure_times 10OKredis&gt; DECR failure_times(integer) 9# 对不存在的 key 值进行 DECRredis&gt; EXISTS count(integer) 0redis&gt; DECR count(integer) -1# 对存在但不是数值的 key 进行 DECRredis&gt; SET company YOUR_CODE_SUCKS.LLCOKredis&gt; DECR company(error) ERR value is not an integer or out of range DECRBYDECRBY key decrement 将 key 所储存的值减去减量 decrement 。 如果 key 不存在，那么 key 的值会先被初始化为 0 ，然后再执行 DECRBY 操作。 如果值包含错误的类型，或字符串类型的值不能表示为数字，那么返回一个错误。 本操作的值限制在 64 位(bit)有符号数字表示之内。 可用版本版本&gt;= 1.0.0 时间复杂度O(1) 返回值减去 decrement 之后， key 的值。 示例12345678910# 对已存在的 key 进行 DECRBYredis&gt; SET count 100OKredis&gt; DECRBY count 20(integer) 80# 对不存在的 key 进行DECRBYredis&gt; EXISTS pages(integer) 0redis&gt; DECRBY pages 10(integer) -10 INCRINCR key 将 key 中储存的数字值增一。 如果 key 不存在，那么 key 的值会先被初始化为 0 ，然后再执行 INCR 操作。 如果值包含错误的类型，或字符串类型的值不能表示为数字，那么返回一个错误。 本操作的值限制在 64 位(bit)有符号数字表示之内。 注意：这是一个针对字符串的操作，因为 Redis 没有专用的整数类型，所以 key 内储存的字符串被解释为十进制 64 位有符号整数来执行 INCR 操作。 可用版本版本&gt;= 1.0.0 时间复杂度O(1) 返回值执行 INCR 命令之后 key 的值。 示例123456redis&gt; SET page_view 20OKredis&gt; INCR page_view(integer) 21redis&gt; GET page_view # 数字值在 Redis 中以字符串的形式保存&quot;21&quot; INCRBYINCRBY key increment 将 key 所储存的值加上增量 increment 。 如果 key 不存在，那么 key 的值会先被初始化为 0 ，然后再执行 INCRBY 命令。 如果值包含错误的类型，或字符串类型的值不能表示为数字，那么返回一个错误。 本操作的值限制在 64 位(bit)有符号数字表示之内。 可用版本版本&gt;= 1.0.0 时间复杂度O(1) 返回值加上 increment 之后， key 的值。 示例12345678910111213141516171819# key 存在且是数字值redis&gt; SET rank 50OKredis&gt; INCRBY rank 20(integer) 70redis&gt; GET rank&quot;70&quot;# key 不存在时redis&gt; EXISTS counter(integer) 0redis&gt; INCRBY counter 30(integer) 30redis&gt; GET counter&quot;30&quot;# key 不是数字值时redis&gt; SET book &quot;long long ago...&quot;OKredis&gt; INCRBY book 200(error) ERR value is not an integer or out of range INCRBYFLOATINCRBYFLOAT key increment 为 key 中所储存的值加上浮点数增量 increment 。 如果 key 不存在，那么 INCRBYFLOAT 会先将 key 的值设为 0 ，再执行加法操作。 如果命令执行成功，那么 key 的值会被更新为（执行加法之后的）新值，并且新值会以字符串的形式返回给调用者。 无论是 key 的值，还是增量 increment ，都可以使用像 2.0e7 、 3e5 、 90e-2 那样的指数符号(exponential notation)来表示，但是，执行 INCRBYFLOAT 命令之后的值总是以同样的形式储存，也即是，它们总是由一个数字，一个（可选的）小数点和一个任意位的小数部分组成（比如 3.14 、 69.768 ，诸如此类)，小数部分尾随的 0 会被移除，如果有需要的话，还会将浮点数改为整数（比如 3.0 会被保存成 3 ）。 除此之外，无论加法计算所得的浮点数的实际精度有多长， INCRBYFLOAT 的计算结果也最多只能表示小数点的后十七位。 当以下任意一个条件发生时，返回一个错误： key 的值不是字符串类型(因为 Redis 中的数字和浮点数都以字符串的形式保存，所以它们都属于字符串类型） key 当前的值或者给定的增量 increment 不能解释(parse)为双精度浮点数(double precision floating point number） 可用版本版本&gt;= 2.6.0 时间复杂度O(1) 返回值执行命令之后 key 的值。 示例1234567891011121314151617181920212223242526# 值和增量都不是指数符号redis&gt; SET mykey 10.50OKredis&gt; INCRBYFLOAT mykey 0.1&quot;10.6&quot;# 值和增量都是指数符号redis&gt; SET mykey 314e-2OKredis&gt; GET mykey # 用 SET 设置的值可以是指数符号&quot;314e-2&quot;redis&gt; INCRBYFLOAT mykey 0 # 但执行 INCRBYFLOAT 之后格式会被改成非指数符号&quot;3.14&quot;# 可以对整数类型执行redis&gt; SET mykey 3OKredis&gt; INCRBYFLOAT mykey 1.1&quot;4.1&quot;# 后跟的 0 会被移除redis&gt; SET mykey 3.0OKredis&gt; GET mykey # SET 设置的值小数部分可以是 0&quot;3.0&quot;redis&gt; INCRBYFLOAT mykey 1.000000000000000000000 # 但 INCRBYFLOAT 会将无用的 0 忽略掉，有需要的话，将浮点变为整数&quot;4&quot;redis&gt; GET mykey&quot;4&quot; MGETMGET key [key …] 返回所有(一个或多个)给定 key 的值。 如果给定的 key 里面，有某个 key 不存在，那么这个 key 返回特殊值 nil 。因此，该命令永不失败。 可用版本版本&gt;= 1.0.0 时间复杂度O(N) , N 为给定 key 的数量。 返回值一个包含所有给定 key 的值的列表。 示例1234567891011redis&gt; SET redis redis.comOKredis&gt; SET mongodb mongodb.orgOKredis&gt; MGET redis mongodb1) &quot;redis.com&quot;2) &quot;mongodb.org&quot;redis&gt; MGET redis mongodb mysql # 不存在的 mysql 返回 nil1) &quot;redis.com&quot;2) &quot;mongodb.org&quot;3) (nil) MSETMSET key value [key value …] 同时设置一个或多个 key-value 对。 如果某个给定 key 已经存在，那么 MSET 会用新值覆盖原来的旧值，如果这不是你所希望的效果，请考虑使用 MSETNX 命令：它只会在所有给定 key 都不存在的情况下进行设置操作。 MSET 是一个原子性(atomic)操作，所有给定 key 都会在同一时间内被设置，某些给定 key 被更新而另一些给定 key 没有改变的情况，不可能发生。 可用版本版本&gt;= 1.0.1 时间复杂度O(N)， N 为要设置的 key 数量。 返回值总是返回 OK (因为 MSET 不可能失败) 示例12345678910111213redis&gt; MSET date &quot;2012.3.30&quot; time &quot;11:00 a.m.&quot; weather &quot;sunny&quot;OKredis&gt; MGET date time weather1) &quot;2012.3.30&quot;2) &quot;11:00 a.m.&quot;3) &quot;sunny&quot;# MSET 覆盖旧值例子redis&gt; SET google &quot;google.hk&quot;OKredis&gt; MSET google &quot;google.com&quot;OKredis&gt; GET google&quot;google.com&quot; MSETNXMSETNX key value [key value …] 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。 即使只有一个给定 key 已存在， MSETNX 也会拒绝执行所有给定 key 的设置操作。 MSETNX 是原子性的，因此它可以用作设置多个不同 key 表示不同字段(field)的唯一性逻辑对象(unique logic object)，所有字段要么全被设置，要么全不被设置。 可用版本版本&gt;= 1.0.1 时间复杂度O(N)， N 为要设置的 key 的数量。 返回值当所有 key 都成功设置，返回 1 。如果所有给定 key 都设置失败(至少有一个 key 已经存在)，那么返回 0 。 示例1234567891011121314# 对不存在的 key 进行 MSETNXredis&gt; MSETNX rmdbs &quot;MySQL&quot; nosql &quot;MongoDB&quot; key-value-store &quot;redis&quot;(integer) 1redis&gt; MGET rmdbs nosql key-value-store1) &quot;MySQL&quot;2) &quot;MongoDB&quot;3) &quot;redis&quot;# MSET 的给定 key 当中有已存在的 keyredis&gt; MSETNX rmdbs &quot;Sqlite&quot; language &quot;python&quot; # rmdbs 键已经存在，操作失败(integer) 0redis&gt; EXISTS language # 因为 MSET 是原子性操作，language 没有被设置(integer) 0redis&gt; GET rmdbs # rmdbs 也没有被修改&quot;MySQL&quot; PSETEXPSETEX key milliseconds value 这个命令和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间，而不是像 SETEX 命令那样，以秒为单位。 可用版本版本&gt;= 2.6.0 时间复杂度O(1) 返回值设置成功时返回 OK 。 示例123456redis&gt; PSETEX mykey 1000 &quot;Hello&quot;OKredis&gt; PTTL mykey(integer) 999redis&gt; GET mykey&quot;Hello&quot; STRLENSTRLEN key 返回 key 所储存的字符串值的长度。 当 key 储存的不是字符串值时，返回一个错误。 可用版本版本&gt;= 2.2.0 复杂度O(1) 返回值字符串值的长度。当 key 不存在时，返回 0 。 示例12345678# 获取字符串的长度redis&gt; SET mykey &quot;Hello world&quot;OKredis&gt; STRLEN mykey(integer) 11# 不存在的 key 长度为 0redis&gt; STRLEN nonexisting(integer) 0]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[精通Hibernate]]></title>
    <url>%2F2017%2F03%2F01%2F%E7%B2%BE%E9%80%9Ahibernate%2F</url>
    <content type="text"><![CDATA[今天去公司上班了，公司后台框架是hibernate+springMvc,虽然之前看过hibernate，但是没有在实际的开发过程中用到，很多都忘记了，就准备看孙卫琴的《精通Hibernate》。 Java对象持久化技术概论从不同的角度解释hibernate： 它是连接Java应用程序和关系数据库的中间件。 它对JDBC API进行了封装，负责Java的持久化。 在分层软件架构中它位于持久化层，封装了所有数据访问细节，使业务逻辑层可以专注与实现业务逻辑。 它是一只ORM映射工具，能够建立面向对象的域模型和关系数据模型之间的映射。 本章介绍软件的三种模型：概念模型、域模型和数据模型，然后介绍了Java对象的持久化概念，并介绍了实现对象持久化的几种模式： 业务逻辑和数据访问耦合 主动域对象模式 ORM模式 JDO模式 CMP模式 应用程序的分层体系结构四层结构应用软件的结构。 表述层：提供与用户交互的界面。GUI(图形用户界面)和web页面而是表述层的两个典型的例子。 业务逻辑层：实现各种业务逻辑。例如当用户发出生产订单的请求时，业务逻辑层负责计算的价格、验证订单的信息。 持久层：封装数据访问细节，为业务逻辑提供了面向对象的API 数据库层：负责存放和管理应用的持久性业务数据。例如对于电子商务网站应用，在数据库中保存了客户、订单和商品等业务数据。关系数据库依然是目前最流行的数据库。 软件分层的优点恰当地为软件分层，将会提高软件的以下性能。 伸缩性：伸缩性指应用程序是否能支持更多的用户。 可维护性：当发生需求变化，只需修改软件的某一部分，不会影响其他部分的代码。层次越多，可维护性也会不断提高，因为修改软件的某一部分的实现，不会影响其它层。 可扩展性：是在现有的系统中增加新功能的难易程度。层数越少，添加新功能就越容易破坏现有的程序结构。层数越多，就可以在每个层次中提供扩展点，不会打破应用的整体框架。 可重复性：程序代码有冗余，同一个程序就能满足多种需求。 可管理性：管理系统的难易程度。将应用程序分为多层后，可以将工作分解给不同的开发小组，从而便于管理。应用越复杂，规模越大，需要的层就越多。 软件分层的缺点 软件分层越多，对软件设计人员的要求就越高。 在设计阶段，必须花时间构思合理的体系结构。 开发流程相对复杂，降低开发效率。 Java应用的持久化层Hibernate API简介hibernate中的接口可分为以下几类： 提供访问数据库的操作（如保存、更新、删除和查询对象）的接口。这些接口包括：Session、Transaction和Quer接口。 用于配置Hibernate的接口：Configuration。 回调接口，使应用程序接受Hibernate内部发生的事件，并做出相应的回应。这些接口包括：Interceptor、Lifecycle和Validatable接口。 用于扩展Hibernate的功能的接口，如UserType、CompositeUserType和IdentifierGenerator接口，如果需要的话，应用程序可以扩展这些接口。 Hibernate入门Hibernate是Java应用和关系型数据库之间的桥梁，内部封装了通过JDBC访问数据库的操作，向上层应用提供了面向对象的数据访问API。在Java应用中使用hibernate包含以下步骤。 创建Hibernate的配置文件。 创建持久化类。 创建对象-关系映射文件。 通过HibernateAPI编写访问数据库的代码。 创建Hibernate的配置文件hibernate的配置文件中读取了数据库连接的有关信息，有两种形式：一种是XML格式文件；还有一种是Java属性文件，采用“健=值”的形式。配置文件的属性：hibernate.properties 123456hibernate.dialect=net.sf.hibernate.dialect.MySQLDialct //指定数据库使用SQL方言hibernate.connection.driver_class=com.mysql.jdbc.Driver //指定数据库的驱动程序hibernate.connection.url=jdbc:mysql://localhost:3306/SAMPLEDB //指定数据库的URLhibernate.connection.username=root //指定数据库的连接名hibernate.connection.password=root //指定数据库的口令hibernate.show_sql=ture //是否在控制台输出SQL语句 创建持久化类持久化类是指其实例需要被Hibernate持久化到数据库中的类。持久化类通常都是域模型中的实体域类。持久化类符合JavaBean的规范，包含一些属性，以及与之对应的getXXX()和setXXX()方法。下列中定义了一个名为Customer的持久化类。 123456789package mypack;import java.io.Serializable;import java.sql.Date;import java.sql.Timestamp;public class Customer implements Serializable &#123;-&#125; 持久化类符合JavaBean的规范，包含一些属性，以及与之对应的getXXX()和setXXX()方法。getXXX()和setXXX()方法必须符合特定的命名规范，”get”和”set”后面紧跟属性的名字，并且属性名的首字母为大写，例如name属性的getName(),如果把get方法写为getname()或者getNANE(),会导致Hibernate在运行时抛出以下的异常： 1net.sf.hibernate.PropertNotFountException:Could not find a getter for property name in class mypack.Customer 如果为boolean类型可以用isXXX()或者getXXX().Hibernate并不要求持久化类必须实现java.io.Serializable接口，但是对于采用分布式结构的Java应用，当Java对象在不同的进程点之间传输时，这个对象所属的类必须实现Serializable接口，此外，在Java web应用中，如果希望对HttpSession中存放的Java对象进行持久化，那么这个Java对象所属的类也必须实现Serializable接口。Customer持久化类有一个id属性，用来唯一标识Customer类的每个属性。在面向对象术语中，这个id属性称为对象标识符(OID,Object Identifier)。通常为整数也可以为其他类型。Hibernate要求持久化类必须提供一个不带参数的默认构造方法，在程序运行时，Hibernate运用Java反射机制，调用java.lang.reflenct.Constructor.newInstance()方法来构造持久化的实例。如果对这个持久化类使用延迟检索策略，为了使Hibernate能够在运行时为这个持久化类创建动态代理，要求持久化类的默认构造方法的访问级别必须是public或protected类型，而不是default 或private类型。在Customer类中没有引入任何Hibernate API，Customer类不需要继承Hibernate的类或者实现Hibernate的接口，这提高了持久化类的独立性。 创建数据库Schema下面为Customer类对应的数据库表名为CUSTOMERS，它在MySQL数据库中的DDL定义如下： 1234567891011121314create table CUSTOMERS( ID bigint not null primary key, NAME varchar(15) not null, EMAIL varchar(128) not null, PASSWORD varchar(8) not null, PHONE int, ADDRESS varchar(255), SEX char(1), IS_MARRIED bit, DESCRIPTION text, IMAGE blob, BIRTHDAY date, REGISTERED_TIME timestamp); 创建对象-关系映射文件Hibernate采用XML格式的文件来指定对象和关系数据之间的映射。在运行时，Hibernate将根据这个映射文件来生成各种SQL语句。下面的Customer.hbm.xml把Customer类映射到CUSTOMERS表： 12345678910111213141516171819&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC &quot;-//Hibernate/Hibernate Mapping DTD 2.0//EN&quot;&quot;http://hibernate.sourceforge.net/hibernate-mapping-2.0.dtd&quot;&gt; &lt;hibernate-mapping&gt;&lt;class name=&quot;mypack.Customer&quot; table=&quot;CUSTOMERS&quot;&gt;&lt;id name=&quot;id&quot; column=&quot;ID&quot; type=&quot;long&quot;&gt;&lt;generator class=&quot;increment&quot;/&gt;&lt;/id&gt;&lt;property name=&quot;name&quot; column=&quot;NAME&quot; type=&quot;string&quot; not-null=&quot;true&quot;/&gt;&lt;property name=&quot;email&quot; column=&quot;EMAIL&quot; type=&quot;string&quot; not-null=&quot;true&quot;/&gt;&lt;property name=&quot;password&quot; column=&quot;PASSWORD&quot; type=&quot;string&quot; not-null=&quot;true&quot;/&gt;&lt;property name=&quot;phone&quot; column=&quot;PHONE&quot; type=&quot;int&quot;/&gt;&lt;property name=&quot;address&quot; column=&quot;ADDRESS&quot; type=&quot;string&quot;/&gt;&lt;property name=&quot;sex&quot; column=&quot;SEX&quot; type=&quot;character&quot;/&gt;&lt;property name=&quot;married&quot; column=&quot;IS_MARRIED&quot; type=&quot;boolean&quot;/&gt;&lt;property name=&quot;description&quot; column=&quot;DESCRIPTION&quot; type=&quot;text&quot;/&gt;&lt;property name=&quot;image&quot; column=&quot;IMAGE&quot; type=&quot;binary&quot;/&gt;&lt;property name=&quot;birthday&quot; column=&quot;BIRTHDAY&quot; type=&quot;date&quot;/&gt;&lt;property name=&quot;registeredTime&quot; column=&quot;REGISTEREDTIME&quot; type=&quot;timestamp&quot;/&gt;&lt;/class&gt;&lt;/hibernate-mapping&gt; 映射文件的文档类型定义（DTD）Customer.hbm.xml文件的开头定义声明DTD（Document Type Definition,文档类型定义），它对XML文件的语法和格式做了定义。]]></content>
      <categories>
        <category>Hibernate</category>
      </categories>
      <tags>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库常见面试题目]]></title>
    <url>%2F2017%2F02%2F20%2FMySQL%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[在准备面试，就在网上收集了一些MySQL面试题目。 如何登陆mysql数据库MySQL -u username -p 如何开启/关闭mysql服务service mysql start/stop 查看mysql的状态service mysql status 如何显示数所有数据库show databases 如何获取表内所有字段对象的名称和类型describe table_name; MYSQL支持事务吗？在缺省模式下，MYSQL是autocommit模式的，所有的数据库更新操作都会即时提交，所以在缺省情况下，mysql是不支持事务的。但是如果你的MYSQL表类型是使用InnoDB Tables 或 BDB tables的话，你的MYSQL就可以使用事务处理,使用SET AUTOCOMMIT=0就可以使MYSQL允许在非autocommit模式，在非autocommit模式下，你必须使用COMMIT来提交你的更改，或者用ROLLBACK来回滚你的更改。示例如下：START TRANSACTION;SELECT @A:=SUM(salary) FROM table1 WHERE type=1;UPDATE table2 SET summmary=@A WHERE type=1;COMMIT; MYSQL相比于其他数据库有哪些特点？MySQL是一个小型关系型数据库管理系统，开发者为瑞典MySQL AB公司，现在已经被Sun公司收购，支持FreeBSD、Linux、MAC、Windows等多种操作系统与其他的大型数据库例如Oracle、DB2、SQL Server等相比功能稍弱一些1、可以处理拥有上千万条记录的大型数据2、支持常见的SQL语句规范3、可移植行高，安装简单小巧4、良好的运行效率，有丰富信息的网络支持5、调试、管理，优化简单（相对其他大型数据库） varchar和char的区别Char是一种固定长度的类型，varchar是一种可变长度的类型 数据库事物有哪几种？隔离性、持续性、一致性、原子性 请简洁地描述下MySQL中InnoDB支持的四种事务隔离级别名称，以及逐级之间的区别？SQL标准定义的四个隔离级别为：read uncommited：读取未提交内容read committed：读取提交内容repeatable read：可重读serializable：可串行化详细解释如下：Read Uncommitted（读取未提交内容）在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。Read Committed（读取提交内容）这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。Repeatable Read（可重读）这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读（Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control 间隙锁）机制解决了该问题。注：其实多版本只是解决不可重复读问题，而加上间隙锁（也就是它这里所谓的并发控制）才解决了幻读问题。Serializable（可串行化）这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。对于不同的事务，采用不同的隔离级别分别有不同的结果。不同的隔离级别有不同的现象。主要有下面3种现在：1、脏读（dirty read）：一个事务可以读取另一个尚未提交事务的修改数据。2、非重复读（nonrepeatable read）：在同一个事务中，同一个查询在T1时间读取某一行，在T2时间重新读取这一行时候，这一行的数据已经发生修改，可能被更新了（update），也可能被删除了（delete）。3、幻像读（phantom read）：在同一事务中，同一查询多次进行时候，由于其他插入操作（insert）的事务提交，导致每次返回不同的结果集。不同的隔离级别有不同的现象，并有不同的锁定/并发机制，隔离级别越高，数据库的并发性就越差，4种事务隔离级别分别表现的现象如下表：这里写图片描述 mysql数据库引擎MyISAM和InnoDB的区别这里写图片描述 mysql有关权限的表都有哪几个MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别user，db，table_priv，columns_priv和host。下面分别介绍一下这些表的结构和内容：user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。db权限表：记录各个帐号在各个数据库上的操作权限。table_priv权限表：记录数据表级的操作权限。columns_priv权限表：记录数据列级的操作权限。host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。 mysql存储引擎有哪些？如何修改mysql存储引擎？MyISAM indexed sequential access method (有索引的顺序访问方法)MyISAM 具有检查和修复表格的大多数工具。表格可以被压缩，而且支持全文收索不是事务安全的，而且不支持外键。MEMORY 也是以前的(HEAP) 该类型表存储在内存中，表的索引是哈希分布的。merge 这些表为了查询目的，把myisam 表集合作为单个表，因此你可以在某些操作系统中避开最大文件大小的限制。archive 这种类型的表只支持，insert ,select 不支持delete,update,replace ,不使用索引。csv 这些表保存在服务器的单个文件中，它包含了用逗号间隔的数据。 innodb 这种表是事务安全的。提供了commit（提交） rollback（实务回滚）支持外键，比myisam慢。修改mysql存储引擎alter table tablename type = innodb; MYSQL 数据表修复及数据恢复面试题MYSQL数据表在什么情况下容易损坏？服务器突然断电导致数据文件损坏。强制关机，没有先关闭mysql 服务等。数据表损坏后的主要现象是什么？从表中选择数据之时，得到如下错误：Incorrect key file for table: ‘…’. Try to repair it查询不能在表中找到行或返回不完全的数据。Error: Table ‘p’ is marked as crashed and should be repaired 。打开表失败： Can’t open file: ‘×××.MYI’ (errno: 145) 。数据表损坏的修复方式有哪些？使用 myisamchk 来修复，具体步骤：1）修复前将mysql服务停止。2）打开命令行方式，然后进入到mysql的/bin目录。3）执行myisamchk –recover 数据库所在路径/*.MYI使用repair table 或者 OPTIMIZE table命令来修复，REPAIR TABLE table_name 修复表 OPTIMIZE TABLE table_name 优化表 REPAIR TABLE 用于修复被破坏的表。OPTIMIZE TABLE 用于回收闲置的数据库空间，当表上的数据行被删除时，所占据的磁盘空间并没有立即被回收，使用了OPTIMIZE TABLE命令后这些空间将被回收，并且对磁盘上的数据行进行重排（注意：是磁盘上，而非数据库） MYSQL数据库服务器性能分析的方法命令有哪些?Show status一些值得监控的变量值：Bytes_received和Bytessent和服务器之间来往的流量。Com服务器正在执行的命令。Created_在查询执行期限间创建的临时表和文件。Handler*存储引擎操作。Select不同类型的联接执行计划。Sort_几种排序信息。Show session status like ‘Select’;Show profilesSET profiling=1;Show profiles\GShow profile; mysql里记录货币用什么字段类型好NUMERIC和DECIMAL类型被MySQL实现为同样的类型，这在SQL92标准允许。他们被用于保存值，该值的准确精度是极其重要的值，例如与金钱有关的数据。当声明一个类是这些类型之一时，精度和规模的能被(并且通常是)指定；例如：salary DECIMAL(9,2)在这个例子中，9(precision)代表将被用于存储值的总的小数位数，而2(scale)代表将被用于存储小数点后的位数。因此，在这种情况下，能被存储在salary列中的值的范围是从-9999999.99到9999999.99。在ANSI/ISO SQL92中，句法DECIMAL(p)等价于DECIMAL(p,0)。同样，句法DECIMAL等价于DECIMAL(p,0)，这里实现被允许决定值p。MySQL当前不支持DECIMAL/NUMERIC数据类型的这些变种形式的任一种。这一般说来不是一个严重的问题，因为这些类型的主要益处得自于明显地控制精度和规模的能力。DECIMAL和NUMERIC值作为字符串存储，而不是作为二进制浮点数，以便保存那些值的小数精度。一个字符用于值的每一位、小数点(如果scale&gt;0)和“-”符号(对于负值)。如果scale是0，DECIMAL和NUMERIC值不包含小数点或小数部分。DECIMAL和NUMERIC值得最大的范围与DOUBLE一样，但是对于一个给定的DECIMAL或NUMERIC列，实际的范围可由制由给定列的precision或scale限制。当这样的列赋给了小数点后面的位超过指定scale所允许的位的值，该值根据scale四舍五入。当一个DECIMAL或NUMERIC列被赋给了其大小超过指定(或缺省的）precision和scale隐含的范围的值，MySQL存储表示那个范围的相应的端点值。]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis]]></title>
    <url>%2F2017%2F02%2F12%2FMybatis%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[初学mybatis。 SqlSessionSqlSession的作用： 向SQL语句传入参数 执行SQL语句 获取执行SQL语句的结果 事务的控制 如何得到SqlSession: 通过配置文件获取数据库连接相关信息 通过配置信息构建SqlSessionFactory 通过SqlSessionFactory打开数据库会话各层分工servlet 负责接收页面的值，向页面传值，如果有相应的业务逻辑需要处理，则调用相应service层。service 负责接收servlet传过来的值，并做执行处理，业务的操作、算法等等，如果有需要要调用相应的dao层。dao 完成与数据库的交互，执行相应的sql语句bean 对象]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx安装过程]]></title>
    <url>%2F2017%2F02%2F11%2FNginx%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[nginx是C语言开发，建议在linux上运行，本教程使用Centos6.5作为安装环境。 nginx安装环境 gcc安装nginx需要先将官网下载的源码进行编译，编译依赖gcc环境，如果没有gcc环境，需要安装gcc：yum install gcc-c++ PCREPCRE(Perl Compatible Regular Expressions)是一个Perl库，包括 perl 兼容的正则表达式库。nginx的http模块使用pcre来解析正则表达式，所以需要在linux上安装pcre库。yum install -y pcre pcre-devel注：pcre-devel是使用pcre开发的一个二次开发库。nginx也需要此库。 zlibzlib库提供了很多种压缩和解压缩的方式，nginx使用zlib对http包的内容进行gzip，所以需要在linux上安装zlib库。yum install -y zlib zlib-devel opensslOpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。 nginx不仅支持http协议，还支持https（即在ssl协议上传输http），所以需要在linux安装openssl库。yum install -y openssl openssl-devel 编译安装将nginx-1.8.0.tar.gz拷贝至linux服务器。解压： tar -zxvf nginx-1.8.0.tar.gz cd nginx-1.8.0 configure./configure –help查询详细参数 参数设置如下：./configure \1234567891011--prefix=/usr/local/nginx \--pid-path=/var/run/nginx/nginx.pid \--lock-path=/var/lock/nginx.lock \--error-log-path=/var/log/nginx/error.log \--http-log-path=/var/log/nginx/access.log \--with-http_gzip_static_module \--http-client-body-temp-path=/var/temp/nginx/client \--http-proxy-temp-path=/var/temp/nginx/proxy \--http-fastcgi-temp-path=/var/temp/nginx/fastcgi \--http-uwsgi-temp-path=/var/temp/nginx/uwsgi \--http-scgi-temp-path=/var/temp/nginx/scgi 注意：上边将临时文件目录指定为/var/temp/nginx，需要在/var下创建temp及nginx目录 编译安装makemake install安装成功查看安装目录 ：]]></content>
      <categories>
        <category>Operations</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库应用从入门到精通]]></title>
    <url>%2F2017%2F01%2F12%2FMySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BA%94%E7%94%A8%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A%2F</url>
    <content type="text"><![CDATA[最近在看《MySQL数据库应用从入门到精通》这本书是基于MySQL5.5版本的，下面是看书过程记录下来的笔记。 数据库概述 SQL主要功能：数据定义语言（DDL）,数据操作语言（DML）,数据控制语言（DCL). 数据可基本操作create Database database_name;创建数据库SHOW DATABASES;查看数据库USE database_name; 选择数据库DROP DATABASE database_name;删除数据库 在执行SQL语句中，可以用”;”、”\g”、”\G”符号表示语句结束。其中前两个符号的作用一样，而最后一个符号除了表示语句结束外，还可以使得结果显示的更加美观。 mysql中的存储引擎和数据类型存储引擎查询存储引擎 存储引擎是MySQL数据库管理系统的一个重要特征，在具体开发时，为了提高MySQL数据库管理系统的使用效率和灵活性，可以根据实际需要来选择存储引擎。因为存储引擎指定了表的类型，即如何存储和索引数据、是否支持事物等，同时存储引擎也决定了表在计算机中的存储方式。SHOW ENGINES;显示支持的存储引擎show variables like &#39;%storage_engine%&#39;;当前默认的存储引擎: 选择存储引擎 下图是3种常用的存储引擎介绍。 上面主要介绍了MyISAM、InnoDB和MEMORY三种存储引擎特性的对比，接下来将详细介绍这3个存储引擎的应用场合并给出相应的建议。 MyISAM:由于该存储引擎不支持事务、也不支持外键，所以访问速度比较快。因为此对事务完整性没有要求并以访问为主的应用适用于该存储引擎。 InnoDB:由于该存储引擎在事务上具有优势，即支持具有提交、回滚和崩溃恢复能力的事务安装，所以比MyISAM存储引擎占用更多的磁盘空间。因此需要进行频繁的更新、删除操作，同时还对事务的完整性要求比较高，需要实现必发控制，此时适用适用该存储引擎。 MEMORY:该存储引擎使用内存来存储数据，因此该存储引擎的数据访问速度比较快，但是安全上没有保障。如果应用中涉及数据比较小，需要进行快速访问，则适用使用该存储引擎。 关于图形化的存储引擎修改这里不做记录，下面讲解通过修改my.ini配置来配置存储引擎。 如果想要修改默认存储引擎，只需修改[mysqld]组中的default-storage-engine参数。如：default-storage-engine=MyISAM 注意：如果修改参数后，需重启MySQL服务才能生效 数据类型整形 整型具体特性如下图： 浮点数类型、定点数类型和位类型当需要精确到小数点后10位以上是，需要选择DOUBLE类型。当需要小数数据精确度非常高时，则可以选择DEC和DECIMAL类型，它们的精确度比DOUBLE类型还要高。FLOAT、DOUBLE数据类型存储数据是存储的是近似数，而DECIMAL存储的是字符串，因此提供了更高的精度。 浮点数类型具体特性如下图： 定点数类型具体特性如下图： FLOAT数据类型和DECIMAL数据类型的区别如下：结果为： 位类型具体类型如下：BIT类型的使用 日期和时间类型 日期和时间类型具体特性如下图： 字符串类型 CHAR系列字符串类型具体特性如下： TEXT系列字符串类型具体特性如下： BINARY系列字符串类型具体特性如下：BINARY可以存储二进制数据（例如图片、音乐或者视频文件），而后者只能存储字符数据。如果二进制数据长度经常变化则选择VARBINARY类型，否则选择BINARY。 BLOB系列字符类型具体特性如下：上面的四种类型与TEXT系列字符串类型非常类似，不同的是，前者可以存储二进制数据（例如图片、音乐或者视频文件），而后者只能存储字符数据。如果需要存储电影等视频文件时则根据实际选择合适长度的BLOB类型 表的操作表的基本概念表是包含数据库中所有数据的数据库对象，表中的数据库对象包含列、索引和触发器。 表的基本语法使用USE database_name;进入要操作的数据库。 创建表的语法形式 可以使用下面几种语法查看表定义DESCRIBE table_name;SHOW CREATE TABLE table_name;DESC table_name; 删除表DROP TABLE table_name; 修改表ALTER TABLE old_name RENAME [TO] new_table_name;修改表名ALTER TABLE table_name ADD 属性名 属性类型；在表的最后一个位置添加字段ALTER TABLE table_name ADD 属性名 属性类型 FIRST；在表的第一个位置添加字段ALTER TABLE table_name ADD 属性名 属性类型 AFTER 属性名；在表指定字段之后添加字段ALTER TABLE table_name DROP 属性名;删除表中指定的属性ALTER TABLE table_name MODIFY 属性名 数据类型;修改字段的数据类型ALTER TABLE table_name CHANGE 旧属性名 新属性名 旧属类型;修改字段名字ALTER TABLE table_name CHANGE 旧属性名 新属性名 新属类型;同时修改字段名字和属性ALTER TABLE table_name MODIFY 属性名1 数据类型 FIRST |AFTER 属性名2;修改字段的顺序 MySQL支持的完整性约束所谓完整性是指数据的准确性和一致性，而完整性检查就是指检查数据的准确性和一致性。MySQL数据库管理系统提供了一致机制来检查数据库表中的数据是否满足规定的条件，以保证数据库中数据的准确性和一致性，这种机制就是约束。完整性约束如下图：CREATE TABLE table_name( 属性名 数据类型 NOT NULL, ...... );非空约束（NOT NULL,NK）CREATE TABLE table_name( 属性名 数据类型 DEFAULT 默认值, ...... );默认值（DEFAULT）CREATE TABLE table_name( 属性名 数据类型 UNIQUE, ...... );唯一约束（UNIQUE,UK）CREATE TABLE table_name( 属性名 数据类型 PRIMARY KEY, ..... );单字段主键（PRIMARY KEY,PK）CREATE TABLE table_name( 属性名 数据类型,.....[CONSTRAINT 约束名]PRIMARY KEY(属性名,属性名......) );多字段主键（PRIMARY KEY,PK）CREATE TABLE table_name( 属性名 数据类型 AUTO_INCREMENT, ..... );自动增加（AUTO_INCREMENT）CREATE TABLE table_name( 属性名 数据类型, 属性名 数据类型, ..... CONSTRAINT 外键约束名 FOREIGN KEY (属性名) REFERENCES 表名 （属性名2） );外键约束（FOREIGN KEY,FK） 注意：如果想给字段上的约束设置一个约束名字，可以执行SQL语句CONSTRAINT.例如：CONSTRAINT 约束名字 约束 (属性名); 索引的操作数据库对象索引其实与书的目录非常类似，主要是为了提高从表中检索数据的速度。InnoDB和MyISAM存储引擎支持BTREE类型索引，MEMORY存储引擎支持HASH类型索引，默认为前者索引。MySQL支持6种索引，分别为普通索引、唯一索引、全文索引、单列索引、多列索引和空间索引。 创建和查看索引ASC参数用来指定为升序排序，DESC参数用来指定为降序排序 普通索引创表时创建普通索引如下： 1234567CREATE TABLE table_name( 属性名 数据类型, 属性名 数据类型, ...... 属性名 数据类型, INDEX|KEY [索引名] (属性名1 [(长度)] [ASC|DESC])); CREATE INDEX 索引名 ON表名(属性名 [(长度)] [ASC|DESC]);在已经存在的表上创建普通索引ALTER TABLE table_name ADD INDEX|KEY 索引名 （属性名 [(长度)] [ASC|DESC]);通过SQL语句ALTER TABLE 创建普通索引 唯一索引注意：explain用法EXPLAIN tbl_name或EXPLAIN [EXTENDED] SELECT select_options前者可以得出一个表的字段结构等等，后者主要是给出相关的一些索引信息，而今天要讲述的重点是后者。创建表时创建唯一索引如下： 1234567CREATE TABLE table_name( 属性名 数据类型, 属性名 数据类型, ...... 属性名 数据类型, UNIQUE INDEX|KEY [索引名] （属性名1 [(长度)] [ASC|DESC])); CREATE UNIQUE INDEX 索引名 ON表名(属性名 [(长度)] [ASC|DESC]);在已经存在的表上创建唯一索引ALTER TABLE table_name ADD UNIQUE INDEX|KEY 索引名 （属性名 [(长度)] [ASC|DESC]);通过SQL语句ALTER TABLE 创建唯一索引 全文索引创建表时创建全文索引如下： 1234567CREATE TABLE table_name( 属性名 数据类型, 属性名 数据类型, ...... 属性名 数据类型, FULLTEXT INDEX|KEY [索引名] （属性名1 [(长度)] [ASC|DESC]) ); CREATE FULLTEXT INDEX 索引名 ON表名(属性名 [(长度)] [ASC|DESC]);在已经存在的表上创建全文索引 ALTER TABLE table_name ADD FULLTEXT INDEX|KEY 索引名 （属性名 [(长度)] [ASC|DESC]);通过SQL语句ALTER TABLE 创建全文索引 多列索引创建表时创建全文索引如下： 123456789CREATE TABLE table_name( 属性名 数据类型, 属性名 数据类型, ...... 属性名 数据类型, INDEX|KEY [索引名] （属性名1 [(长度)] [ASC|DESC], ...... 属性名n [(长度)] [ASC|DESC]) ); 在已经存在的表上创建多列索引如下： 12345CREATE INDEX 索引名 ON 表名（属性名1 [(长度)] [ASC|DESC], ...... 属性名n [(长度)] [ASC|DESC] ）; 通过SQL语句ALTER TABLE创建多列索引 12345ALTER TABLE table_name( ADD INDEX|KEY 索引名（属性名1 [(长度)] [ASC|DESC], ...... 属性名n [(长度)] [ASC|DESC] ）; 删除索引DROP INDEX index_name ON table_name;删除索引 视图的操作视图的特点特点如下： 视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。 视图是由基本表（实表）产生的表（虚表）。 视图的建立和删除不影响基本表。 对视图内容的更新（添加、删除和修改）直接影响基本表。 当视图来自多个基本表是，不允许添加和删除数据。 创建视图CREATE VIEW view_name AS 查询语句;创建视图USE view;使用视图 常量视图具体语句如下：123CREATE VIEW view_test1 AS SELECT 3.1415926; 封装使用聚合函数（SUM、MIN、MAX、COUNT等）查询语句的视图具体语句如下：1234CREATE VIEW view_test2 AS SELECT COUNT(name) FROM database_name; 封装了实现功能（ORDER BY）查询语句的视图具体语句如下：12345CREATE VIEW view_test3 AS SELECT name FROM table_name ORDER BY id DESC; 封装了实现表内连接查询语句的视图具体语句如下：12345CREATE VIEW view_test4 AS SELECT s.name FROM t_student as s,t_group as g WHERE s.group_id=g.id AND g.id=2; 封装了实现表外连接（LEFT JOIN 和RIGHT JOIN）查询语句视图具体语句如下：12345CREATE VIEW view_test5 AS SELECT s.name FROM t_student as s LEFT JOIN t_group as g ON s.group_id=g.id where g.id=2; 封装了实现子查询相关查询语句的视图具体语句如下：12345CREATE VIEW view_test6 AS SELECT s.name FROM t_student AS s WHERE s.grop_id IN(SELECT id FROM t_group); 封装了实现记录联合（UNION和UNION ALL）查询语句的视图具体语句如下：12345CREATE VIEW view_test7 AS SELECT id,name FROM t_student UNION ALL SELECT id,name FROM t_group; 查看视图USE dababase_name; SHOW TABLES;查看视图名USE database_name; SHOW CREATE VIEW viewname;查看视图定义信息USE database_name; DESCRIBE | DESC viewname;查看视图设计信息SHOW TABLE STATUS [FROM db_name] [LIKE &#39;pattern&#39;];查看视图（和表）详细信息SHOW TABLE STATUS返回字段含义如下图： 删除视图USE database_name; DROP VIEW view_name [,view_name] ...;删除视图 修改视图CREATE OR REPLACE VIEW语句修改视图12345`USE database_name; CREATE OR REPLACE VIEW view_selectproduct AS SELECT name FROM t_products; ALTER 语句修改视图12345`USE database_name; ALTER VIEW view_selectproduct AS SELECT name FROM t_products; 利用视图操作基本表检索（查询）数据SELECT * FROM view_name; 利用视图操作基本表数据 对视图数据进行添加、删除和更新操作直接影响基本表。 视图来自多个基本表时，不允许添加和删除数据。 添加数据操作12INSERT INTO view_name(属性1,属性2，属性3...) VALUES(value1,value2,value3...); 删除数据操作12DELETE FROM view_name WHERE name=’属性名‘; 更新数据操作123UPDATE view_name set 属性1=value WHERE 属性2=value； 触发器的操作在具体的应用中，之所以经常使用触发器数据对象，是由与该对象能够加强数据库表中数据的完整性约束和业务规则等。 创建有一条执行语句的触发器123create trigger trigger_name BEFORE|AFTER trigger_EVENT ON TABLE_NAME FOR EACH ROW trigger_STMT; 创建包含多条执行语句的触发器123456create trigger trigger_name BEFORE|AFTER trigger_EVENT ON TABLE_NAME FOR EACH ROW BEGIN trigger_STMT END; 查看触发器SHOW TRIGGERS;语句查看触发器通过查看系统表triggers实现查看触发器，如下12USE information_schema;SELECT * FROM triggers (WHERE TRIGGER_NAME=&apos;trigger_name&apos;) \G 删除触发器DROP TRIGGER trigger_name;删除触发器 数据操作插入数据插入一部分数据12INSERT INTO table_name(field1,field2,field3,......fieldn) VALUES(value1,value2,value3......valuen); 插入完整数据12INSERT INTO table_name VALUES(value1,value2,value3......valuen); 插入多天数据123456789101112131415#插入多条部分数据INSERT INTO table_name(field1,field2,field3,...fieldn) VALUES(value11,value21,value31...valuen1), (value11,value21,value31...valuen1), (value11,value21,value31...valuen1), ...... (value1m,value2m,value3m...valuenm);#插入多条完整数据INSERT INTO table_name VALUES(value11,value21,value31...valuen1), (value11,value21,value31...valuen1), (value11,value21,value31...valuen1), ...... (value1m,value2m,value3m...valuenm); 插入查询结果1234INSERT INTO table_name1(field11,field12,field13,...field1n) SELECT (field21,field22,field23,...field2n) FROM table name2 WHERE ... 更新数据记录12345UPDATE table_name SET field1=value1, field2=value2, field3=value3, WHERE CONDITION 删除特定数据记录 12DELETE FROM table_nameWHERE CONDITION 单表数据记录查询简单数据查询一般查询SELECT field1 field2 ...fieldn FROM table_name; 查询指定字段数据SELECT * FROM table_name; 查询所有字段数据SELECT DISTINCT field1 field2 ...fieldn FROM table_name;避免数据重复查询–DISTINCT 实现数学四则运算数据查询mysql支持的关系运算符如下：12345SELECT field1 [AS] otherfield1,field2 [AS] otherfield2,...fieldn [AS] otherfieldnFROM table_name#例如：SELECT ename,sal*12 [AS] yearsalaryFROM t_employee; 设置显示格式数据查询如下显示的是以固定的格式（ename雇员的年薪为：sal）显示查询到数据12SELECT CONCAT(ename,&apos;雇员的年薪为：&apos;,sal*12) yearsalary FROM t_employee; 结果为： 条件数据记录查询条件查询的语法格式123SELECT field1、field2 ...field3 FROM table_name WNERE CONDITION; 带关系运算符和逻辑运算符的条件数据查询带（not）between value1 and value2查询（不）符合范围之内IS （NOT） NULL查询是（不是）空值 带IN关键字的集合查询注意：IN查询时，查询集合中包括NULL,则不会影响结果；NOT IN查询时，查询集合中包括NULL,则查询不到结果。1234SELECT field1 field2 ...fieldnFROM table_nameWHERE field IN(value1,value2,value3,...,valuen);//在集合中WHERE field NOT IN(value1,value2,value3,...,valuen);//不在集合中 带LIKE关键字模糊查询123SELECT field1 field2 ...fieldnFROM table_nameWHERE field [NOT] LIKE value; LIKE支持的通配符如下： “_”通配符，该通配符值能匹配单个字符 “%”通配符，该通配符可以匹配任意长度单位字符串，可以0个字符、1个或者更多 排序数据记录查询1234SELECT field1 field2 ...fieldnFROM table_nameWHERE CONDITIONORDER BY fieldm1 [ASC|DESC] [,fieldm2 [ASC|DESC],]; 限制数据记录查询数量12345SELECT field1 field2 ...fieldnFROM table_name where CONDITION LIMIT OFFSET_START,ROW_COUNT;#OFFSET_START为初始位置，可以选择不指定数据。 统计函数和分组数据记录查询 COUNT()：记录条数。 AVG()：平均值。 SUN():总和。 MAX():最大值。 MIN():最小值。 注意：如果操作表中没有数据，则COUNT()函数返回为0，其它返回为NULL. 分组数据查询分组查询的简单格式：1234SELECT function() FROM table_name WHER CONDITION GROUP BY field; 下面为分组查询不同情况： function()为*时是简单分组查询 function()为GROUP_CONCAT(field)时实现统计功能分组查询，如下： 123SELECT deptno,GROUP_CONCAT(ename),COUNT(ename) number FROM t_employee GROUP BY deptno; 多字段分组查询 1234SELECT GROUP_COUNT(field),function(field)FROM table_nameWHERE CONDITIONGROUP BY field1,field2,...fieldn; 实现HAVING字句限定分组查询 1234567891011SELECT function(field)FROM table_nameWHERE CONDITIONGROUP BY field1,field2,...fieldnHAVING CONDITION;#例如：SELECT deptno,AVG(sal) average,GROUP_CONCAT(ename) ename,COUNT(ename) numberFROM t_employeeGROUP BY deptnoHAVING AVG(sal)&gt;2000; 自定义排序1234567891011121314151617181920212223242526原表 user：id name roleId1 aaa 12 bbb 23 ccc 34 ddd 45 eee 5- MySQL可以通过field()函数自定义排序，格式：field(value,str1,str2,str3,str4)，value与str1、str2、str3、str4比较，返回1、2、3、4，如遇到null或者不在列表中的数据则返回0.例如：select * from user order by field(roleId,2,3,4,1,5);结果：id name roleId2 bbb 23 ccc 34 ddd 41 aaa 15 eee 5- locate（substr,str）函数返回子串substr在字符串str中第一次出现的位置，可以根据该函数进行排序例如：select * from user order by locate(id,&apos;2,3,1,5,4&apos;);结果：id name roleId2 bbb 23 ccc 31 aaa 15 eee 54 ddd 4 多表数据记录查询关系数据库操作并（UNION）UNION指令的目的是将两个SQL语句的结果合并起来.UNION的一个限制是两个SQL语句所产生的栏位需要是同样的资料种类。另外，当我们用UNION这个指令时，我们只会看到不同的资料值（类似于SELECT DISTINCT），而UNION ALL会将每一笔符合条件的资料都显示出来，无论资料有没有重复。123SELECT DATA FROM database1UNION ALLSELECT DATA FROM database2; 笛卡尔积SELECT *FROM table1 CROSS JOIN table2;交叉连接笛卡尔积在SQL中的实现方式既是交叉连接(Cross Join)。所有连接方式都会先生成临时笛卡尔积表，笛卡尔积是关系代数里的一个概念，表示两个表中的每一行数据任意组合. 内连接(INNER JOIN)内连接语法形式：123SELECT field1 field2...fieldnFROM join_tablename1 INNER JOIN join_tablename2 [INNER JOIN join_tablename]ON join_condition; 自然连接 在表关系的笛卡尔积中，首先根据表关系中相同名称的字段自动进行记录匹配，然后去掉重复的字段。是一种特殊的等值连接，它要求两个关系进行比较的分量必须是相同的属性组，并且在结果集中将重复属性列去掉。一个简单的例子，将下列关系R和S进行自然连接： 1234567891011121314SELECT *from R natural join S;R：A B Ca b cb a dc d ed f gS：A C Da c dd f gb d g 首先要对两个关系中相同属性组的分量进行比较，即比较R.A，R.C和S.A,S.C。 显然在R中只有第一行和第二行满足条件，因此进行连接得到结果：123A B C Da b c db a d g 等值连接表关系的笛卡尔积中，选择所匹配字段值相等（=符号）的数据记录。下面为等值连接与自然连接的区别： 等值连接中不要求相等属性值的属性名相同，而自然连接要求相等属性值的属性名必须相同，即两关系只有在同名属性才能进行自然连接。 等值连接不将重复属性去掉，而自然连接去掉重复属性，也可以说，自然连接是去掉重复列的等值连接。一个简单的例子，将下列关系R和S进行等值连接： 1234567891011121314select *from R inner join SON R.B=S.C;R：A B Ca b cb a dc d ed f gS：A C Da c dd f gb d g 比较R.B=S.C。 显然在R中只有第一行和第二行满足条件，因此进行连接得到结果：123R.A R.B R.C S.A S.C S.Dc d e b d gd f g d f g 不等查询表关系的笛卡尔积中，选择所匹配字段不相等的数据操作。内连接查询中的不等连接，就是在关键字ON后的匹配条件中通过除了等于关系运算符来实现不等条件外，可以使用的关系运算符包含”&gt;””&gt;=””&lt;””&lt;=”和”!=”等运算符号。一个简单的例子，将下列关系R和S进行不等值连接： 1234567891011121314select *from R inner join SON R.B!=S.C AND R.A!=&quot;c&quot;;R：A B Ca b cb a dc d ed f gS：A C Da c dd f gb d g 比较R.B=S.C 和 R.A!=”c”。 显然在R中只有第一行和第二行满足条件，因此进行连接得到结果：12R.A R.B R.C S.A S.C S.Dc d e b d g 外连接所谓外连接(OUTER JOIN),就是在表关系的笛卡尔积数据记录中，不仅保留关系中所有匹配的数据记录，而且还会保留部分不匹配的数据记录。按照保留不匹配的数据记录来源可以分为左外连接（LEFT OUTER JOIN）、右外连接（RIGHT OUTER JOIN)和全外连接（FULL OUTER JOIN). 一个简单的例子，为外连接的各种情况： 123456789101112131415161718192021222324252627282930313233a表 id name 1 张3 2 李四 3 王武 b表 id jod parent_id1 23 12 34 23 34 4 左连接 select a.*,b.* from a left join b on a.id=b.parent_id 结果是 1 张3 1 23 1 2 李四 2 34 2 3 王武 null 右连接 select a.*,b.* from a right join b on a.id=b.parent_id 结果是 1 张3 1 23 1 2 李四 2 34 2 null 3 34 4 完全连接 select a.*,b.* from a full join b on a.id=b.parent_id 结果是 1 张3 1 23 1 2 李四 2 34 2 null 3 34 4 3 王武 null 合并查询记录结果语法如下：123456789SELECT field1 field2 ...fieldn FROM tablename1UNION |UNION ALLSELECT field1 field2 ...fieldn FROM tablename2UNION |UNION ALLSELECT field1 field2 ...fieldn FROM tablename3UNION |UNION ALL 子查询例子如下：12345678910111213141516171819202122232425- 单行子查询 select ename,deptno,sal from emp where deptno=(select deptno from dept where loc=&apos;NEW YORK&apos;)；- 多行子查询 SELECT ename,job,sal FROM EMP WHERE deptno in ( SELECT deptno FROM dept WHERE dname LIKE &apos;A%&apos;)；- 多列子查询 SELECT deptno,ename,job,sal FROM EMP WHERE (deptno,sal) IN (SELECT deptno,MAX(sal) FROM EMP GROUP BY deptno)；- 内联视图子查询 (1)SELECT ename,job,sal,rownum FROM (SELECT ename,job,sal FROM EMP ORDER BY sal)； (2)SELECT ename,job,sal,rownum FROM ( SELECT ename,job,sal FROM EMP ORDER BY sal) WHERE rownum&lt;=5； - 在HAVING子句中使用子查询 SELECT deptno,job,AVG(sal) FROM EMP GROUP BY deptno,job HAVING AVG(sal)&gt;(SELECT sal FROM EMP WHERE ename=&apos;MARTIN&apos;)； · 使用MySQL运算符算术、比较、逻辑和位运算符 算术运算符如下图：注意：”&gt;”、”&lt;”、”&gt;=”和”=&lt;”比较运算符不能操作NULL(空值)。 比较运算符如下图：特殊功能运算符（实现正则表达式匹配的需要REGEXP）：如下图：如下图： 逻辑运算符如下图： 位运算符 MySQL常用的函数使用字符串函数 合并字符串函数CONCAT(S1,S2...SN)CONCAT_WS(SEP,S1,S2...SN) SEP为分隔符可以为一个字符串，也可以为其他参数，如果为NULL时返回NULL，其它位置的NULL则可忽略; 比较字符串大小函数STRCMP()STRCMP(str1,str2);str1&gt;str2为1，str1&lt; str2为-1，str1=str2为0 获取字符串的长度函数LENGTH()和字符数函数CHAT_LENGTH()LENGTH(str);参数str的长度CHAR_LENGTH(str);参数str的字符数 大小写转换UPPER(S)或者UCASE(S)转换为大写LOWER(S)或者LCASE(S)转换为小写 查找字符串位置FIND_IN_SET(str1,str2);返回字符串str2中与str1相匹配的字符串位置，str2包含若干个用逗号隔开的字符串。FIELD(str,str1,str2...);返回一个与字符串str匹配的位置（str1位置为1开始） 返回字符串相匹配的开始位置LOCATE(str1,str)、POSITION(str1 IN str)和INSTR(str,str1)在str中返回str1的开始位置。 从现有字符串中截取子字符串LEFT(str ,num)返回字符串中str中包含前num个字母（从左边数）的字符串。RIGHT(str ,num)返回字符串中str中包含后num个字母（从左边数）的字符串。 去除字符串的首尾空格LTRIM(str);去除字符串开始处空格RTRIM(str);去除字符串结束处空格TRIM(str);去除字符串首尾空格 替代字符串INSERT(str,pos,len,newstr);字符串中的pos位置开始长度为len的字符串用字符串newstr来替换。如果参数pos的值超过字符串的长度，这返回值为原始字符串str.如果len的长度大于原来字符串（str)中所剩字符串的长度，则从位置pos开始进行全部替换。若任何一个参数为NULL，则返回Null.REPLACE(str,substr,newstr);字符串substr用字符串newstr来替代。 使用数值函数常用的数值函数： 0~1随机数RAND();完全随机RAND(X);X相同时返回相同的值 整数随机数CEIl(X)或CEILING(X);大于或者等于数值X的最小整数FLOOR(X);小于或者等于数值X的最大整数 截取数值函数TRUNCATE(x,y);返回数值x保留到小数点后y位的值，y可以为负数。 四舍五入ROUND(x,y); 返回数值x保留到小数点后y位的值，在具体截取数值是需要进行四舍五入的操作。单没有y时默认为四舍五入到整数。 使用日期和时间函数常用的时间日期函数： 获取当前时间当前时间NOW(),CURRENT_TIMESTAMP(),LOCALTIME(),SYSDATE();2017-03-20 17:38:50CURDATE(),CURRENT_DATE();2017-05-02CURTIME(),CURRENT_TIME();16:29:59UNIX_TIMESTAMP(NOW());unix格式，可以不用参数表示当前时间，从1970年1月1号开始计算，以秒为单位。FROM_UNIXTIME(UNIX_TIMESTAMP(NOW()));把NUIX格式转换为普通格式同NOW()格式。UTC_DATE();UTC日期 2012-05-22UTC_TIME();UTC时间 13:00:01 获取时间和日期的各个部分获取时间和日期的各个部分的功能如下：关于月份：MONTH(NOW());月MONTHNAME(NOW());月关于星期：关于天的函数：DAYOFYEAR(NOW());年中第几天DAYOFMONTH(NOW());月中第几天获取指定值得EXTRACT()函数EXTRACT(tye FROM date);函数会从时间和日期参数中获取指定类型type的值。关于type参数的值可以是YEAR、MONTH、DAY、HOUR、MINUTE和SECOND。 计算日期和时间函数TO_DAYS(date);从0000年1月1日开始算起多少天。FROM_DAYS(TO_DAYS(NOW()));一段时间后日期和时间。DATEDIFF(DATE1,DATE2);日期参数之间的相隔天数。ADDTIME(DATE,n);date加上n秒后的时间。SUBTIME(DATE,n);date减上n秒后的时间。ADDDATE(DATE,n);date加上n天后的日期。SUBDATE(DATE,n);date减上n天后的日期。关于ADDDATE()和SUBDATE()函数另外用法：ADDDATE(d,INTERVAL expr type);日期d加上一段时间后的日期，expr决定时间的长度，type决定了操作对象。SUBDATE(d,INTERVAL expr type);日期d减去一段时间后的日期，expr决定时间的长度，type决定了操作对象。参数type类型：例子如下： 使用系统信息函数常用系统信息函数 其它函数流程函数如下： 特殊函数如下： 存储过程和函数的操作存储过程和函数的执行效率要比在程序中拼sql语句的执行效率要高。存储过程与函数区别：函数必须有返回值，而存储过程则没有，存储过程的参数类型远远多于函数。 创建存储过程和函数创建存储过程语法形式如下图： 创建函数语法形式 创建简单的存储过程和函数存储过程简单sql语句：12345678910USE company;DELIMITER $$CREATE PROCEDURE proce_employee_sal()COMMENT&apos;查询所有雇员的工资&apos;BEGIN SELECT sal FROM t_employee;END$$DELIMITER ; 函数简单SQL语句：123456789101112USE company;DELIMITER $$CREATE FUNCTION func_employee_sal(empno INT(11)) RETURNS DOUBLE(10,2)COMMENT&apos;查询所有雇员的工资&apos;BEGIN RETURN (SELECT sal FROM t_employee WHERE t_employee.empno=empno);END$$DELIMITER ; MySQL事务当多个用户访问同一份数据，一个用户在更改数据的过程中可能有其他客户同时发起更改请求，为了保证数据库记录的更新从一个一致性状态更改为另外一个一致性状态，使用事务处理是非常必要的，事务有以下4个特性： 原子性（Atimicity):事务中所有的操作视为一个原子单位，即对事务所进行的数据修改等操作只能完全提交或者完全回滚。 一致性（Consistency):事务在完成时，必须是所有的数据从一种一致性状态变更为另外一种一致性状态，所有的变更都必须应用于事务的修改，以确保数据的完整性。 隔离性（ISOLATION):一个事务中的操作语句所做的修改必须与其他事务所做的修改相隔离。 持久性（Durability):事务完成后，所做的修改对数据的影响是永久的，即使系统重启或者出现系统故障数据仍可以恢复。 MySQL数据库维护和性能提高MySQL数据库性能优化建议如下： MySQL软件具有特定的硬件建议，在具体安装和使用数据库软件时，该软件所依托的计算机服务器最好能够遵循这些硬件建议。一般来说MySQL软件应该运行在自己的专用计算机服务器上。 MySQL软件安装成功后，会进行一系列的默认配置，这些配置开始通常是比较适合的，但是一段时间后，就需要调整内存分配、缓存区大小。可以通过执行SHOW VARIABLES 和SHOW STATES来实现。 MySQL软件是一个多用户多线程的数据库管理系统，对于该类型的服务器，经常会同时执行多个任务。如果这些任务中的某一个执行缓慢，则其他所有任务都会执行缓慢。为了解决这个问题，可以通过执行SQL语句show processlist显示所有的活动进程，或者通过执行kill命令终结消耗太多资源的进程。 通过SELECT语句实现多表查询时，应该多次试验连接和子查询等各种方式，找出最佳的方式。在具体判断select语句执行性能时，可以通过explain查看select语句的执行情况。 使用数据储存过程比一条一条执行语句速度要快许多。 不要查找比需求还要多的数据内容，换言之，不要执行“select *”语句，除非要真正需要查询所有字段。 通过UNION关键字连接的select语句，替代包含一系列复杂OR条件的SELECT语句，可以极大的改进性能。 数据库对象索引可以改善数据检索的性能，但会损失数据CUD操作（数据插入、数据更新和删除）性能。因此不经常查询的表，最好不要创建索引。 关键字LIKE的执行效率很低，一般来说，会通过“full text”来替代关键字LIKE; 数据库中的表时不断变化的实体。一组结构优良的表，使用一段时间后，表的使用和内容就会需要进行更改，因此当初理想的优化和配置就需要改变。]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown using]]></title>
    <url>%2F2017%2F01%2F12%2FMarkdown%2F</url>
    <content type="text"><![CDATA[Markdown 和 Haroopad 介绍文档 要想写一遍自己的博客，一个好的工具往往会带来很多的便利这里我推荐本人使用的一款工具Markdown编辑器Haroopad Markdown简介 是一种轻量级标记语言，创始人为约翰·格鲁伯（John Gruber）。它允许人们“使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML(或者HTML)文档”。这种语言吸收了很多在电子邮件中已有的纯文本标记的特性。 —— 维基百科可以理解是通过类似html的语法渲染文本的工具。 正如您在阅读的这份文档，它使用简单的符号标识不同的标题，将某些文字标记为粗体或者斜体，跨平台，代码高亮，Vim 键绑定，多列模式，行号，折叠， Github Flavored Markdown 等功能~下面列举了几个高级功能，更多语法可以查看官网或者中文文档。 标题可以在标题内容前输入特定数量的井号(‘#’)来实现对应级别的HTML样式的标题(HTML提供六级标题) 特殊格式的字体在需要改变的文字片段前后 使用一对符号可以改变文字为特殊格式： 粗体 使用**文字**或者__文字__ 效果：这里请大家尤其注意！ 斜体 使用*文字*或者_文字_ 效果：会不调用父类的 析构函数 呢？ 高亮 使用 ==文字== 效果：==这里是高亮的重点==，但这里不是。 下划线 使用++文字++ 效果：如果此时的++判断结果为真++…… 删除线 使用~~文字~~ 效果：1.2的版本已经修复这个Bug？ 上角标 使用^文字^ 效果：单位圆的方程式是x^2^+y^2^=1。 下角标 使用~文字~ 效果：最常见的氧化反应是C+O~2~=CO~2~ 代码块引用代码块的时候，先空一行，按tab接着就可以编写您需要的代码了 function a(){ return(&quot;这是引用代码，亦即使代码块在浏览器显示的时候，区别对待&quot;)； } LaTeX 公式为了让haroopad支持数学公式首先需要在配置里面开启数学公式支持点击文件-&gt;偏好设置-&gt;markdown-&gt;将数学表达式全部勾选 可以创建行内公式，例如 $$\sqrt{3x-1}+{1+x}^2$$或者块级公式： $$x = \dfrac{-b \pm \sqrt{b^2 - 4ac}}{2a}$$ 表格Haroopad中绘制表格的语法如下: 效果如下: 姓名 性别 年龄 张三 男 20 李四 女 20 流程图Haroopad支持 mermaid 扩展。Mermaid是一套绘图的符号语言扩展，支持绘制各种关系图，序列图 Haroopad中mermaid绘图以 ~~~mermaid 单独一行开始，以 ~~~ 单独一行结束。 其中graph TD指定绘图方向是从上而下 改为graph LR则是从左至右 绘制流程图的语法如下： 效果如下: Mermaid扩展还支持其它绘图方式，以及调整绘图样式，具体见绘图介绍 12345678910111213141516171819graph TD; subgraph 子图; a1[矩形]; a2&gt;旗帜形]; a3(圆角方形); end; subgraph 第二个子图; b1((圆形)); b2&#123;斜方形&#125;; end; a1--&gt;|实线箭头|a2; a2--&gt;a1; a2-.-&gt;|虚线箭头|a3; a3-.-&gt;a2; a3==&gt;|加粗箭头|a1; a1==&gt;a3; b1---b2; b2---|实线无箭头|b1; a1--&gt;b1; 时序图 ~~~mermaid sequenceDiagram Alice->>Bob: Hello Bob, how are you? alt is sick Bob->>Alice: Not so good :( else is well Bob->>Alice: Feeling fresh like a daisy end opt Extra response Bob->>Alice: Thanks for asking end ~~~ 复选框（任务清单）使用 - [ ] 和 - [x] 语法可以创建复选框，实现 todo-list 等功能。Haroopad扩展支持tasklist，语法如下： [x] a [ ] b [ ] c [ ] d **目前支持尚不完全，在编辑器勾选复选框是无效、不能同步的 ###兼容HTML 一些 HTML 区块元素――比如 &lt;div&gt;、&lt;table&gt;、&lt;pre&gt;、&lt;p&gt; 等标签，需在标签前后加上空行，且标签本身不能缩进 在HTML里面的Markdown是不被解析的 在Markdown里面可以是直接空格+enter键换行，也可以是使用&lt;br/&gt;标签进行换行 使用标签换行的方法是在需要换行的地方键入两个空格，回车之后加上&lt;br/&gt;标签即可语法示例：效果显示： 我要 在第二个字换行 区块引用，直接在文本前面增加&gt;符号即可（使用不同数量的&gt;符号可以进行引用的嵌套，并且还支持Markdown语法） 段落和换行 你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。 链接（行内式和参考式） 行内式语法加效果This is [an example](http://example.com/ &quot;Title&quot;) inline link.This is an example inline link. 参考式语法加效果This is [an example] [id] reference-style link.This is [an example][id] reference-style link. 强调(在需要强调的文字两边加上*或者_字符) 反引号` 起到保护不被解析的作用 图片（行内式和参考式） ![Alt text](/path/to/img.jpg)![Alt text](/path/to/img.jpg &quot;Optional title&quot;)[id]: url/to/image &quot;Optional title attribute&quot; 自动链接Markdown 支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用尖括号包起来， Markdown 就会自动把它转成链接。一般网址的链接文字就和链接地址一样 总结 由于其简单易用，Markdown在社区已经越来越流行。甚至有些项目将自动化测试用例都用markdown语法来写，可以直接发布给客户当作说明文档，执行的时候靠一段解释代码将其翻译成目标语言执行，真的做到测试即文档。而Haroopad是一款非常强大的markdown编辑器，它内置的很多mardown扩展都是为了方便程序员，避免了大家到处寻找插件自行配制的繁琐。到目前为止haroopad是我找到的最好用的markdown编辑器，这篇文档就是用haroopad撰写。最后在支持如此多的特性后，haroopad依然非常轻量！ 希望Haroopad同样适合你！]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据类型--List（列表）]]></title>
    <url>%2F2017%2F01%2F07%2FRedis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B--List%EF%BC%88%E5%88%97%E8%A1%A8%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Redis对链表（linked-list）结构的支持使得它在键值存储的世界中独树一帜。链表上的每个节点包含一个字符串。文档目前描述的内容以 Redis 2.8 版本为准。结构的读写能力： 从链表的两端推入或者弹出元素 根据偏移量对链表进行修剪（trim） 读取单个或者多个元素 根据值查找或者移除元素 LSETLSET key index value 将列表 key 下标为 index 的元素的值设置为 value 。 当 index 参数超出范围，或对一个空列表( key 不存在)进行 LSET 时，返回一个错误。 可用版本版本&gt;= 1.0.0 时间复杂度对头元素或尾元素进行 LSET 操作，复杂度为 O(1)。其他情况下，为 O(N)， N 为列表的长度。 返回值操作成功返回 ok ，否则返回错误信息。 示例12345678910111213141516171819# 对空列表(key 不存在)进行 LSETredis&gt; EXISTS list(integer) 0redis&gt; LSET list 0 item(error) ERR no such key# 对非空列表进行 LSETredis&gt; LPUSH job &quot;cook food&quot;(integer) 1redis&gt; LRANGE job 0 01) &quot;cook food&quot;redis&gt; LSET job 0 &quot;play game&quot;OKredis&gt; LRANGE job 0 01) &quot;play game&quot;# index 超出范围redis&gt; LLEN list # 列表长度为 1(integer) 1redis&gt; LSET list 3 &apos;out of range&apos;(error) ERR index out of range LINDEXLINDEX key index 返回列表 key 中，下标为 index 的元素。 下标(index)参数 start 和 stop 都以 0 为底，也就是说，以 0 表示列表的第一个元素，以 1 表示列表的第二个元素，以此类推。 你也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。 如果 key 不是列表类型，返回一个错误。 可用版本版本&gt;= 1.0.0 时间复杂度O(N)， N 为到达下标 index 过程中经过的元素数量。因此，对列表的头元素和尾元素执行 LINDEX 命令，复杂度为O(1)。 返回值列表中下标为 index 的元素。如果 index 参数的值不在列表的区间范围内(out of range)，返回 nil 。 示例12345678910redis&gt; LPUSH mylist &quot;World&quot;(integer) 1redis&gt; LPUSH mylist &quot;Hello&quot;(integer) 2redis&gt; LINDEX mylist 0&quot;Hello&quot;redis&gt; LINDEX mylist -1&quot;World&quot;redis&gt; LINDEX mylist 3 # index不在 mylist 的区间范围内(nil) LINSERTLINSERT key BEFORE|AFTER pivot value 将值 value 插入到列表 key 当中，位于值 pivot 之前或之后。 当 pivot 不存在于列表 key 时，不执行任何操作。 当 key 不存在时， key 被视为空列表，不执行任何操作。 如果 key 不是列表类型，返回一个错误。 可用版本版本&gt;= 2.2.0 时间复杂度O(N)， N 为寻找 pivot 过程中经过的元素数量。 返回值如果命令执行成功，返回插入操作完成之后，列表的长度。如果没有找到 pivot ，返回 -1 。如果 key 不存在或为空列表，返回 0 。 示例123456789101112131415161718redis&gt; RPUSH mylist &quot;Hello&quot;(integer) 1redis&gt; RPUSH mylist &quot;World&quot;(integer) 2redis&gt; LINSERT mylist BEFORE &quot;World&quot; &quot;There&quot;(integer) 3redis&gt; LRANGE mylist 0 -11) &quot;Hello&quot;2) &quot;There&quot;3) &quot;World&quot;# 对一个非空列表插入，查找一个不存在的 pivotredis&gt; LINSERT mylist BEFORE &quot;go&quot; &quot;let&apos;s&quot;(integer) -1 # 失败# 对一个空列表执行 LINSERT 命令redis&gt; EXISTS fake_list(integer) 0redis&gt; LINSERT fake_list BEFORE &quot;nono&quot; &quot;gogogog&quot;(integer) 0 # 失败 LLENLLEN key 返回列表 key 的长度。 如果 key 不存在，则 key 被解释为一个空列表，返回 0 . 如果 key 不是列表类型，返回一个错误。 可用版本版本&gt;= 1.0.0 时间复杂度O(1) 返回值列表 key 的长度。 示例12345678910# 空列表redis&gt; LLEN job(integer) 0# 非空列表redis&gt; LPUSH job &quot;cook food&quot;(integer) 1redis&gt; LPUSH job &quot;have lunch&quot;(integer) 2redis&gt; LLEN job(integer) 2 LPOPLPOP key 移除并返回列表 key 的头元素。 可用版本版本&gt;= 1.0.0 时间复杂度O(1) 返回值列表的头元素。当 key 不存在时，返回 nil 。 示例12345678redis&gt; LLEN course(integer) 0redis&gt; RPUSH course algorithm001(integer) 1redis&gt; RPUSH course c++101(integer) 2redis&gt; LPOP course # 移除头元素&quot;algorithm001&quot; LPUSHLPUSH key value [value …] 将一个或多个值 value 插入到列表 key 的表头 如果有多个 value 值，那么各个 value 值按从左到右的顺序依次插入到表头： 比如说，对空列表 mylist 执行命令 LPUSH mylist a b c ，列表的值将是 c b a ，这等同于原子性地执行 LPUSH mylist a 、 LPUSH mylist b 和 LPUSH mylist c 三个命令。 如果 key 不存在，一个空列表会被创建并执行 LPUSH 操作。 当 key 存在但不是列表类型时，返回一个错误。 在Redis 2.4版本以前的 LPUSH 命令，都只接受单个 value 值。 可用版本版本&gt;= 1.0.0 时间复杂度O(1) 返回值执行 LPUSH 命令后，列表的长度。 示例12345678910111213141516# 加入单个元素redis&gt; LPUSH languages python(integer) 1# 加入重复元素redis&gt; LPUSH languages python(integer) 2redis&gt; LRANGE languages 0 -1 # 列表允许重复元素1) &quot;python&quot;2) &quot;python&quot;# 加入多个元素redis&gt; LPUSH mylist a b c(integer) 3redis&gt; LRANGE mylist 0 -11) &quot;c&quot;2) &quot;b&quot;3) &quot;a&quot; LPUSHXLPUSHX key value 将值 value 插入到列表 key 的表头，当且仅当 key 存在并且是一个列表。 和 LPUSH 命令相反，当 key 不存在时， LPUSHX 命令什么也不做。 可用版本版本&gt;= 2.2.0 时间复杂度O(1) 返回值LPUSHX 命令执行之后，表的长度。 示例12345678910111213# 对空列表执行 LPUSHXredis&gt; LLEN greet # greet 是一个空列表(integer) 0redis&gt; LPUSHX greet &quot;hello&quot; # 尝试 LPUSHX，失败，因为列表为空(integer) 0# 对非空列表执行 LPUSHXredis&gt; LPUSH greet &quot;hello&quot; # 先用 LPUSH 创建一个有一个元素的列表(integer) 1redis&gt; LPUSHX greet &quot;good morning&quot; # 这次 LPUSHX 执行成功(integer) 2redis&gt; LRANGE greet 0 -11) &quot;good morning&quot;2) &quot;hello&quot; LRANGELRANGE key start stop 返回列表 key 中指定区间内的元素，区间以偏移量 start 和 stop 指定。 下标(index)参数 start 和 stop 都以 0 为底，也就是说，以 0 表示列表的第一个元素，以 1 表示列表的第二个元素，以此类推。 你也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。 注意LRANGE命令和编程语言区间函数的区别假如你有一个包含一百个元素的列表，对该列表执行 LRANGE list 0 10 ，结果是一个包含11个元素的列表，这表明 stop 下标也在 LRANGE 命令的取值范围之内(闭区间)，这和某些语言的区间函数可能不一致，比如Ruby的 Range.new 、 Array#slice 和Python的 range() 函数。 超出范围的下标 超出范围的下标值不会引起错误。 如果 start 下标比列表的最大下标 end ( LLEN list 减去 1 )还要大，那么 LRANGE 返回一个空列表。 如果 stop 下标比 end 下标还要大，Redis将 stop 的值设置为 end 。 可用版本版本&gt;= 1.0.0 时间复杂度O(S+N)， S 为偏移量 start ， N 为指定区间内元素的数量。 返回值一个列表，包含指定区间内的元素。 示例123456789redis&gt; RPUSH fp-language lisp(integer) 1redis&gt; LRANGE fp-language 0 01) &quot;lisp&quot;redis&gt; RPUSH fp-language scheme(integer) 2redis&gt; LRANGE fp-language 0 11) &quot;lisp&quot;2) &quot;scheme&quot; LREMLREM key count value 根据参数 count 的值，移除列表中与参数 value 相等的元素。count 的值可以是以下几种： count &gt; 0 : 从表头开始向表尾搜索，移除与 value 相等的元素，数量为 count 。 count &lt; 0 : 从表尾开始向表头搜索，移除与 value 相等的元素，数量为 count 的绝对值。 count = 0 : 移除表中所有与 value 相等的值。 可用版本版本&gt;= 1.0.0 时间复杂度O(N)， N 为列表的长度。 返回值被移除元素的数量。因为不存在的 key 被视作空表(empty list)，所以当 key 不存在时， LREM 命令总是返回 0 。 示例12345678910111213141516171819202122232425262728293031323334353637# 先创建一个表，内容排列是# morning hello morning helllo morningredis&gt; LPUSH greet &quot;morning&quot;(integer) 1redis&gt; LPUSH greet &quot;hello&quot;(integer) 2redis&gt; LPUSH greet &quot;morning&quot;(integer) 3redis&gt; LPUSH greet &quot;hello&quot;(integer) 4redis&gt; LPUSH greet &quot;morning&quot;(integer) 5redis&gt; LRANGE greet 0 4 # 查看所有元素1) &quot;morning&quot;2) &quot;hello&quot;3) &quot;morning&quot;4) &quot;hello&quot;5) &quot;morning&quot;redis&gt; LREM greet 2 morning # 移除从表头到表尾，最先发现的两个 morning(integer) 2 # 两个元素被移除redis&gt; LLEN greet # 还剩 3 个元素(integer) 3redis&gt; LRANGE greet 0 21) &quot;hello&quot;2) &quot;hello&quot;3) &quot;morning&quot;redis&gt; LREM greet -1 morning # 移除从表尾到表头，第一个 morning(integer) 1redis&gt; LLEN greet # 剩下两个元素(integer) 2redis&gt; LRANGE greet 0 11) &quot;hello&quot;2) &quot;hello&quot;redis&gt; LREM greet 0 hello # 移除表中所有 hello(integer) 2 # 两个 hello 被移除redis&gt; LLEN greet(integer) 0 LTRIMLTRIM key start stop 对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。 举个例子，执行命令 LTRIM list 0 2 ，表示只保留列表 list 的前三个元素，其余元素全部删除。 下标(index)参数 start 和 stop 都以 0 为底，也就是说，以 0 表示列表的第一个元素，以 1 表示列表的第二个元素，以此类推。 你也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。 当 key 不是列表类型时，返回一个错误。 LTRIM 命令通常和 LPUSH 命令或 RPUSH 命令配合使用，举个例子：12LPUSH log newest_logLTRIM log 0 99 这个例子模拟了一个日志程序，每次将最新日志 newest_log 放到 log 列表中，并且只保留最新的 100 项。注意当这样使用 LTRIM 命令时，时间复杂度是O(1)，因为平均情况下，每次只有一个元素被移除。 注意LTRIM命令和编程语言区间函数的区别 假如你有一个包含一百个元素的列表 list ，对该列表执行 LTRIM list 0 10 ，结果是一个包含11个元素的列表，这表明 stop 下标也在 LTRIM 命令的取值范围之内(闭区间)，这和某些语言的区间函数可能不一致，比如Ruby的 Range.new 、 Array#slice 和Python的 range() 函数。 超出范围的下标 超出范围的下标值不会引起错误。 如果 start 下标比列表的最大下标 end ( LLEN list 减去 1 )还要大，或者 start &gt; stop ， LTRIM 返回一个空列表(因为 LTRIM 已经将整个列表清空)。 如果 stop 下标比 end 下标还要大，Redis将 stop 的值设置为 end 。 可用版本版本&gt;= 1.0.0 时间复杂度O(N)， N 为被移除的元素的数量。 返回值命令执行成功时，返回 ok 。 示例123456789101112131415161718192021222324252627282930313233343536373839# 情况 1： 常见情况， start 和 stop 都在列表的索引范围之内redis&gt; LRANGE alpha 0 -1 # alpha 是一个包含 5 个字符串的列表1) &quot;h&quot;2) &quot;e&quot;3) &quot;l&quot;4) &quot;l&quot;5) &quot;o&quot;redis&gt; LTRIM alpha 1 -1 # 删除 alpha 列表索引为 0 的元素OKredis&gt; LRANGE alpha 0 -1 # &quot;h&quot; 被删除了1) &quot;e&quot;2) &quot;l&quot;3) &quot;l&quot;4) &quot;o&quot;# 情况 2： stop 比列表的最大下标还要大redis&gt; LTRIM alpha 1 10086 # 保留 alpha 列表索引 1 至索引 10086 上的元素OKredis&gt; LRANGE alpha 0 -1 # 只有索引 0 上的元素 &quot;e&quot; 被删除了，其他元素还在1) &quot;l&quot;2) &quot;l&quot;3) &quot;o&quot;# 情况 3： start 和 stop 都比列表的最大下标要大，并且 start &lt; stopredis&gt; LTRIM alpha 10086 123321OKredis&gt; LRANGE alpha 0 -1 # 列表被清空(empty list or set)# 情况 4： start 和 stop 都比列表的最大下标要大，并且 start &gt; stopredis&gt; RPUSH new-alpha &quot;h&quot; &quot;e&quot; &quot;l&quot; &quot;l&quot; &quot;o&quot; # 重新建立一个新列表(integer) 5redis&gt; LRANGE new-alpha 0 -11) &quot;h&quot;2) &quot;e&quot;3) &quot;l&quot;4) &quot;l&quot;5) &quot;o&quot;redis&gt; LTRIM new-alpha 123321 10086 # 执行 LTRIMOKredis&gt; LRANGE new-alpha 0 -1 # 同样被清空(empty list or set) RPOPRPOP key 移除并返回列表 key 的尾元素。 可用版本版本&gt;= 1.0.0 时间复杂度O(1) 返回值列表的尾元素。当 key 不存在时，返回 nil 。 示例1234567891011redis&gt; RPUSH mylist &quot;one&quot;(integer) 1redis&gt; RPUSH mylist &quot;two&quot;(integer) 2redis&gt; RPUSH mylist &quot;three&quot;(integer) 3redis&gt; RPOP mylist # 返回被弹出的元素&quot;three&quot;redis&gt; LRANGE mylist 0 -1 # 列表剩下的元素1) &quot;one&quot;2) &quot;two&quot; RPOPLPUSHRPOPLPUSH source destination  命令 RPOPLPUSH 在一个原子时间内，执行以下两个动作： 将列表 source 中的最后一个元素(尾元素)弹出，并返回给客户端。 将 source 弹出的元素插入到列表 destination ，作为 destination 列表的的头元素。举个例子，你有两个列表 source 和 destination ， source 列表有元素 a, b, c ， destination 列表有元素 x, y, z ，执行 RPOPLPUSH source destination 之后， source 列表包含元素 a, b ， destination 列表包含元素 c, x, y, z ，并且元素 c 会被返回给客户端。 如果 source 不存在，值 nil 被返回，并且不执行其他动作。 如果 source 和 destination 相同，则列表中的表尾元素被移动到表头，并返回该元素，可以把这种特殊情况视作列表的旋转(rotation)操作。 可用版本版本&gt;= 1.2.0 时间复杂度O(1) 返回值被弹出的元素。 示例123456789101112131415161718192021222324252627282930313233343536373839404142# source 和 destination 不同redis&gt; LRANGE alpha 0 -1 # 查看所有元素1) &quot;a&quot;2) &quot;b&quot;3) &quot;c&quot;4) &quot;d&quot;redis&gt; RPOPLPUSH alpha reciver # 执行一次 RPOPLPUSH 看看&quot;d&quot;redis&gt; LRANGE alpha 0 -11) &quot;a&quot;2) &quot;b&quot;3) &quot;c&quot;redis&gt; LRANGE reciver 0 -11) &quot;d&quot;redis&gt; RPOPLPUSH alpha reciver # 再执行一次，证实 RPOP 和 LPUSH 的位置正确&quot;c&quot;redis&gt; LRANGE alpha 0 -11) &quot;a&quot;2) &quot;b&quot;redis&gt; LRANGE reciver 0 -11) &quot;c&quot;2) &quot;d&quot;# source 和 destination 相同redis&gt; LRANGE number 0 -11) &quot;1&quot;2) &quot;2&quot;3) &quot;3&quot;4) &quot;4&quot;redis&gt; RPOPLPUSH number number&quot;4&quot;redis&gt; LRANGE number 0 -1 # 4 被旋转到了表头1) &quot;4&quot;2) &quot;1&quot;3) &quot;2&quot;4) &quot;3&quot;redis&gt; RPOPLPUSH number number&quot;3&quot;redis&gt; LRANGE number 0 -1 # 这次是 3 被旋转到了表头1) &quot;3&quot;2) &quot;4&quot;3) &quot;1&quot;4) &quot;2&quot; RPUSHRPUSH key value [value …] 将一个或多个值 value 插入到列表 key 的表尾(最右边)。 如果有多个 value 值，那么各个 value 值按从左到右的顺序依次插入到表尾：比如对一个空列表 mylist 执行 RPUSH mylist a b c ，得出的结果列表为 a b c ，等同于执行命令 RPUSH mylist a 、 RPUSH mylist b 、 RPUSH mylist c 。 如果 key 不存在，一个空列表会被创建并执行 RPUSH 操作。 当 key 存在但不是列表类型时，返回一个错误。 在 Redis 2.4 版本以前的 RPUSH 命令，都只接受单个 value 值。 可用版本版本&gt;= 1.0.0 时间复杂度O(1) 返回值执行 RPUSH 操作后，表的长度。 示例12345678910111213141516# 添加单个元素redis&gt; RPUSH languages c(integer) 1# 添加重复元素redis&gt; RPUSH languages c(integer) 2redis&gt; LRANGE languages 0 -1 # 列表允许重复元素1) &quot;c&quot;2) &quot;c&quot;# 添加多个元素redis&gt; RPUSH mylist a b c(integer) 3redis&gt; LRANGE mylist 0 -11) &quot;a&quot;2) &quot;b&quot;3) &quot;c&quot; RPUSHXRPUSHX key value 将值 value 插入到列表 key 的表尾，当且仅当 key 存在并且是一个列表。 和 RPUSH 命令相反，当 key 不存在时， RPUSHX 命令什么也不做。 可用版本版本&gt;= 2.2.0 时间复杂度O(1) 返回值RPUSHX 命令执行之后，表的长度。 示例12345678910111213# key不存在redis&gt; LLEN greet(integer) 0redis&gt; RPUSHX greet &quot;hello&quot; # 对不存在的 key 进行 RPUSHX，PUSH 失败。(integer) 0# key 存在且是一个非空列表redis&gt; RPUSH greet &quot;hi&quot; # 先用 RPUSH 插入一个元素(integer) 1redis&gt; RPUSHX greet &quot;hello&quot; # greet 现在是一个列表类型，RPUSHX 操作成功。(integer) 2redis&gt; LRANGE greet 0 -11) &quot;hi&quot;2) &quot;hello&quot; BLPOPBLPOP key [key …] timeout BLPOP 是列表的阻塞式(blocking)弹出原语。 它是 LPOP 命令的阻塞版本，当给定列表内没有任何元素可供弹出的时候，连接将被 BLPOP 命令阻塞，直到等待超时或发现可弹出元素为止。 当给定多个 key 参数时，按参数 key 的先后顺序依次检查各个列表，弹出第一个非空列表的头元素。 非阻塞行为 当 BLPOP 被调用时，如果给定 key 内至少有一个非空列表，那么弹出遇到的第一个非空列表的头元素，并和被弹出元素所属的列表的名字一起，组成结果返回给调用者。 当存在多个给定 key 时， BLPOP 按给定 key 参数排列的先后顺序，依次检查各个列表。 假设现在有 job 、 command 和 request 三个列表，其中 job 不存在， command 和 request 都持有非空列表。考虑以下命令：1BLPOP job command request 0  BLPOP 保证返回的元素来自 command ，因为它是按”查找 job -&gt; 查找 command -&gt; 查找 request “这样的顺序，第一个找到的非空列表。 123456789redis&gt; DEL job command request # 确保key都被删除(integer) 0redis&gt; LPUSH command &quot;update system...&quot; # 为command列表增加一个值(integer) 1redis&gt; LPUSH request &quot;visit page&quot; # 为request列表增加一个值(integer) 1redis&gt; BLPOP job command request 0 # job 列表为空，被跳过，紧接着 command 列表的第一个元素被弹出。1) &quot;command&quot; # 弹出元素所属的列表2) &quot;update system...&quot; # 弹出元素所属的值 阻塞行为 如果所有给定 key 都不存在或包含空列表，那么 BLPOP 命令将阻塞连接，直到等待超时，或有另一个客户端对给定 key 的任意一个执行 LPUSH 或 RPUSH 命令为止。  超时参数 timeout 接受一个以秒为单位的数字作为值。超时参数设为 0 表示阻塞时间可以无限期延长(block indefinitely) 。1234567891011redis&gt; EXISTS job # 确保两个 key 都不存在(integer) 0redis&gt; EXISTS command(integer) 0redis&gt; BLPOP job command 300 # 因为key一开始不存在，所以操作会被阻塞，直到另一客户端对 job 或者 command 列表进行 PUSH 操作。1) &quot;job&quot; # 这里被 push 的是 job2) &quot;do my home work&quot; # 被弹出的值(26.26s) # 等待的秒数redis&gt; BLPOP job command 5 # 等待超时的情况(nil)(5.66s) # 等待的秒数 相同的key被多个客户端同时阻塞  相同的 key 可以被多个客户端同时阻塞。 不同的客户端被放进一个队列中，按『先阻塞先服务』(first-BLPOP，first-served)的顺序为 key 执行 BLPOP 命令。在MULTI/EXEC事务中的BLPOPBLPOP 可以用于流水线(pipline,批量地发送多个命令并读入多个回复)，但把它用在 MULTI / EXEC 块当中没有意义。因为这要求整个服务器被阻塞以保证块执行时的原子性，该行为阻止了其他客户端执行 LPUSH 或 RPUSH 命令。 因此，一个被包裹在 MULTI / EXEC 块内的 BLPOP 命令，行为表现得就像 LPOP 一样，对空列表返回 nil ，对非空列表弹出列表元素，不进行任何阻塞操作。12345678910111213141516171819# 对非空列表进行操作redis&gt; RPUSH job programming(integer) 1redis&gt; MULTIOKredis&gt; BLPOP job 30QUEUEDredis&gt; EXEC # 不阻塞，立即返回1) 1) &quot;job&quot; 2) &quot;programming&quot;# 对空列表进行操作redis&gt; LLEN job # 空列表(integer) 0redis&gt; MULTIOKredis&gt; BLPOP job 30QUEUEDredis&gt; EXEC # 不阻塞，立即返回1) (nil) 可用版本版本&gt;= 2.0.0 时间复杂度O(1) 返回值如果列表为空，返回一个 nil 。否则，返回一个含有两个元素的列表，第一个元素是被弹出元素所属的 key ，第二个元素是被弹出元素的值。 BRPOPBRPOP key [key …] timeout BRPOP 是列表的阻塞式(blocking)弹出原语。 它是 RPOP 命令的阻塞版本，当给定列表内没有任何元素可供弹出的时候，连接将被 BRPOP 命令阻塞，直到等待超时或发现可弹出元素为止。 当给定多个 key 参数时，按参数 key 的先后顺序依次检查各个列表，弹出第一个非空列表的尾部元素。 关于阻塞操作的更多信息，请查看 BLPOP 命令， BRPOP 除了弹出元素的位置和 BLPOP 不同之外，其他表现一致。 可用版本版本&gt;= 2.0.0 时间复杂度O(1) 返回值假如在指定时间内没有任何元素被弹出，则返回一个 nil 和等待时长。反之，返回一个含有两个元素的列表，第一个元素是被弹出元素所属的 key ，第二个元素是被弹出元素的值。 示例123456789redis&gt; LLEN course(integer) 0redis&gt; RPUSH course algorithm001(integer) 1redis&gt; RPUSH course c++101(integer) 2redis&gt; BRPOP course 301) &quot;course&quot; # 弹出元素的 key2) &quot;c++101&quot; # 弹出元素的值 BRPOPLPUSHBRPOPLPUSH source destination timeout BRPOPLPUSH 是 RPOPLPUSH 的阻塞版本，当给定列表 source 不为空时， BRPOPLPUSH 的表现和 RPOPLPUSH 一样。 当列表 source 为空时， BRPOPLPUSH 命令将阻塞连接，直到等待超时，或有另一个客户端对 source 执行 LPUSH 或 RPUSH 命令为止。 超时参数 timeout 接受一个以秒为单位的数字作为值。超时参数设为 0 表示阻塞时间可以无限期延长(block indefinitely) 。 可用版本版本&gt;= 2.2.0 时间复杂度O(1) 返回值假如在指定时间内没有任何元素被弹出，则返回一个 nil 和等待时长。反之，返回一个含有两个元素的列表，第一个元素是被弹出元素的值，第二个元素是等待时长。 示例123456789101112# 非空列表redis&gt; BRPOPLPUSH msg reciver 500&quot;hello moto&quot; # 弹出元素的值(3.38s) # 等待时长redis&gt; LLEN reciver(integer) 1redis&gt; LRANGE reciver 0 01) &quot;hello moto&quot;# 空列表redis&gt; BRPOPLPUSH msg reciver 1(nil)(1.34s)]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据类型--Hash（哈希表）]]></title>
    <url>%2F2017%2F01%2F07%2FRedis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B--Hash%EF%BC%88%E5%93%88%E5%B8%8C%E8%A1%A8%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Redis的散列可以存储多个键值对之间的映射。和字符串一样，散列存储的值既可以是字符串又可以是数字值，并且用户同样子可以对散列存储的数字执行自增操作或者自减操作。结构的读写： 添加、获取、移除单个键值对 获取所有的键值对 HDELHDEL key field [field …]  删除哈希表 key 中的一个或多个指定域，不存在的域将被忽略。 在Redis2.4以下的版本里， HDEL 每次只能删除单个域，如果你需要在一个原子时间 内删除多个域，请将命令包含在 MULTI / EXEC 块内。 可用版本版本&gt;= 2.0.0 时间复杂度O(N)， N 为要删除的域的数量。 返回值被成功移除的域的数量，不包括被忽略的域。 示例12345678910111213141516171819202122# 测试数据redis&gt; HGETALL abbr1) &quot;a&quot;2) &quot;apple&quot;3) &quot;b&quot;4) &quot;banana&quot;5) &quot;c&quot;6) &quot;cat&quot;7) &quot;d&quot;8) &quot;dog&quot;# 删除单个域redis&gt; HDEL abbr a(integer) 1# 删除不存在的域redis&gt; HDEL abbr not-exists-field(integer) 0# 删除多个域redis&gt; HDEL abbr b c(integer) 2redis&gt; HGETALL abbr1) &quot;d&quot;2) &quot;dog&quot; HEXISTSHEXISTS key field  查看哈希表 key 中，给定域 field 是否存在。 可用版本版本&gt;= 2.0.0 时间复杂度O(1) 返回值如果哈希表含有给定域，返回 1 。如果哈希表不含有给定域，或 key 不存在，返回 0 。 示例123456redis&gt; HEXISTS phone myphone(integer) 0redis&gt; HSET phone myphone nokia-1110(integer) 1redis&gt; HEXISTS phone myphone(integer) 1 HGETHGET key field  返回哈希表 key 中给定域 field 的值。 可用版本版本&gt;= 2.0.0 时间复杂度O(1) 返回值给定域的值。当给定域不存在或是给定 key 不存在时，返回 nil 。 示例12345678# 域存在redis&gt; HSET site redis redis.com(integer) 1redis&gt; HGET site redis&quot;redis.com&quot;# 域不存在redis&gt; HGET site mysql(nil) HGETALLHGETALL key  返回哈希表 key 中，所有的域和值。 在返回值里，紧跟每个域名(field name)之后是域的值(value)，所以返回值的长度是哈希表大小的两倍。 可用版本版本&gt;= 2.0.0 时间复杂度O(N)， N 为哈希表的大小。 ####返回值以列表形式返回哈希表的域和域的值。若 key 不存在，返回空列表。 示例123456789redis&gt; HSET people jack &quot;Jack Sparrow&quot;(integer) 1redis&gt; HSET people gump &quot;Forrest Gump&quot;(integer) 1redis&gt; HGETALL people1) &quot;jack&quot; # 域2) &quot;Jack Sparrow&quot; # 值3) &quot;gump&quot;4) &quot;Forrest Gump&quot; HINCRBYHINCRBY key field increment  为哈希表 key 中的域 field 的值加上增量 increment 。 增量也可以为负数，相当于对给定域进行减法操作。 如果 key 不存在，一个新的哈希表被创建并执行 HINCRBY 命令。 如果域 field 不存在，那么在执行命令前，域的值被初始化为 0 。 对一个储存字符串值的域 field 执行 HINCRBY 命令将造成一个错误。 本操作的值被限制在 64 位(bit)有符号数字表示之内。 可用版本版本&gt;= 2.0.0 时间复杂度O(1) ####返回值执行 HINCRBY 命令之后，哈希表 key 中域 field 的值。 示例1234567891011121314151617181920212223# increment 为正数redis&gt; HEXISTS counter page_view # 对空域进行设置(integer) 0redis&gt; HINCRBY counter page_view 200(integer) 200redis&gt; HGET counter page_view&quot;200&quot;# increment 为负数redis&gt; HGET counter page_view&quot;200&quot;redis&gt; HINCRBY counter page_view -50(integer) 150redis&gt; HGET counter page_view&quot;150&quot;# 尝试对字符串值的域执行HINCRBY命令redis&gt; HSET myhash string hello,world # 设定一个字符串值(integer) 1redis&gt; HGET myhash string&quot;hello,world&quot;redis&gt; HINCRBY myhash string 1 # 命令执行失败，错误。(error) ERR hash value is not an integerredis&gt; HGET myhash string # 原值不变&quot;hello,world&quot; HINCRBYFLOATHINCRBYFLOAT key field increment  为哈希表 key 中的域 field 加上浮点数增量 increment 。 如果哈希表中没有域 field ，那么 HINCRBYFLOAT 会先将域 field 的值设为 0 ，然后再执行加法操作。 如果键 key 不存在，那么 HINCRBYFLOAT 会先创建一个哈希表，再创建域 field ，最后再执行加法操作。 当以下任意一个条件发生时，返回一个错误： 域 field 的值不是字符串类型(因为 redis 中的数字和浮点数都以字符串的形式保存，所以它们都属于字符串类型） 域 field 当前的值或给定的增量 increment 不能解释(parse)为双精度浮点数(double precisionfloating point number) HINCRBYFLOAT 命令的详细功能和 INCRBYFLOAT 命令类似，请查看 INCRBYFLOAT 命令获取更多相关信息。 可用版本版本&gt;= 2.6.0 时间复杂度O(1) 返回值执行加法操作之后 field 域的值。 示例1234567891011121314151617181920212223242526272829# 值和增量都是普通小数redis&gt; HSET mykey field 10.50(integer) 1redis&gt; HINCRBYFLOAT mykey field 0.1&quot;10.6&quot;# 值和增量都是指数符号redis&gt; HSET mykey field 5.0e3(integer) 0redis&gt; HINCRBYFLOAT mykey field 2.0e2&quot;5200&quot;# 对不存在的键执行 HINCRBYFLOATredis&gt; EXISTS price(integer) 0redis&gt; HINCRBYFLOAT price milk 3.5&quot;3.5&quot;redis&gt; HGETALL price1) &quot;milk&quot;2) &quot;3.5&quot;# 对不存在的域进行 HINCRBYFLOATredis&gt; HGETALL price1) &quot;milk&quot;2) &quot;3.5&quot;redis&gt; HINCRBYFLOAT price coffee 4.5 # 新增 coffee 域&quot;4.5&quot;redis&gt; HGETALL price1) &quot;milk&quot;2) &quot;3.5&quot;3) &quot;coffee&quot;4) &quot;4.5&quot; HKEYSHKEYS key  返回哈希表 key 中的所有域。 可用版本版本&gt;= 2.0.0 时间复杂度O(N)， N 为哈希表的大小。 返回值一个包含哈希表中所有域的表。当 key 不存在时，返回一个空表。 示例1234567891011121314151617181920212223242526272829# 哈希表非空redis&gt; HMSET website google www.google.com yahoo www.yahoo.comOKredis&gt; HKEYS website1) &quot;google&quot;2) &quot;yahoo&quot;# 空哈希表/key不存在redis&gt; EXISTS fake_key(integer) 0redis&gt; HKEYS fake_key(empty list or set)HLENHLEN key返回哈希表 key 中域的数量。时间复杂度：O(1)返回值：哈希表中域的数量。当 key 不存在时，返回 0 。redis&gt; HSET db redis redis.com(integer) 1redis&gt; HSET db mysql mysql.com(integer) 1redis&gt; HLEN db(integer) 2redis&gt; HSET db mongodb mongodb.org(integer) 1redis&gt; HLEN db(integer) 3 HMGETHMGET key field [field …]  返回哈希表 key 中，一个或多个给定域的值。 如果给定的域不存在于哈希表，那么返回一个 nil 值。 因为不存在的 key 被当作一个空哈希表来处理，所以对一个不存在的 key 进行 HMGET 操作将返回一个只带有 nil 值的表。 可用版本版本&gt;= 2.0.0 时间复杂度O(N)， N 为给定域的数量。 返回值一个包含多个给定域的关联值的表，表值的排列顺序和给定域参数的请求顺序一样。 示例123456redis&gt; HMSET pet dog &quot;doudou&quot; cat &quot;nounou&quot; # 一次设置多个域OKredis&gt; HMGET pet dog cat fake_pet # 返回值的顺序和传入参数的顺序一样1) &quot;doudou&quot;2) &quot;nounou&quot;3) (nil) # 不存在的域返回nil值 HMSETHMSET key field value [field value …]  同时将多个 field-value (域-值)对设置到哈希表 key 中。 此命令会覆盖哈希表中已存在的域。 如果 key 不存在，一个空哈希表被创建并执行 HMSET 操作。 可用版本版本&gt;= 2.0.0 时间复杂度O(N)， N 为 field-value 对的数量。 返回值如果命令执行成功，返回 OK 。当 key 不是哈希表(hash)类型时，返回一个错误。 示例123456redis&gt; HMSET website google www.google.com yahoo www.yahoo.comOKredis&gt; HGET website google&quot;www.google.com&quot;redis&gt; HGET website yahoo&quot;www.yahoo.com&quot; HSETHSET key field value  将哈希表 key 中的域 field 的值设为 value 。 如果 key 不存在，一个新的哈希表被创建并进行 HSET 操作。 如果域 field 已经存在于哈希表中，旧值将被覆盖。 可用版本版本&gt;= 2.0.0 时间复杂度O(1) 返回值如果 field 是哈希表中的一个新建域，并且值设置成功，返回 1 。如果哈希表中域 field 已经存在且旧值已被新值覆盖，返回 0 。 示例1234redis&gt; HSET website google &quot;www.g.cn&quot; # 设置一个新域(integer) 1redis&gt; HSET website google &quot;www.google.com&quot; # 覆盖一个旧域(integer) 0 HSETNXHSETNX key field value  将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在。 若域 field 已经存在，该操作无效。 如果 key 不存在，一个新哈希表被创建并执行 HSETNX 命令。 可用版本版本&gt;= 2.0.0 时间复杂度O(1) 返回值设置成功，返回 1 。如果给定域已经存在且没有操作被执行，返回 0 。 示例1234redis&gt; HSETNX nosql key-value-store redis(integer) 1redis&gt; HSETNX nosql key-value-store redis # 操作无效，域 key-value-store 已存在(integer) 0 HVALSHVALS key  返回哈希表 key 中所有域的值。 可用版本版本&gt;= 2.0.0 时间复杂度O(N)， N 为哈希表的大小。 返回值一个包含哈希表中所有值的表。当 key 不存在时，返回一个空表。 示例1234567891011# 非空哈希表redis&gt; HMSET website google www.google.com yahoo www.yahoo.comOKredis&gt; HVALS website1) &quot;www.google.com&quot;2) &quot;www.yahoo.com&quot;# 空哈希表/不存在的keyredis&gt; EXISTS not_exists(integer) 0redis&gt; HVALS not_exists(empty list or set) HSCANHSCAN key cursor [MATCH pattern] [COUNT count] 具体信息请参考 SCAN 命令。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[了解如何搭建自己的hexo博客]]></title>
    <url>%2F2016%2F12%2F11%2F%E4%BA%86%E8%A7%A3%E5%A6%82%E4%BD%95%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84hexo%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[前段时间在朋友的帮助下，也找过很多资料来搭建自己的hexo博客，之前也就是在简述上写自己的博客文章，说真的，自己如果懂得如何搭建博客来写，更有些自豪感。废话就不多说了，下面就来了解一下hexo以及如何搭建一个属于自己的hexo博客。 了解hexohexo文档给出的hexo定义是：Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 hexo出自台湾的tommy351之手，一个基于Node.js的静态博客程序，可以很方便的生成静态网页托管于github、gitcafe和Heroku，类似于jekyll，但Jekyll需要的git命令稍有点繁琐。 重要的是hexo是免费的，可以在各个平台上搭建，如GitHub、GitCafe、coding、七牛。可以快速渲染自己编写的markdown文件。 hexo的依赖 搭建nodejs环境 （必须） node官网 git （必须） windows 下载：git linux 下载：12$ sudo apt-get update$ sudo apt-get install git coding（ 必须 ，可以用github来搭建） 域名（个性化）域名只是让你的博客访问更有个性化，coding默认的访问博客的地址是 http://your-coding-name.coding.me/your-repo-name ，在github中的访问地址是：https://your-github-name.github.io/your-repo-name/ 编写hexo可以使用Atom，我挺喜欢这款编辑器的markdown预览功能 安装hexo安装hexo，打开git bash操作界面（cmd界面也可以）1npm install -g hexo 初始化blog项目，并安装依赖1234mkdir blogcd bloghexo initnpm install 运行hexo，在本地中预览 - 全称（hexo server）1hexo s 直接输入http://localhost:4000/就可以看到本地部署的hexo 紧接着就创建自己的coding项目，把本地的hexo放到远程的coding上运行。 本人是把hexo放在master分支，博文放到coding-pages分支中。 在coding中创建博客项目创建博客项目 这时写上项目名以及项目的描述。 绑定ssh检查本地是否存在ssh key：1$ cd ~/.ssh 生成ssh如果本地没有，那么就在本地中生成ssh证书，生成的证书中有两个文件，一个是私钥，一个是公钥。1ssh-keygen -t rsa -C &quot;邮箱地址&quot; 执行以上代码，会弹出是否需要输入密码，输不输入密码关系不大，这里选择不输入密码。 把公钥(id_rsa.pub)的内容拷贝到coding账户 -&gt; SSH公钥 -&gt; 新增公钥的内容中去，写上公钥名字，以及将公钥的有效期的永久有效勾上 测试对于coding，git@git.coding.net（在windows中是没有ssh指令，可以使用git bash命令窗口就能找到）1$ ssh -T git@git.coding.net 对于github，git@github.com不需要修改1$ ssh -T git@github.com 会出现类以下的反馈123The authenticity of host &apos;github.com (207.97.227.239)&apos; can&apos;t be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)? 点击yes，就ok了。 在hexo中配置与coding相连打开你在本地创建的项目blog，找到_config.yml,打开配置如下，将内容推送到coding-pages分支中1234deploy: type: git repo: git@git.coding.net:your-coding-name/your-repo-name.git branch: coding-pages 在你的博客项目blog，初始化为git仓库安装完git，需要配置以下信息12$ git config --global user.name &quot;username&quot; //用户名$ git config --global user.email &quot;youremail&quot; //填写自己的邮箱 初始化项目1git init 选择要添加进仓库的文件：1git add . 如果你想分享这个文件夹里所有代码，就在add后面加“.”，如果指定某个文件，只需把“.”改为文件名即可。添加进入仓库：1git commit -m &quot;first commit&quot; -m后面的参数，表示说明，将代码提交到GitHub后，将会给出一个提交说明，表明这是我哪次提交的。所有工作已准备充分，现在开始提交，还是几条命令：123456// 添加coding源git remote add origin git@git.coding.net:your-coding-name/your-repo-name.git// 执行 git push 没有指定分支时，只有当前分支会被 push 到你使用 git pull 获取的代码。git config --global push.default simple// 上传本地项目代码到master分支git push -u origin master 开启Pages服务及配置域名域名的使用购买域名后，可以配置子域名来绑定hexo博客 将记录类型设置成CNAME 主机记录，你喜欢 记录值设置成，pages.coding.me设置成那样就可以了 Pages里添加域名访问呢进入刚才创建的项目中，点击左侧的代码，再进入Pages服务页面中，点击立即开启，部署来源选择coding-pages分支。 好像是找不到coding-pages分支的，那么就要手动创建一个coding-pages分支，然后指定分支开启服务。 在自定义域名里，可以填写自己已经注册的域名，这样就可以通过自己的域名去访问你的博客 开始使用以上配置好后，使用域名就可以访问了 新建文章1hexo n &quot;postName&quot; 相当于 hexo new &quot;postName&quot; 新建页面1hexo n page &quot;pageName&quot; 相当于hexo new page &quot;pageName&quot; 生成静态页面至public目录1hexo g 相当于hexo generate 开启预览本地博客服务，地址为http://localhost:4000/1hexo s 相当于hexo server 将.deploy目录部署到远程项目中1hexo d 相当于hexo deplog 安装hexo-deployer-git插件 - 第一次使用要安装这个插件1npm install hexo-deployer-git --save 清除缓存文件 (db.json) 和已生成的静态文件 (public)1hexo clean 查看帮助1hexo h 相当于hexo help 查看hexo的版本1hexo v 相当于hexo version 一般你写好自己的文章或配置好自己的设置，使用以下命令即可123hexo cleanhexo ghexo d 主题 - 我这个主题为Next下载Next主题12$ cd your-hexo-site`$ git clone https://github.com/iissnan/hexo-theme-next themes/next 修改配置文件找到根目录下的_config.yml文件，修改theme使支持12345# Extensions## Plugins: http://hexo.io/plugins/## Themes: http://hexo.io/themes/#theme: landscapetheme: next 选择Scheme为Mist，自己觉得这个样式会比较好看找到主题配置文件，blog/themes/next目录下的_config.yml文件1234# Schemes#scheme: Musescheme: Mist#scheme: Pisces 添加tags标签，与页面中的tag对应1hexo new page &quot;tags&quot; 修改/source/tags/index.md文件1234title: tagsdate: 2016-12-04 09:06:02type: &quot;tags&quot;--- 其他配置配置域名与hexo关联前面配置的是，域名与coding之间的关联。 找到根目录的_config.yml文件123456# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: 填写你的域名地址root: /permalink: :year/:month/:day/:title/permalink_defaults: 配置头像在根目录的_config.yml，me.jpg需要放到/blog/source/images目录下12# 头像avatar: /images/me.jpg 配置多说评论在根目录下的配置文件_config.yml添加字段1duoshuo_shortname: commit commit为你注册多说域名的子域名，就如你多说的域名为：http://commit.duoshuo.com 使你的菜单栏显示中文在根目录下的配置文件_config.yml找到language字段，修改为zh-Hans12# Sitelanguage: zh-Hans 配置社交链接12345678# Social linkssocial: GitHub: git地址# Social Iconssocial_icons: enable: true # Icon Mappings GitHub: github 如果想添加其他社交链接，可以查看官方文档 配置hexo插件添加网站地图12npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save 在站点配置文件_config.yml中添加如下代码12345# hexo sitemapsitemap:path: sitemap.xmlbaidusitemap:path: baidusitemap.xml 配置成功后，会生成在public目录下生成sitemap.xml 和 baidusitemap.xml，前者适合提交给谷歌搜素引擎，后者适合提交百度搜索引擎。 其次，在 robots.txt 中添加下面的一段代码：12Sitemap: http://blog.tangxiaozhu.com/sitemap.xmlSitemap: http://blog.tangxiaozhu.com/baidusitemap.xml 将robots.txt 放置在\source 目录下。 参考hexo官方文档next主题文档使用 Hexo 搭建博客的深度优化与定制Hexo搭建GitHub博客（三）- NexT主题配置使用HEXO+Github,搭建属于自己的博客]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7上安装JDK8与Tomcat8]]></title>
    <url>%2F2016%2F09%2F12%2FCentOS7%E5%AE%89%E8%A3%85Java8%E4%BB%A5%E5%8F%8ATomcat8%2F</url>
    <content type="text"><![CDATA[CentOS7 安装 Java 8 以及Tomcat8过程如下。 安装 Java8准备更新软件1yum update 查看是否已经安装了javajava -version 如果出现如图，说明没有安装 如果以前已经安装就卸载12345#查看内置的JDKrpm -qa | grep jdk#卸载内置的JDKyum remove java-1.6.0-openjdkyum remove java-1.7.0-openjdk 检查是否安装wget下载工具如果输入wget 显示如下： 说明已经安装了wget了，如果提示没有 wget 命令，那么必须先安装 wget 如下：yum install wget 采用离线下载的方式下载wget.rpm下载wget.rpm 上传到Linux服务器http://mirrors.163.com/centos/7.2.1511/os/x86_64/Packages/wget-1.14-10.el7_0.1.x86_64.rpm 安装wget12#安装rpm -ivh wget-1.14-10.el7_0.1.x86_64.rpm 下载java8RPM安装在线下载 RPM注意：如果地址无效，去download.oracle.com找相应版本地址替代。12345### For 32 bitwget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;http://download.oracle.com/otn-pub/java/jdk/8u91-b14/jdk-8u91-linux-i586.rpm&quot;### For 64 bitwget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;http://download.oracle.com/otn-pub/java/jdk/8u91-b14/jdk-8u91-linux-x64.rpm&quot; 如果报以下错误： 参考以下解决：http://blog.csdn.net/angel22xu/article/details/25070373 再次下载即可 离线下载 RPM 下载地址：http://download.oracle.com/otn-pub/java/jdk/8u91-b14/jdk-8u91-linux-x64.rpm?AuthParam=1462805862_8be369be38fdce92bf8162c929be817b 将下载好的rpm文件上传到Linux服务器然后安装 安装 RPM rpm -ivh jdk-8u91-linux-x64.rpm 测试 是否安装成功 java -version 如下： tar.gz安装在线下载 tar.gz1wget http://download.oracle.com/otn-pub/java/jdk/8u91-b14/jdk-8u91-linux-x64.tar.gz?AuthParam=1462934736_6fb6b206c0b3018e3ad5642e2893687b 离线下载 tar.gz 下载地址：1http://download.oracle.com/otn-pub/java/jdk/8u91-b14/jdk-8u91-linux-x64.tar.gz?AuthParam=1462934736_6fb6b206c0b3018e3ad5642e2893687b 将tar.gz 文件上传上去 解压安装 tar.gz12#上传解压tar -zxvf jdk-8u91-linux-x64.tar.gz -C /opt/soft 配置环境变量12345678910# 修改配置文件vi /etc/profile# 在export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL下添加export JAVA_HOME=/opt/soft/jdk1.8.0_91export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar# 刷新配置文件source /etc/profile 测试如上 至此CentOS7成功安装 Java8 安装Tomcat8这里采用离线解压tar.gz的方式安装 下载： 1wget http://mirror.bit.edu.cn/apache/tomcat/tomcat-8/v8.0.33/bin/apache-tomcat-8.0.33.tar.gz 解压： tar -zxvf apache-tomcat-8.0.33.tar.gz -C /opt/soft 启动Tomcat：12cd /opt/soft/apache-tomcat-8.0.33/bin/./startup.sh 将8080端口添加到防火墙例外并重启12firewall-cmd --zone=public --add-port=8080/tcp --permanentfirewall-cmd --reload 访问8080端口测试 转载于 http://blog.csdn.net/uq_jin/article/details/51356799]]></content>
      <categories>
        <category>The Operations OF CentOS</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>CentOS</tag>
        <tag>Tomcat</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7.0下使用yum安装MySQL]]></title>
    <url>%2F2016%2F09%2F11%2FCentOS7.0%E4%B8%8B%E4%BD%BF%E7%94%A8yum%E5%AE%89%E8%A3%85MySQL%2F</url>
    <content type="text"><![CDATA[CentOS7默认数据库是mariadb,配置等用着不习惯,因此决定改成mysql,但是CentOS7的yum源中默认好像是没有mysql的。为了解决这个问题，我们要先下载mysql的repo源。 1.下载mysql的repo源 $ wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm 2.安装mysql-community-release-el7-5.noarch.rpm包 $ sudo rpm -ivh mysql-community-release-el7-5.noarch.rpm 安装这个包后，会获得两个mysql的yum repo源：/etc/yum.repos.d/mysql-community.repo，/etc/yum.repos.d/mysql-community-source.repo。 3.安装mysql $ sudo yum install mysql-server 根据提示安装就可以了,不过安装完成后没有密码,需要重置密码 4.重置mysql密码 $ mysql -u root 登录时有可能报这样的错：ERROR 2002 (HY000): Can‘t connect to local MySQL server through socket ‘/var/lib/mysql/mysql.sock‘ (2)，原因是/var/lib/mysql的访问权限问题。下面的命令把/var/lib/mysql的拥有者改为当前用户： $ sudo chown -R root:root /var/lib/mysql 重启mysql服务 $ service mysqld restart 接下来登录重置密码： $ mysql -u root //直接回车进入mysql控制台 mysql &gt; use mysql; mysql &gt; update user set password=password(‘123456’) where user=’root’; mysql &gt; exit;]]></content>
      <categories>
        <category>The Operations OF CentOS</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>CentOS</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS开放MySQL远程连接及开启3306端口]]></title>
    <url>%2F2016%2F09%2F11%2FCentOS%E5%BC%80%E6%94%BEMySQL%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E5%8F%8A%E5%BC%80%E5%90%AF3306%E7%AB%AF%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[报错:1130-host … is not allowed to connect to this MySql server。 这是远程链接数据库出现的错误，解决方案如下。 改表法。可能是你的帐号不允许从远程登陆，只能在localhost。这个时候只要在localhost的那台电脑，登入mysql后，更改 “mysql” 数据库里的 “user” 表里的 “host” 项，从”localhost”改称”%”12345mysql -u root -pvmwaremysql&gt;use mysql;mysql&gt;update user set host = &apos;%&apos; where user = &apos;root&apos;;mysql&gt;select host, user from user; 授权法。例如，你想myuser使用mypassword从任何主机连接到mysql服务器的话。123GRANT ALL PRIVILEGES ON *.* TO &apos;myuser&apos;@&apos;%&apos; IDENTIFIED BY &apos;mypassword&apos; WITH GRANT OPTION;FLUSH PRIVILEGES; 如果你想允许用户myuser从ip为192.168.1.6的主机连接到mysql服务器，并使用mypassword作为密码123GRANT ALL PRIVILEGES ON *.* TO &apos;myuser&apos;@&apos;192.168.1.3&apos; IDENTIFIED BY &apos;mypassword&apos; WITH GRANT OPTION;FLUSH PRIVILEGES; 如果你想允许用户myuser从ip为192.168.1.6的主机连接到mysql服务器的dk数据库，并使用mypassword作为密码123GRANT ALL PRIVILEGES ON dk.* TO &apos;myuser&apos;@&apos;192.168.1.3&apos; IDENTIFIED BY &apos;mypassword&apos; WITH GRANT OPTION;FLUSH PRIVILEGES; 我用的第一个方法,刚开始发现不行,在网上查了一下,少执行一个语句 mysql&gt;FLUSH RIVILEGES 使修改生效.就可以了 另外一种方法,不过我没有亲自试过的,在csdn.net上找的,可以看一下. 在安装mysql的机器上运行：12345671、d:\mysql\bin\&gt;mysql -h localhost -u root //这样应该可以进入MySQL服务器2、mysql&gt;GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; WITH GRANT OPTION //赋予任何主机访问数据的权限3、mysql&gt;FLUSH PRIVILEGES //修改生效4、mysql&gt;EXIT //退出MySQL服务器 这样就可以在其它任何的主机上以root身份登录啦！ CentOS中数据库开启3306端口123456789$ firewall-cmd --zone=public --add-port=3306/tcp --permanentsuccess$ firewall-cmd --reloadsystemctl stop firewalld.service #停止systemctl disable firewalld.service #禁用]]></content>
      <categories>
        <category>The Operations OF CentOS</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>CentOS</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos下完全卸载MySQL]]></title>
    <url>%2F2016%2F09%2F11%2FCentos%E4%B8%8B%E5%AE%8C%E5%85%A8%E5%8D%B8%E8%BD%BDMySQL%2F</url>
    <content type="text"><![CDATA[CentOS中两种安装(yum与rmp)MySQL方式对应的卸载方法。 yum方式1、yum remove mysql mysql-server mysql-libs compat-mysql512、rm -rf /var/lib/mysql3、rm /etc/my.cnf 查看是否还有mysql软件：rpm -qa|grep mysql如果存在的话，继续删除即可。 rpm方式a）查看系统中是否以rpm包安装的mysql：[root@localhost opt]# rpm -qa | grep -i mysqlMySQL-server-5.6.17-1.el6.i686MySQL-client-5.6.17-1.el6.i686b)卸载mysql[root@localhost local]# rpm -e MySQL-server-5.6.17-1.el6.i686[root@localhost local]# rpm -e MySQL-client-5.6.17-1.el6.i686c)删除mysql服务[root@localhost local]# chkconfig –list | grep -i mysql[root@localhost local]# chkconfig –del mysqld)删除分散mysql文件夹[root@localhost local]# whereis mysql 或者 find / -name mysql mysql: /usr/lib/mysql /usr/share/mysql清空相关mysql的所有目录以及文件rm -rf /usr/lib/mysqlrm -rf /usr/share/mysqlrm -rf /usr/my.cnf 通过以上几步，mysql应该已经完全卸载干净了]]></content>
      <categories>
        <category>The Operations OF CentOS</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>CentOS</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式--Facade(外观模式)]]></title>
    <url>%2F2016%2F04%2F07%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F--Facade(%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F)%2F</url>
    <content type="text"><![CDATA[为子系统中的一组接口提供一个一致的界面，Facade模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 将一个系统划分成为若干个子系统有利于降低系统的复杂性。一个常见的设计目标是使子系统间的通信和相互依赖关系达到最小。 达到该目标的途径之一是就是引入一个外观（Facade）对象，它为子系统中较一般的设施提供了一个单一而简单的界面。 Facade模式概述 实际应用中，我们在对付一些老旧的code（尤其是将C的代码转成C++代码）或者即便不是老旧code，但涉及多个子系统时，除了重写全部代码 （对于老旧code而言），我们还可能采用这样一种策略：重新进行类的设计，将原来分散在源码中的类/结构及方法重新组合，形成新的、统一的接口，供上层应用使用。这在某种意义上与Adapter及Proxy有类似之处，但是，Proxy（代理）注重在为Client-Subject提供一个访问的中间层，如CORBA可为应用程序提供透明访问支持，使应用程序无需去考虑平台及网络造成的差异及其它诸多技术细节；Adapter（适配器）注重对接口的转换与调整；而Facade所面对的往往是多个类或其它程序单元，通过重新组合各类及程序单元，对外提供统一的接口/界面。 Facade模式应用在遇到以下情况使用Facade模式：1、当你要为一个复杂子系统提供一个简单接口时。子系统往往因为不断演化而变得越来越复杂。大多数模式使用时都会产生更多更小的类。这使得子系统更具可重用性，也更容易对子系统进行定制，但这也给那些不需要定制子系统的用户带来一些使用上的困难。Facade可以提供一个简单的缺省视图，这一视图对大多数用户来说已经足够，而那些需要更多的可定制性的用户可以越过Facade层。2、客户程序与抽象类的实现部分之间存在着很大的依赖性。引入Facade将这个子系统与客户以及其他的子系统分离，可以提高子系统的独立性和可移植性。3、当你需要构建一个层次结构的子系统时，使用Facade模式定义子系统中每层的入口点，如果子系统之间是相互依赖的，你可以让它们仅通过Facade进行通讯，从而简化了它们之间的依赖关系。 Facade模式优缺点Facade模式有下面一些优点：1、它对客户屏蔽子系统组件，因而减少了客户处理的对象的数目并使得子系统使用起来更加方便。2、它实现了子系统与客户之间的松耦合关系，而子系统内部的功能组件往往是紧耦合的。松耦合关系使得子系统的组件变化不会影响到它的客户。Facade模式有助于建立层次结构系统，也有助于对对象之间的依赖关系分层。Facade模式可以消除复杂的循环依赖关系。这一点在客户程序与子系统是分别实现的时候尤为重要。在大型软件系统中降低编译依赖性至关重要。在子系统类改变时，希望尽量减少重编译工作以节省时间。用Facade可以降低编译依赖性，限制重要系统中较小的变化所需的重编译工作。Facade模式同样也有利于简化系统在不同平台之间的移植过程，因为编译一个子系统一般不需要编译所有其他的子系统。3、如果应用需要，它并不限制它们使用子系统类。因此你可以在系统易用性和通用性之间加以选择。图实例： 举例代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136package design.facade; public interface ServiceA &#123; /** * ServiceA 的A方法 * */ public void methodA() ; &#125; package design.facade; public class ServiceAImpl implements ServiceA &#123; /* (non-Javadoc) * @see design.facade.ServiceA#methodA() */ @Override public void methodA() &#123; System.out.println( &quot;methodA--&gt; is runing&quot; ); &#125; &#125; package design.facade; public interface ServiceB &#123; /** * ServiceB 的B方法 * */ public void methodB() ; &#125; package design.facade; public class ServiceBImpl implements ServiceB &#123; /* (non-Javadoc) * @see design.facade.ServiceA#methodA() */ @Override public void methodB() &#123; System.out.println( &quot;methodB--&gt; is runing&quot; ); &#125; &#125; package design.facade; public interface ServiceC &#123; /** * ServiceC 的C方法 * */ public void methodC() ; &#125; package design.facade; public class ServiceCImpl implements ServiceC &#123; /* (non-Javadoc) * @see design.facade.ServiceA#methodA() */ @Override public void methodC() &#123; System.out.println( &quot;methodC--&gt; is runing&quot; ); &#125; &#125; package design.facade; public class Facade &#123; ServiceA sa; ServiceB sb; ServiceC sc; public Facade() &#123; sa = new ServiceAImpl(); sb = new ServiceBImpl(); sc = new ServiceCImpl(); &#125; public void methodA() &#123; sa.methodA(); sb.methodB(); &#125; public void methodB() &#123; sb.methodB(); sc.methodC(); &#125; public void methodC() &#123; sc.methodC(); sa.methodA(); &#125; &#125; package design.facade; public class Client &#123; /** * @param args */ public static void main(String[] args) &#123; ServiceA sa = new ServiceAImpl(); ServiceB sb = new ServiceBImpl(); sa.methodA(); sb.methodB(); System.out.println(&quot;=====================&quot;); Facade f = new Facade(); f.methodA(); f.methodB(); f.methodC() ; &#125; &#125;]]></content>
      <categories>
        <category>Patterns</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简化Java开发]]></title>
    <url>%2F2016%2F03%2F11%2F%E7%AE%80%E5%8C%96Java%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[Spring是为了解决企业级应用开发的复杂性而创建的，使用Spring可以让简单的JavaBean实现之前只有EJB才能完成的事情。但Spring不仅仅局限于服务器端开发，任何Java应用都能在简单性、可测试性和松耦合等方面从Spring中获益。虽然Spring用bean或者JavaBean来表示应用组件，但并不意味着Spring组件必须要遵循JavaBean规范。一个Spring组件可以是任何形式的POJO。Spring 可以做非常多的事情。但归根结底，支撑Spring的仅仅是少许的基本理念，所有的理念都可以追溯到Spring最根本的使命上：简化Java开发。 为了降低Java开发的复杂性，Spring采取了以下4种关键策略： 基于POJO的轻量级和最小侵入性编程； 通过依赖注入和面向接口实现松耦合； 基于切面和惯例进行声明式编程； 通过切面和模板减少样板式代码。 激发POJO的潜能很多框架通过强迫应用继承它们的类或实现他们的接口从而导致应用与框架绑死，就如EJB2时的无转台会话bean。而Spring竭力避免因自身API弄乱你的应用代码，Spring不会强迫你实现Spring规范的接口或继承Spring规范的类，相反，在基于Spring构建的应用中，它的类通常没有任何痕迹表明你使用了Spring。如代码清单1 Spring不会再HelloWorldBean上有任何不合理的要求。代码清单1 HelloWorldBean类 12345public class HelloWorldBean &#123; public String sayHello() &#123; return &quot;Hello World&quot;; &#125;&#125; 这是一个简单普通的Java类——POJO。没有任何地方表明它是一个Spring组件。Spring的非侵入编程模型意味着这个类在Spring应用和非Spring应用中都可以发挥同样的作用。Spring赋予POJO魔力的方式之一就是通过DI来装配它们。让我们看看DI是如何帮助应用对象彼此之间保持松散耦合的。 依赖注入依赖注入这个词让人望而生畏，现在已经演变成一项复杂的编程技巧或设计模式理念。但事实证明，依赖注入并不像它听上去那么复杂。在项目中应用DI，你会发现你的代码会变得异常简单并且更容易理解和测试。 DI功能如何实现任何一个有实际意义的应用（肯定比Hello World示例更复杂）都会由两个或者更多的类组成，这些类相互之间进行协作来完成特定的业务逻辑。按照传统的做法，每个对象负责管理与自己相互协作的对象（即它所依赖的对象）的引用，这将会导致高度耦合和难以测试的代码，如代码清单2所示。代码清单2 DamselRescuingKnight类1234567891011121314151617public class DamselRescuingKnight implements Knight &#123; private RescueDamselQuest quest; /* 构造函数中创建RescueDamselQuest,与RescueDamselQuest紧耦合， 极大限度限制DamselRescuingKnight执行能力,如果RescueDamselQuest相当复杂， 为DamselRescuingKnight编写单元测试将出奇困难，那么接下来embarhOnQuest的测试将没法进行。 */ public DamselRescuingKnight() &#123; quest = new RescueDamselQuest(); &#125; @Override public void embarhOnQuest() &#123; quest.embark(); &#125;&#125; 耦合具有两面性（two-headed beast）。一方面，紧密耦合的代码难以测试、难以复用、难以理解，并且典型地表现出“打地鼠”式的bug特性（修复一个bug，将会出现一个或者更多新的bug）。另一方面，一定程度的耦合又是必须的——完全没有耦合的代码什么也做不了。为了完成有实际意义的功能，不同的类必须以适当的方式进行交互。总而言之，耦合是必须的，但应当被小心谨慎地管理。 通过DI，对象的依赖关系将由系统中负责协调各对象的第三方组件在创建对象的时候进行设定。对象无需自行创建或管理它们的依赖关系，如图1所示，依赖关系将被自动注入到需要它们的对象当中去，而不是让对象自己去获取依赖。 图1 依赖注入会将所依赖的关系自动交给目标对象 下面的代码将展示这一点，BraveKnight能很简单的接收赋予它的任务。代码清单3 BraveKnight能很简单的接收赋予它的任务12345678910111213public class BraveKnight implements Knight &#123; private Quest quest; public BraveKnight(Quest quest) &#123; this.quest = quest;// quest被注入到对象中 &#125; @Override public void embarhOnQuest() throws QuestException &#123; quest.embark(); &#125;&#125; 不同于之前的DamselRescuingKnight，Braveknight没有自行创建RescueDamselQuest(),而是构造的时候将Quest的对象quest作为构造器参数传入。这是依赖注入的方式之一，即构造器注入（constructor injection）。 更重要的是，传入的任务类型是Quest，一个所有的任务都必须实现的接口。所以，Braveknight能够响应RescueDamselQuest、SlayDragonQuest、MakeRoundTableRounderQuest等任意的Query实现。 这里的要点是BraveKnight没有与任何特定的Quest实现发生耦合。对它来说，只要能使Quest接口实现，那么具体哪种类型实现就无关紧要了。这就是DI所带来的最大收益————松耦合。如果一个对象只通过接口（而不是具体实现或者初始过程）来表名依赖关系，那么这种依赖就能够在对象本身毫不知情的情况下，用不同的具体实现进行替换。对依赖进行替换的一个最常用方法就是在测试的时候使用mock实现。我们无法充分地测试DamselRescuingKnight,因为它是紧耦合的；但是可以轻松地测试BraveKnight，只需给它一个Quest的mock实现即可，如程序4所示。代码清单4 注入一个mock Quest，测试BraveKnight1234567891011public class BraveKnightTest &#123; @Test public void KnightShouldEmbarkOnQuest() &#123; Quest mockQuest=mock(Quest.class); //创建mock Quest BraveKnight knight=new BraveKnight(mockQuest); //注入mock Quest knight.embarkOnQuest(); verify(mockQuest,times(1)).embark(); &#125;&#125; 可以使用mock框架Mockito去创建一个Quest接口的mock实现。通过这个mock对象，就可以创建一个新的BraveKnight实例，并通过构造器注入这个mock Quest。当调用embarkOnQuest()方法时，你可以要求Mockito框架验证Quest的mock实现的embark（）方法仅仅被调用了一次。 将Query注入到Knight中现在BraveKnight类可以接受你传递给它的任一一种Quest的实现，但该怎样把特定的Query实现传递给它呢？如代码清单5所示，SlayDragonQuest是要注入到BraveKnight中的Quest实现。代码清单5 SlayDragonQuest是要注入到BraveKnight中的Quest实现1234567891011public class SlayDragonQuest implements Quest &#123; private PrintStream stream; public SlayDragonQuest(PrintStream stream) &#123; this.stream = stream; &#125; public void embark() &#123; stream.println(&quot;Embarking on quest to slay the dragon!&quot;); &#125;&#125; 我们可以看到，SlayDragonQuest实现了Quest接口，这样它就适合注入到BraveKnight中去了。与其它的Java入门样例有所不同，SlayDragonQuest没有使用System.out.println()，而是构造方法中请求一个更为通用的PrintStream。这里最大的问题在于，我们该如何将SlayDragonQuest交给BraveKnight呢？又如何将PrintStream交给SlayDragonQuest呢？ 创建应用组件之间协作的行为通常称为装配（wiring）。Spring有多种装配bean的方式，采用XML是很常见的一种装配方式。程序清单6展现了一个简单的Spring配置文件：knights.xml,该配置文件将BraveKnight、SlayDragonQuest和PrintStream装配到了一起。代码清单6 使用Spring将SlayDragonQuest注入到BraveKnight中123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;knight&quot; class=&quot;Springing.Simplifying.BraveKnight&quot;&gt; &lt;constructor-arg ref=&quot;quest&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;quest&quot; class=&quot;Springing.Simplifying.SlayDragonQuest&quot;&gt; &lt;constructor-arg value=&quot;#&#123;T(System).out&#125;&quot; /&gt; &lt;/bean&gt;&lt;/beans&gt; 在这里，BraveKnight和SlayDragonQuest被声明为Spring中的bean。就BraveKnight bean来讲，它在构造时传入了对SlayDragonQuest bean的引用，将其作为构造器参数同时，SlayDragonQuest bean的声明使用了Spring表达式语言（SpringExpression Language），将System.out(这是一个PrintStream)传入到SlayDragonQuest的构造器中。下面为基于Java的配置，他的功能与代码清单6相同。代码清单7 Spring基于Java的配置12345678public class KnightMain &#123; public static void main(String[] args) throws Exception &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;/Springing/Simplifying/config/knights.xml&quot;); Knight knight = context.getBean(Knight.class); knight.embarkOnQuest(); context.close(); &#125;&#125; 不管是基于xml还是基于Java配置，DI所带来的受益都是相同的。尽管BraveKnight依赖于Quest，但是它并不知道传递给它的是什么类型的Quest，也不知道这个Quest来自哪里。与之类似，SlayDragonQuest依赖于PrintStream，但是在编码时它并不需要知道这个PrintStream是什么样子的。只有Spring通过它的配置，能够了解这些组成部分是如何装配起来的。这样的话，就可以在不改变所依赖的类的情况下，修改依赖关系。这个样例展现了在Spring中装配bean的一种简单方式。 现在我们已经声明了BraveKnight与Quest的关系，接下来我们只说明通过xml配置文件装配，并把应用启动起来。 观察它如何工作Spring通过应用上下文（Application Context）装载bean的定义并把它们组装起来。Spring应用上下文全权负责对象的创建和组装。Spring自带了多种应用上下文的实现，它们之间主要的区别仅仅在于如何加载配置。 因为Knights.xml中的bean是使用xml文件进行配置，所以选择ClassPathXMLApplicationContext作为应用上下文相对是比较合适的。该类加载位于应用程序类路径下的一个或多个XML配置文件。123456789public class KnightMain &#123; public static void main(String[] args) throws Exception &#123; //调用ClassPathXmlApplicationContext加载knights.xml,获得Knight对象的引用 ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;/Springing/Simplifying/config/knights.xml&quot;); Knight knight = context.getBean(Knight.class); //获取knight bean knight.embarkOnQuest(); // 使用knight context.close(); &#125;&#125; mian()方法基于knight.xml文件创建了Spring应用上下文。随后它调用该应用上下文获取一个ID为knight的bean。得到knight对象的引用后，只需简单调用embarkOnQuest（）方法就可以获取运行结果。 应用切面DI能够让相互协作的软件组件保持松散耦合，而面向切面编程（aspect-oriented programming，AOP）允许你把遍布应用各处的功能分离出来形成可重用的组件。 面向切面编程往往被定义为促使软件系统实现关注点分离的一项技术。系统由许多不同的组件组成，每一个组件各负责一块特定功能。除了实现自身核心的功能之外，这些组件还经常承担着额外的职责。诸如日志、事务管理和安全这样的系统服务经常融入到自身具有核心业务逻辑的组件中去，这些系统服务通常被称为横切关注点，因为它们会跨越系统的多个组件。 如果将这些关注点分散到多个组件中去，你的代码将会带来双重的复杂性。 实现系统关注点功能的代码将会重复出现在多个组件中。这意味着如果你要改变这些关注点的逻辑，必须修改各个模块中的相关实现。即使你把这些关注点抽象为一个独立的模块，其他模块只是调用它的方法，但方法的调用还是会重复出现在各个模块中。组件会因为那些与自身核心业务无关的代码而变得混乱。一个向地址簿增加地址条目的方法应该只关注如何添加地址，而不应该关注它是不是安全的或者是否需要支持事务。 SpringInAction第4版源代码。]]></content>
      <categories>
        <category>Spring In Action</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[容纳你的Bean]]></title>
    <url>%2F2016%2F03%2F10%2F%E5%AE%B9%E7%BA%B3%E4%BD%A0%E7%9A%84Bean%2F</url>
    <content type="text"><![CDATA[对于Java程序员来说，这是一个很好的时代。 在Java近20年的历史中，它经历过很好的时代，也经历过饱受诟病的时代。尽管有很多粗糙的地方，如applet、企业级JavaBean（Enterprise JavaBean，EJB）、Java数据对象（Java Data Object，JDO）以及无数的日志框架，但是作为一个平台，Java的历史是丰富多彩的，有很多的企业级软件都是基于这个平台构建的。Spring是Java历史中很重要的组成部分。 在诞生之初，创建Spring的主要目的是用来替代更加重量级的企业级Java技术，尤其是EJB。相对于EJB来说，Spring提供了更加轻量级和简单的编程模型。它增强了简单老式Java对象（Plain Old Java object，POJO）的功能，使其具备了之前只有EJB和其他企业级Java规范才具有的功能。 随着时间的推移，EJB以及Java 2企业版（Java 2 Enterprise Edition，J2EE）在不断演化。EJB自身也提供了面向简单POJO的编程模型。现在，EJB也采用了依赖注入（Dependency Injection，DI）和面向切面编程（Aspect-Oriented Programming，AOP）的理念，这毫无疑问是受到Spring成功的启发。 尽管J2EE（现在称之为JEE）能够赶上Spring的步伐，但Spring也没有停止前进。Spring继续在其他领域发展，而JEE则刚刚开始涉及这些领域，或者还完全没有开始在这些领域的创新。移动开发、社交API集成、NoSQL数据库、云计算以及大数据都是Spring正在涉足和创新的领域。Spring的前景依然会很美好。 正如我之前所言，对于Java开发者来说，这是一个很好的时代。]]></content>
      <categories>
        <category>Spring In Action</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring之旅--Java程序员的美好时代]]></title>
    <url>%2F2016%2F03%2F10%2FSpring%E4%B9%8B%E6%97%85--Java%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E7%BE%8E%E5%A5%BD%E6%97%B6%E4%BB%A3%2F</url>
    <content type="text"><![CDATA[对于Java程序员来说，这是一个很好的时代。 在Java近20年的历史中，它经历过很好的时代，也经历过饱受诟病的时代。尽管有很多粗糙的地方，如applet、企业级JavaBean（Enterprise JavaBean，EJB）、Java数据对象（Java Data Object，JDO）以及无数的日志框架，但是作为一个平台，Java的历史是丰富多彩的，有很多的企业级软件都是基于这个平台构建的。Spring是Java历史中很重要的组成部分。 在诞生之初，创建Spring的主要目的是用来替代更加重量级的企业级Java技术，尤其是EJB。相对于EJB来说，Spring提供了更加轻量级和简单的编程模型。它增强了简单老式Java对象（Plain Old Java object，POJO）的功能，使其具备了之前只有EJB和其他企业级Java规范才具有的功能。 随着时间的推移，EJB以及Java 2企业版（Java 2 Enterprise Edition，J2EE）在不断演化。EJB自身也提供了面向简单POJO的编程模型。现在，EJB也采用了依赖注入（Dependency Injection，DI）和面向切面编程（Aspect-Oriented Programming，AOP）的理念，这毫无疑问是受到Spring成功的启发。 尽管J2EE（现在称之为JEE）能够赶上Spring的步伐，但Spring也没有停止前进。Spring继续在其他领域发展，而JEE则刚刚开始涉及这些领域，或者还完全没有开始在这些领域的创新。移动开发、社交API集成、NoSQL数据库、云计算以及大数据都是Spring正在涉足和创新的领域。Spring的前景依然会很美好。 正如我之前所言，对于Java开发者来说，这是一个很好的时代。]]></content>
      <categories>
        <category>Spring In Action</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx的一些基本功能]]></title>
    <url>%2F2016%2F03%2F08%2FNginx%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[Nginx的一些基本功能有做静态HTTP服务器、反向代理服务器、负载均衡、虚拟主机和FastCGI，其应用如下。 静态HTTP服务器首先，Nginx是一个HTTP服务器，可以将服务器上的静态文件（如HTML、图片）通过HTTP协议展现给客户端。 配置： 123456server &#123; listen80; # 端口号 location / &#123; root /usr/share/nginx/html; # 静态文件路径 &#125; &#125; 反向代理服务器什么是反向代理？ 客户端本来可以直接通过HTTP协议访问某网站应用服务器，网站管理员可以在中间加上一个Nginx，客户端请求Nginx，Nginx请求应用服务器，然后将结果返回给客户端，此时Nginx就是反向代理服务器。 配置： 123456server &#123; listen80; location / &#123; proxy_pass http://192.168.20.1:8080; # 应用服务器HTTP地址 &#125; &#125; 既然服务器可以直接HTTP访问，为什么要在中间加上一个反向代理，不是多此一举吗？反向代理有什么作用？继续往下看，下面的负载均衡、虚拟主机等，都基于反向代理实现，当然反向代理的功能也不仅仅是这些。 负载均衡当网站访问量非常大，网站站长开心赚钱的同时，也摊上事儿了。因为网站越来越慢，一台服务器已经不够用了。于是将同一个应用部署在多台服务器上，将大量用户的请求分配给多台机器处理。同时带来的好处是，其中一台服务器万一挂了，只要还有其他服务器正常运行，就不会影响用户使用。 Nginx可以通过反向代理来实现负载均衡。 配置: 12345678910upstream myapp &#123; server192.168.20.1:8080; # 应用服务器1 server192.168.20.2:8080; # 应用服务器2 &#125; server &#123; listen80; location / &#123; proxy_pass http://myapp; &#125; &#125; 以上配置会将请求轮询分配到应用服务器，也就是一个客户端的多次请求，有可能会由多台不同的服务器处理。可以通过ip-hash的方式，根据客户端ip地址的hash值将请求分配给固定的某一个服务器处理。配置： 1234567891011upstream myapp &#123; ip_hash; # 根据客户端IP地址Hash值将请求分配给固定的一个服务器处理 server192.168.20.1:8080; server192.168.20.2:8080; &#125; server &#123; listen80; location / &#123; proxy_pass http://myapp; &#125; &#125; 另外，服务器的硬件配置可能有好有差，想把大部分请求分配给好的服务器，把少量请求分配给差的服务器，可以通过weight来控制。配置： 12345678910upstream myapp &#123; server192.168.20.1:8080weight=3; # 该服务器处理3/4请求 server192.168.20.2:8080; # weight默认为1，该服务器处理1/4请求 &#125; server &#123; listen80; location / &#123; proxy_pass http://myapp; &#125; &#125; 虚拟主机有的网站访问量大，需要负载均衡。然而并不是所有网站都如此出色，有的网站，由于访问量太小，需要节省成本，将多个网站部署在同一台服务器上。 例如将www.aaa.com和www.bbb.com两个网站部署在同一台服务器上，两个域名解析到同一个IP地址，但是用户通过两个域名却可以打开两个完全不同的网站，互相不影响，就像访问两个服务器一样，所以叫两个虚拟主机。 配置： 12345678910111213141516171819202122232425262728server &#123; listen80default_server; server_name _; return444; # 过滤其他域名的请求，返回444状态码 &#125; server &#123; listen80; server_name www.aaa.com; # www.aaa.com域名 location / &#123; proxy_pass http://localhost:8080; # 对应端口号8080 &#125; &#125; server &#123; listen80; server_name www.bbb.com; # www.bbb.com域名 location / &#123; proxy_pass http://localhost:8081; # 对应端口号8081 &#125; &#125; ``` 在服务器8080和8081分别开了一个应用，客户端通过不同的域名访问，根据server_name可以反向代理到对应的应用服务器。虚拟主机的原理是通过HTTP请求头中的Host是否匹配server_name来实现的，有兴趣的同学可以研究一下HTTP协议。另外，server_name配置还可以过滤有人恶意将某些域名指向你的主机服务器。#### FastCGINginx本身不支持PHP等语言，但是它可以通过FastCGI来将请求扔给某些语言或框架处理（例如PHP、Python、Perl）。 server { listen80; location ~ .php$ { include fastcgi_params; fastcgi_param SCRIPT_FILENAME /PHP文件路径$fastcgi_script_name; # PHP文件路径 fastcgi_pass127.0.0.1:9000; # PHP-FPM地址和端口号 # 另一种方式：fastcgi_pass unix:/var/run/php5-fpm.sock; } }```配置中将.php结尾的请求通过FashCGI交给PHP-FPM处理，PHP-FPM是PHP的一个FastCGI管理器。 转载于http://blog.csdn.net/zhongguozhichuang/article/details/52816887]]></content>
      <categories>
        <category>Operations</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分隔符和定长解码器的应用]]></title>
    <url>%2F2016%2F01%2F01%2F%E5%88%86%E9%9A%94%E7%AC%A6%E5%92%8C%E5%AE%9A%E9%95%BF%E8%A7%A3%E7%A0%81%E5%99%A8%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[通过使用DelimiterBasedFrameDecoder、FixedLengthFrameDecoder实现分隔符和定长解码器。 TCP以流的方式进行数据传输，上层的应用协议为了对消息进行分区，往往采用下面4种方式： 消息长度固定，累计读取到长度总和为定长LEN的报文后，就以为读取到了一个完整的消息；将计数器置位，重新开始读取下一个数据报； 将回车换行符作为消息结束符，例如FTP协议，这种方式在文本协议中应用比较广泛； 将特殊的分隔符作为消息的结束标志，回车换行符就是一种特殊的结束分隔符； 通过在消息头中定义长度字段来标识消息的总长度。 DelimiterBasedFrameDecoder应用开发通过对DelimiterBasedFrameDecoder的使用，我们可以自动完成以分隔符作为码流结束标识的消息的解码；通过一个实例来演示，EchoServer接受到EchoClient的请求 消息后，将其打印出来，然后将原始消息返回给客户端，消息以”$_”作为分隔符。 服务端开发代码清单1 EchoServer服务端EchoServer1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class EchoServer &#123; public void bind(int port)throws Exception&#123; //创建服务端的NIO线程组 EventLoopGroup bossGroup=new NioEventLoopGroup(); EventLoopGroup workerGroup=new NioEventLoopGroup(); try &#123; ServerBootstrap b=new ServerBootstrap(); b.group(bossGroup,workerGroup) .channel(NioServerSocketChannel.class).option(ChannelOption.SO_BACKLOG, 100) .childHandler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; // TODO Auto-generated method stub //首先创建分隔符缓冲对象ByteBuf，本例中使用“$_”作为分隔符。 ByteBuf delimiter=Unpooled.copiedBuffer(&quot;$_&quot;.getBytes()); /* 创建DelimiterBasedFrameDecoder对象，将其加入到ChannelPipeline中。 DelimiterBasedFrameDecoder有多个构造方法，这里我们传递两个参数： 第一个1024表示单条消息的最大长度，当达到该长度任然没有查到分隔符，就抛出TooLongFrameException异常， 防止由于异常码流缺失分隔符导致的内存溢出，这是Netty解码器的可靠性保护；第二个就是分隔符缓冲对象。*/ ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, delimiter)); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new EchoServerHander()); &#125; &#125;); //绑定端口，同步等待成功 ChannelFuture f=b.bind(port).sync(); //等待服务端监听端口关闭 f.channel().closeFuture().sync(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception &#123; // TODO Auto-generated method stub int port=8080; if(args!=null&amp;&amp;args.length&gt;0)&#123; try &#123; port=Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // TODO: handle exception &#125; &#125; new EchoServer().bind(port); &#125;&#125; 代码清单2 EchoServer服务端EchoServerHandler123456789101112131415161718192021@Sharablepublic class EchoServerHander extends ChannelHandlerAdapter &#123; int counter=0; @Override public void channelRead(ChannelHandlerContext ctx,Object msg)throws Exception&#123; /* 直接将接受的消息打印出来，由于DelimiterBasedFrameDecoder自动对请求消息进行解码， 后续的ChannelHandler接受到的msg对象就是个完整的消息包； 第二个ChannelHandler是StringDecoder，它将ByteBuf解码器成字节符对象； 第三个EchoServerHandler接受到的msg消息就是解码后的字符串对象。*/ String body=(String) msg; System.out.println(&quot;This is &quot;+ ++counter+&quot; times receive client :[&quot;+body+&quot;]&quot;); ByteBuf echo=Unpooled.copiedBuffer(body.getBytes()); ctx.writeAndFlush(echo); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 由于我们设置DelimiterBasedFrameDecoder过滤掉了分隔符，所以，返回给客户端是需要在请求消息尾部拼接分隔符“$_”,最后创建ByteBuf，将原始消息重新返回给客户端。 客户端开发代码清单3 EchoServer客户端EchoClient123456789101112131415161718192021222324252627282930313233343536373839404142434445public class EchoClient &#123; public void connect(int port, String host) throws Exception &#123; // 配置客户端NIO线程组、 EventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class).option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; /* 与 服务端类似，分别DelimiterBasedFrameDecoder和StringDecoder 添加到客户端ChannelPipeline中，最后添加客户端I/O事件处理类EchoClientHandler。 */ ByteBuf delimiter = Unpooled.copiedBuffer(&quot;$_&quot;.getBytes()); ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, delimiter)); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new EchoClientHandler()); &#125; &#125;); // 发起异步连接操作 ChannelFuture f = b.connect(host,port).sync(); // 等待客户端链路关闭 f.channel().closeFuture().sync(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // TODO: handle exception &#125; &#125; new EchoClient().connect(port, &quot;127.0.0.1&quot;); &#125;&#125; 代码清单4 EchoClient客户端EchoClientHandler123456789101112131415161718192021222324252627282930313233343536public class EchoClientHandler extends ChannelHandlerAdapter&#123; private int counter; static final String ECHO_REQ = &quot;Hi,Lilinfeng.Welcome to netty.$_&quot;; public EchoClientHandler() &#123; // TODO Auto-generated constructor stub &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; //循环发送给服务端 for (int i = 0; i &lt; 10; i++) &#123; ctx.writeAndFlush(Unpooled.copiedBuffer(ECHO_REQ.getBytes())); &#125; &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; //打印接收到服务端应答消息同时进行计数 System.out.println(&quot;This is &quot; + ++counter + &quot; times receive server : [&quot; + msg + &quot;]&quot;); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 服务端与客户端运行服务端运行结果如下。 客户端运行结果如下。 测试表明DelimiterBasedFrameDecoder可以自动对采用分隔符做码流结束标识的消息进行解码。 DelimiterBasedFrameDecoder没有解码器处理对服务端的DelimiterBasedFrameDecoder注释掉，代码如图1所示。 图1 删掉DelimiterBasedFrameDecoder后的服务端代码 服务端运行结果如下： FixedLengthFrameDecoder应用开发FixedLengthFrameDecoder是固定长度解码器，它能够按照指定长度对消息进行自动解码，开发者不需要考虑TCP的粘包/拆包问题，非常实用。 服务端开发在服务端的ChannelPipeline中新增FixedLengthFrameDecoder，长度设置为20，然后再依次增加字符串解码器和EchoServerHandler。代码清单5 EchoServer服务端 EchoServer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class EchoServer &#123; public void bind(int port) throws Exception &#123; // 配置服务端的NIO线程组 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChildChannelHandler()); // 绑定端口，同步等待成功 ChannelFuture f = b.bind(port).sync(); // 等待服务端监听端口关闭 f.channel().closeFuture().sync(); &#125; finally &#123; // 优雅退出，释放线程池资源 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; private class ChildChannelHandler extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel arg0) throws Exception &#123; arg0.pipeline().addLast(new FixedLengthFrameDecoder(20)); arg0.pipeline().addLast(new StringDecoder()); arg0.pipeline().addLast(new EchoServerHandler()); &#125; &#125; /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; new EchoServer().bind(port); &#125;&#125; 代码清单6 EchoServer服务端 EchoServerHandler1234567891011121314151617@Sharablepublic class EchoServerHandler extends ChannelHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println(&quot;Receive client : [&quot;+msg+&quot;]&quot;); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 利用FixedLengthFrameDecoder解码器，无论一次接收多少数据报，它都会按照构造函数中设置的固定长度进行解码，如果是半包消息，FixedLengthFrameDecoder会缓存半包消息并等待下个包到达后进行拼包，直到一个完整的包。 利用NetAssist软件测试服务端如图2所示，通过NetAssist软件，发送消息到服务端，消息内容为：https://5iyxx.github.io/categories/Netty-The-Definitive-Guide/ 。 图2 NetAssist软件参数 EchoServer服务端运行结果如图3所示，FixedLengthFrameDecoder解码器按照20个字节对请求进行截取。 图3 EchoServer服务端运行结果]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP粘包/拆包问题的解决之道]]></title>
    <url>%2F2015%2F12%2F01%2FTCP%E7%B2%98%E5%8C%85%E6%8B%86%E5%8C%85%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E4%B9%8B%E9%81%93%2F</url>
    <content type="text"><![CDATA[熟悉TCP编程的读者可能都知道，无论是服务端还是客户端，当我们读取或者发送消息的时候，都需要考虑TCP底层的粘包/拆包机制。 TCP粘包/拆包TCP底层并不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进行包的划分，所以在业务上认为，一个完整的包可能会被TCP拆分成多个包进行发送，这就是所谓的TCP粘包和拆包问题。 TCP粘包/拆包问题说明在我们可以通过图解对TCP粘包和拆包问题进行说明，如图1所示。 图1 TCP粘包/拆包问题 假设客户端分别发送了两个数据包D1 和D2给服务端，由于服务端一次读取到的字节数是不确定的，故可能存在4种情况： 服务端分两次读取到了两个独立的数据包，分别是D1 和 D2，没有粘包和拆包 服务端一次接收到了两个数据包，D1和D2粘合在一起，被称为TCP粘包 服务端分两次读取到了两个数据包，第一次读取到了完整的D1包和D2包的部分内容，第二次读取到了D2包的剩余内容，这称为TCP拆包 服务端分两次读取到了两个数据包，第一次读取到了D1包的部分内容D1_1，第二次读取到了D1包的剩余内容D1_2和D2包的整包。 如果此时服务端TCP接收滑窗非常小，而数据包D1和D2比较大，很可能会发生第5种可能，即服务端分多次才能将D1和D2包接收完全，期间发生多次拆包 TCP粘包/拆包发生的原因问题产生的原因有三个，分别如下： 应用程序write写入的字节大小大于套接口发送缓冲区大小； 进行MSS大小的TCP分段； 以太网帧的payload大于MTU进行IP分片。 图解如图2所示。 图2 TCP粘包/拆包问题原因 粘包问题的解决策略由于底层的TCP无法理解上层的业务数据，所以在底层是无法保证数据包不被拆分和重组的，这个问题只能通过上层的应用协议栈设计来解决，根据业界的主流协议的解决方案，可以归纳如下。 消息定长，例如每个报文的大小固定长度为200字节，如果不够，空位补空格； 在包尾添加回车换行符进行分割，例如FTP协议； 将消息分为消息头和消息体，消息头中包含表示消息总长度（或者消息体长度）的字段，通常设计思路为消息头的第一个字段使用int32来表示消息的总长度； 更复杂的应用协议。 未考虑TCP粘包导致功能异常案例在前面的时间服务器中（代码见超链接），我们并没有考虑读半包问题，这些功能测试时往往没有问题，但是一旦压力上来，发送大报文之后，就会存在粘包/拆包问题。下面模拟故障场景，然后看看如何正确使用Netty的半包解码来解决TCP粘包/拆包问题。 TimeServer的改造代码清单1 Netty时间服务器服务端 TimeServerHandler12345678910111213141516171819202122232425262728public class TimeServerHandler extends ChannelHandlerAdapter &#123; private int counter; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf buf = (ByteBuf) msg; byte[] req = new byte[buf.readableBytes()]; buf.readBytes(req); String body = new String(req, &quot;UTF-8&quot;).substring(0, req.length - System.getProperty(&quot;line.separator&quot;).length()); System.out.println(&quot;The time server receive order : &quot; + body + &quot; ; the counter is : &quot; + ++counter); String currentTime = &quot;QUERY TIME ORDER&quot;.equalsIgnoreCase(body) ? new java.util.Date(System.currentTimeMillis()).toString() : &quot;BAD ORDER&quot;; currentTime = currentTime + System.getProperty(&quot;line.separator&quot;); ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes()); ctx.write(resp); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; ctx.close(); &#125;&#125; 每读到一条消息后，就计一次数，然后发送应答消息给客户端。按照设计，服务端接收到的消息总数应该跟客户端发送的消息总数相同，而且请求消息删除回车换行符后应该为“QUERY TIME ORDER”。 TimeClient的改造代码清单2 Netty时间服务器服务端 TimeServer1234567891011121314151617181920212223242526272829303132333435363738394041424344public class TimeClientHandler extends ChannelHandlerAdapter &#123; private static final Logger logger = Logger .getLogger(TimeClientHandler.class.getName()); private int counter; private byte[] req; /** * Creates a client-side handler. */ public TimeClientHandler() &#123;req=(&quot;QUERY TIME ORDER&quot;+System.getProperty(&quot;line.separator&quot;)).getBytes(); &#125; @Override public void channelActive(ChannelHandlerContext ctx) &#123; ByteBuf message=null; for(int i=0;i&lt;100;i++)&#123; message=Unpooled.buffer(req.length); message.writeBytes(req); ctx.writeAndFlush(message); &#125; &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf buf = (ByteBuf) msg; byte[] req = new byte[buf.readableBytes()]; buf.readBytes(req); String body = new String(req, &quot;UTF-8&quot;); System.out.println(&quot;Now is : &quot; + body+&quot; ;the counter is : &quot;+ ++counter); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; // 释放资源 logger.warning(&quot;Unexpected exception from downstream : &quot; + cause.getMessage()); ctx.close(); &#125;&#125; 主要修改点是代码第18~23行，客户端跟服务端链路建立成功之后，循环发送100条消息，每发一条就刷新一次，保证每条消息都会被写入Channel中。按照设计，服务端应该接收到100条查询时间指令的请求消息。第34行，客户端每接收到服务端一条应答消息之后，就打印一次计数器。按照设计初衷，客户端应该打印100次服务端的系统时间。 运行结果服务端运行结果如下。 服务端运行结果表明它只接收到了两条消息，第一条包含57条“QUERY TIME ORDER”指令，第二条包含了43条“QUERY TIME ORDER”指令，总数正好100条。我们期待的是收到100条消息，每条包含一条“QUERY TIME ORDER”指令。这说明发生了TCP粘包。客户端运行结果如下。 按照设计初衷，客户端应该收到100条当前系统时间的消息，但实际上只收到一条。这不难理解，因为服务端只收到了2条请求消息，所以实际服务端只发生了2条应答，由于请求消息不满足查询条件，所以返回了2条“BAD ORDER”应答消息。但是实际上客户端只收到一条包含2条“BAO ORDER”指令的消息，说明服务端返回的应答消息也发生了粘包。由于上面的例程没有考虑TCP的粘包/拆包，所以当发生TCP粘包时，我们的程序就不能正常工作。 利用LineBasedFrameDecoder解决TCP粘包问题为了解决TCP粘包/拆包导致的半包读写问题，Netty默认提供了多种编解码器用于处理半包，只要能熟练掌握这些类库的使用，TCP粘包问题从此会变得非常简单，你甚至不需要关心它们，这也是其他NIO框架和JDK原生的NIO API所无法匹敌的。下面我们就以修正时间服务器中（代码见超链接）为目标进行开发和讲解，通过对实际代码的讲解让大家能够尽快熟悉和掌握半包解码器的使用。 支持TCP粘包的TimeServer直接看代码，然后对LineBasedFrameDecoder和StringDecoder的API进行说明。代码清单3 Netty时间服务器服务端 TimeServer1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class TimeServer &#123; public void bind(int port) throws Exception &#123; // 配置服务端的NIO线程组 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) .childHandler(new ChildChannelHandler()); // 绑定端口，同步等待成功 ChannelFuture f = b.bind(port).sync(); // 等待服务端监听端口关闭 f.channel().closeFuture().sync(); &#125; finally &#123; // 优雅退出，释放线程池资源 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; private class ChildChannelHandler extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel arg0) throws Exception &#123; //在原来的TimeServerHandler之前新增了两个解码器：LineBasedFrameDecoder和StringDecoder。 arg0.pipeline().addLast(new LineBasedFrameDecoder(1024)); arg0.pipeline().addLast(new StringDecoder()); arg0.pipeline().addLast(new TimeServerHandler()); &#125; &#125; /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; new TimeServer().bind(port); &#125;&#125; 代码清单4 Netty时间服务器服务端 TimeServerHandler1234567891011121314151617181920public class TimeServerHandler extends ChannelHandlerAdapter &#123; private int counter; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; //可以发现接收到的msg就是删除回车换行符后的请求消息，不需要额外考虑处理读半包问题，也不需要对请求消息进行编码，代码非常简洁。 String body = (String) msg; System.out.println(&quot;The time server receive order : &quot; + body + &quot; ; the counter is : &quot; + ++counter); String currentTime = &quot;QUERY TIME ORDER&quot;.equalsIgnoreCase(body) ? new java.util.Date(System.currentTimeMillis()).toString() : &quot;BAD ORDER&quot;; currentTime = currentTime + System.getProperty(&quot;line.separator&quot;); ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes()); ctx.write(resp); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; ctx.flush(); &#125; 支持TCP粘包的TimeClient代码清单5 Netty时间服务器客户端 TimeClient12345678910111213141516171819202122232425262728293031323334353637383940414243public class TimeClient &#123; public void connect(int port, String host) throws Exception &#123; // 配置客户端NIO线程组 EventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; //在原来的TimeServerHandler之前新增了两个解码器：LineBasedFrameDecoder和StringDecoder。 ch.pipeline().addLast(new LineBasedFrameDecoder(1024)); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new TimeClientHandler()); &#125; &#125;); // 发起异步连接操作 ChannelFuture f = b.connect(host, port).sync(); // 当代客户端链路关闭 f.channel().closeFuture().sync(); &#125; finally &#123; // 优雅退出，释放NIO线程组 group.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; new TimeClient().connect(port, &quot;127.0.0.1&quot;); &#125;&#125; 代码清单6 Netty时间服务器客户端 TimeClientHandler12345678910111213141516171819202122232425262728293031323334353637383940public class TimeClientHandler extends ChannelHandlerAdapter &#123; private static final Logger logger = Logger.getLogger(TimeClientHandler.class.getName()); private int counter; private byte[] req; /** * Creates a client-side handler. */ public TimeClientHandler() &#123; req = (&quot;QUERY TIME ORDER&quot; + System.getProperty(&quot;line.separator&quot;)).getBytes(); &#125; @Override public void channelActive(ChannelHandlerContext ctx) &#123; ByteBuf message = null; for (int i = 0; i &lt; 100; i++) &#123; message = Unpooled.buffer(req.length); message.writeBytes(req); ctx.writeAndFlush(message); &#125; &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; //拿到的msg已经是解码成字符串的应答消息了，相比于之前的代码简洁了很多。 String body = (String) msg; System.out.println(&quot;Now is : &quot; + body + &quot; ;the counter is : &quot; + ++counter); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; // 释放资源 logger.warning(&quot;Unexpected exception from downstream : &quot; + cause.getMessage()); ctx.close(); &#125;&#125; 运行支持TCP粘包的时间服务器程序服务端运行结果如下。 客户端运行结果如下。 程序的运行结果完全符合预期，说明通过使用LineBasedFrameDecoder和StringDecoder成功解决了TCP粘包导致的读半包问题。 LineBasedFrameDecoder和StringDecoder的原理分析LineBasedFrameDecoder的工作原理是它依次遍历ByteBuf中的可读字节，判断看是否有“\n”或者“\r\n”,如果有就以此位置结束，从可读索引到结束位置区间的字节就组成了一行。它是以换行符为结束标志的解码器，支持携带结束符或者不携带结束符两种解码方式。同时支持配置单行的最大长度。如果连续读取最大长度后任然没有发现换行符，就会抛出异常，同时忽略掉之前读到的异常码流。 StringDecoder的功能非常简单，就是将接受到的对象转换成字符串，然后继续调用后面的handler。LineBasedFrameDecoder和StringDecoder组合就是按行切换的文本解码器，它被设计用来支持TCP的粘包和拆包。]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JBossMarshalling编解码]]></title>
    <url>%2F2015%2F07%2F01%2FJBossMarshalling%E7%BC%96%E8%A7%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[JBoss Marshalling是一个Java对象序列化包，对JDK默认的序列化框架进行了优化，但又保存跟java.io.Serializable接口兼容，同时增加了一些可调的参数和附加特性，这些参数和特性可通过工厂类进行配置。 服务端运行结果如下。 图6 服务端运行结果 客户端运行结果如下。 图7 客户端运行结果]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GoogleProtobuf编解码]]></title>
    <url>%2F2015%2F06%2F01%2FGoogleProtobuf%E7%BC%96%E8%A7%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[Google的Protobuf在业界非常流行，很多商业项目选择Protobuf作为编解码框架，其优点如下。 在谷歌内部长期使用，产品成熟度高： 跨语言，支持多种语言，包括C十十、java和Python. 编码后的消息更小，更加有利于存储和传输： 编解码的性能非常高： 支持不同协议版本的前向兼容： 支辫定义可选和必选字段。 Protobuf的入门Protobuf是一个灵活、高效、结构化的数据序列化框架，相比于XML等传统的序列化工具，它更小，更快，更简单。Protobuf支持数据结构化一次可以到处使用，甚至跨语言使用，通过代码生成工具可以自动生成不同语言版本的源代码，甚至可以在使用不同版本的数据结构j进程间进行数据传递，实现数据结构的前向兼容。 下面我们通过一个简单的例程来学习如何使用Protobuf对POJO对象进行编解码，然后，我们以这个例程为基础，学习如何在Netty中对POJO对象迸行Protobuf编解码，并在两个进程之间进行通信和数据交换。 Protobuf开发环境搭建首先下载Protobuf的Windows版本，得到protoc.exe.下面我们以商品订购例程为例，定义SubscribeReq.proto和SubscribeResp.proto与protoc.exe放在同目录下（方便下面操作）.代码清单1 SubscribeReq.proto12345678910package com.eric.netty.codec.protobuf; option java_package = &quot;com.eric.netty.codec.protobuf&quot;; option java_outer_classname = &quot;SubscribeReqProto&quot;; message SubscribeReq&#123; required int32 subReqID = 1; required string userName = 2; required string productName = 3; repeated string address = 4; &#125; 代码清单2 SubscribeReq.proto12345678package com.eric.netty.codec.protobuf; option java_package = &quot;com.eric.netty.codec.protobuf&quot;; option java_outer_classname = &quot;SubscribeRespProto&quot;; message SubscribeResp&#123; required int32 subReqID = 1; required string respCode = 2; required string desc = 3; &#125; 通过protoc.exe命令protoc --java_out=SubscribeReq.proto和protoc --java_out=SubscribeResp.proto行生成Java代码。如果出现Missing input file则改用protoc ./SubscribeReq.proto --java_out=./和protoc ./SubscribeResp.proto --java_out=./如图1所示,再把生成的SubscribeReqProto.java和SubscribeRespProto.java拷贝到项目中。 图1 通过protoc.exe工具生成源代码 生成的源代码编译出错，是由于缺少protobuf-java的jar包，其maven的依赖如下，将jar包引入到类库中就能正常使用，Protobuf开发环境也已经构建完成。 代码清单3 protobuf-java的maven的依赖12345&lt;dependency&gt;&lt;groupId&gt;com.google.protobuf&lt;/groupId&gt;&lt;artifactId&gt;protobuf-java&lt;/artifactId&gt;&lt;version&gt;3.4.0&lt;/version&gt;&lt;/dependency&gt; Protobuf编解码开发Protobuf的类库使用比较简单，下面我们就通过对SubscribeReqProto进行编解码来介绍Protobuf的使用。代码清单4 Protobuf入门 TestSubscribeReqProto123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class TestSubscribeReqProto &#123; private static byte[] encode(SubscribeReqProto.SubscribeReq req) &#123; /* 编码时通过调用SubscribeReqProto.SubscrobeReq实例的toByteArray即可将SubscribeReq编码为byte数组，使用非常方便。 */ return req.toByteArray(); &#125; private static SubscribeReqProto.SubscribeReq decode(byte[] body) throws InvalidProtocolBufferException &#123; /* 编码时通过调用SubscribeReqProto.SubscrobeReq实例的parseFrom将二进制byte数组解码为原始的对象。 */ return SubscribeReqProto.SubscribeReq.parseFrom(body); &#125; /* 通过SubscribeReqProto.SubscribeReq的静态方法newBuilder创建 SubscribeReqProto.SubscribeReq的Builder实例 */ private static SubscribeReqProto.SubscribeReq createSubscribeReq() &#123; /* 通过Builder构造器对SubscribeReq的属性进行设置 */ SubscribeReqProto.SubscribeReq.Builder builder = SubscribeReqProto.SubscribeReq .newBuilder(); builder.setSubReqID(1); builder.setUserName(&quot;Lilinfeng&quot;); builder.setProductName(&quot;Netty Book&quot;); /* 对于集合类型通过addAllXXX()方法将集合对象设置 到对应的属性中。 */ List&lt;String&gt; address = new ArrayList&lt;&gt;(); address.add(&quot;NanJing YuHuaTai&quot;); address.add(&quot;BeiJing LiuLiChang&quot;); address.add(&quot;ShenZhen HongShuLin&quot;); builder.addAllAddress(address); return builder.build(); &#125; /** * @param args * @throws InvalidProtocolBufferException */ public static void main(String[] args) throws InvalidProtocolBufferException &#123; SubscribeReqProto.SubscribeReq req = createSubscribeReq(); System.out.println(&quot;Before encode : &quot; + req.toString()); SubscribeReqProto.SubscribeReq req2 = decode(encode(req)); System.out.println(&quot;After decode : &quot; + req.toString()); System.out.println(&quot;Assert equal : --&gt; &quot; + req2.equals(req)); &#125;&#125; 运行Protobuf例程运行TestSubscribeReqProto，执行结果如图2所示。 图2 运行TestSubscribeReqProto执行结果 Netty的Protobuf服务端开发下面为一个Protobuf版本的图书订购程序。 Protobuf服务端开发代码清单5 Protobuf版本图书订购代码SubReqServer12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class SubReqServer &#123; public void bind(int port) throws Exception &#123; // 配置服务端的NIO线程组 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) &#123; /* 向ChannelPipeline添加ProtobufVarint32FrameDecoder， 它主要用于半包处理，随后继续添加ProtobufDecoder解码器， 它的参数是com.google.protobuf.MessageLite,实际上就是 要告诉ProtobufDecoder需要解码的目标类是什么，否则仅仅 从字节数组中是无法判断出要解码的目标类型信息的。 */ ch.pipeline().addLast( new ProtobufVarint32FrameDecoder()); ch.pipeline().addLast( new ProtobufDecoder( SubscribeReqProto.SubscribeReq .getDefaultInstance())); ch.pipeline().addLast( new ProtobufVarint32LengthFieldPrepender()); ch.pipeline().addLast(new ProtobufEncoder()); ch.pipeline().addLast(new SubReqServerHandler()); &#125; &#125;); // 绑定端口，同步等待成功 ChannelFuture f = b.bind(port).sync(); // 等待服务端监听端口关闭 f.channel().closeFuture().sync(); &#125; finally &#123; // 优雅退出，释放线程池资源 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; new SubReqServer().bind(port); &#125;&#125; 代码清单6 Protobuf版本图书订购代码SubReqServerHandler1234567891011121314151617181920212223242526272829@Sharablepublic class SubReqServerHandler extends ChannelHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; SubscribeReqProto.SubscribeReq req = (SubscribeReqProto.SubscribeReq) msg; if (&quot;Lilinfeng&quot;.equalsIgnoreCase(req.getUserName())) &#123; System.out.println(&quot;Service accept client subscribe req : [&quot; + req.toString() + &quot;]&quot;); ctx.writeAndFlush(resp(req.getSubReqID())); &#125; &#125; private SubscribeRespProto.SubscribeResp resp(int subReqID) &#123; SubscribeRespProto.SubscribeResp.Builder builder = SubscribeRespProto.SubscribeResp .newBuilder(); builder.setSubReqID(subReqID); builder.setRespCode(String.valueOf(0)); builder.setDesc(&quot;Netty book order succeed, 3 days later, sent to the designated address&quot;); return builder.build(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; cause.printStackTrace(); ctx.close();// 发生异常，关闭链路 &#125;&#125; 由于protobufDecoder已经对消息进行了自动解码，因此接收到的订购请求消息可以直接使用。对用户名进行校验，校验通过后构造应答消息返回给客户端，由于使用了ProtobufEncoder,所以不需要对SubscribeRespProto.SubscribeResp进行手工编码。 Protobuf客户端开发代码清单7 Protobuf版本图书订购代码SubReqClient123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class SubReqClient &#123; public void connect(int port, String host) throws Exception &#123; // 配置客户端NIO线程组 EventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast( new ProtobufVarint32FrameDecoder()); /* 需要指出的是客户端需要解码的对象是订购响应，使用 SubscribeRespProto.SubscribeResp的实例作为入参 */ ch.pipeline().addLast( new ProtobufDecoder( SubscribeRespProto.SubscribeResp .getDefaultInstance())); ch.pipeline().addLast( new ProtobufVarint32LengthFieldPrepender()); ch.pipeline().addLast(new ProtobufEncoder()); ch.pipeline().addLast(new SubReqClientHandler()); &#125; &#125;); // 发起异步连接操作 ChannelFuture f = b.connect(host, port).sync(); // 当代客户端链路关闭 f.channel().closeFuture().sync(); &#125; finally &#123; // 优雅退出，释放NIO线程组 group.shutdownGracefully(); &#125; &#125; /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; new SubReqClient().connect(port, &quot;127.0.0.1&quot;); &#125;&#125; 代码清单8 Protobuf版本图书订购代码SubReqHandler1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class SubReqClientHandler extends ChannelHandlerAdapter &#123; /** * Creates a client-side handler. */ public SubReqClientHandler() &#123; &#125; @Override public void channelActive(ChannelHandlerContext ctx) &#123; for (int i = 0; i &lt; 10; i++) &#123; ctx.write(subReq(i)); &#125; ctx.flush(); &#125; private SubscribeReqProto.SubscribeReq subReq(int i) &#123; SubscribeReqProto.SubscribeReq.Builder builder = SubscribeReqProto.SubscribeReq .newBuilder(); builder.setSubReqID(i); builder.setUserName(&quot;Lilinfeng&quot;); builder.setProductName(&quot;Netty Book For Protobuf&quot;); List&lt;String&gt; address = new ArrayList&lt;&gt;(); address.add(&quot;NanJing YuHuaTai&quot;); address.add(&quot;BeiJing LiuLiChang&quot;); address.add(&quot;ShenZhen HongShuLin&quot;); builder.addAllAddress(address); return builder.build(); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println(&quot;Receive server response : [&quot; + msg + &quot;]&quot;); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 测试Protobuf版本的图书订购程序功能服务端运行结果如图3所示. 图3 服务端运行结果 服务端运行结果如图4所示. 图4 服务端运行结果 Protobuf的使用注意事项ProtoBufDecoder仅仅负责解码，它不支持读半包。因此，在ProtobufDecoder前面，一定要有能够处理读半包的解码器，有以下三种方式可以选择。 使用Netty提供的ProtobufVarint32FrameDecoder，可以处理半包消息； 继承Netty的通用半包解码器LengthFieldBasedFrameDecoder; 继承ByteToMessageDecoder类，自己处理半包消息。 如果使用ProtobufDecoder解码器而忽略对半包消息的处理，程序是不能正常工作的。以前面的图书订购为例服务端代码进行修改，注释掉ProtobufVarint32FrameDecoder，代码修改如图5所示。 图5 注释掉ProtobufVarint32FrameDecoder 程序运行，结果如图6所示，运行出错。 图6 注释掉ProtobufVarint32FrameDecoder运行出错 Netty权威指南第二版源代码。]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MessagePack编解码]]></title>
    <url>%2F2015%2F04%2F01%2FMessagePack%E7%BC%96%E8%A7%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[MessagePack是一个高效的二进制序列化框架，它像JSON一样支持不同语言间的数据交互，但是它的性能更快，序列化之后的码流也更小。由于MessagePack在业界得到了非常广泛的应用，将介绍如何利用Netty的CodeC框架新增对MessagePack的支持。 MessagePack介绍MessagePack的特点如下： 编解码高效，性能高； 序列化之后码流小； 支持跨语言。 衡量序列化框架通用性的一个重要指标就是对多语言的支持，因为数据交换的双方很难保证一定采用相同的语言开发，如果序列化框架和某种语言绑定，他就很难跨语言，如Java的序列化机制。MessagePack提供了多种语言支持：Java、Python、Ruby、Haskell、C#、OCaml、Lua、Go、C、C++等。 官网地址：http://msgpack.org/Git地址：https://github.com/msgpack/msgpack-java MessagePack Java API 介绍Maven引用的方式：12345&lt;dependency&gt; &lt;groupId&gt;org.msgpack&lt;/groupId&gt; &lt;artifactId&gt;msgpack&lt;/artifactId&gt; &lt;version&gt;$&#123;msgpack.version&#125;&lt;/version&gt;&lt;/dependency&gt; API官方示例： 代码清单1 官方示例12345678910111213141516171819202122232425262728293031import java.io.IOException;import java.util.ArrayList;import java.util.List;import org.msgpack.MessagePack;import org.msgpack.template.Templates;public class TestMessagePack &#123; public static void main(String[] args) &#123; // Create serialize objects List&lt;String&gt; src=new ArrayList&lt;String&gt;(); src.add(&quot;msgpack&quot;); src.add(&quot;kumofs&quot;); src.add(&quot;viver&quot;); MessagePack msgpack=new MessagePack(); // Serialize byte[] raw; try &#123; raw = msgpack.write(src); // Deserialize directly using a template List&lt;String&gt; dst1 = msgpack.read(raw,Templates.tList(Templates.TString)); System.out.println(dst1.get(0)); System.out.println(dst1.get(1)); System.out.println(dst1.get(2)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; MessagePack编码器和解码器开发MessagePack编码器开发代码清单2 msgpack编码器 MsgpackEncoder123456789public class MsgpackEncoder extends MessageToByteEncoder&lt;Object&gt; &#123; @Override protected void encode(ChannelHandlerContext arg0, Object arg1, ByteBuf arg2) throws Exception &#123; MessagePack msgpack=new MessagePack(); byte[] raw=msgpack.write(arg1); arg2.writeBytes(raw); &#125;&#125; MsgpackEncoder继承MessageToByteEncoder,它负责将Object类型的POJO对象编码为byte数组，然后写入到ByteBuf中。 MessagePack解码器开发代码清单3 msgpack编码器 MsgPackDecoder12345678910111213public class MsgPackDecoder extends MessageToMessageDecoder&lt;ByteBuf&gt; &#123; @Override protected void decode(ChannelHandlerContext arg0, ByteBuf arg1, List&lt;Object&gt; arg2) throws Exception &#123; final byte[] array; final int length=arg1.readableBytes(); array=new byte[length]; arg1.getBytes(arg1.readerIndex(), array,0,length); MessagePack msgpack=new MessagePack(); arg2.add(msgpack.read(array)); &#125;&#125; 首先从数据报arg1中获取需要解码的byte数组，然后调用MessagePack的read方法将其反序列化为Object对象，将解码后的对象加入到解码列表中arg2中，这样就完成了MessagePack的解码操作。 #### 功能测试完成编解码器开发之后，我们以Netty原生Echo程序为例，进行测试。对Echo进行简单改造，传输的对象由字符串修改为POJO对象，利用MessagePack对POJO对象进行序列化。 序列化对象代码清单4 UserInfo1234567891011121314151617@Messagepublic class UserInfo &#123;private int age;private String name;public int getAge() &#123; return age;&#125;public void setAge(int age) &#123; this.age = age;&#125;public String getName() &#123; return name;&#125;public void setName(String name) &#123; this.name = name;&#125;&#125; 客户端代码代码清单5 EchoClient12345678910111213141516171819202122232425262728293031323334353637383940public class EchoClient &#123; private final String host; private final int port; private final int sendNumber; public EchoClient(int port,String host,int sendNumber)&#123; this.host=host; this.port=port; this.sendNumber=sendNumber; &#125; public void run() throws Exception&#123; EventLoopGroup group=new NioEventLoopGroup(); try&#123; Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 3000) .handler(new ChannelInitializer&lt;SocketChannel&gt;()&#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; //LengthFieldBasedFrameDecoder用于处理半包消息 //这样后面的MsgpackDecoder接收的永远是整包消息 ch.pipeline().addLast(&quot;frameDecoder&quot;,new LengthFieldBasedFrameDecoder(65535,0,2,0,2)); ch.pipeline().addLast(&quot;msgpack decoder&quot;,new MsgPackDecoder()); //在ByteBuf之前增加2个字节的消息长度字段 ch.pipeline().addLast(&quot;frameEncoder&quot;,new LengthFieldPrepender(2)); ch.pipeline().addLast(&quot;msgpack encoder&quot;,new MsgpackEncoder()); ch.pipeline().addLast(new EchoClientHandler(sendNumber)); &#125; &#125;); ChannelFuture f= b.connect(host,port).sync(); f.channel().closeFuture().sync(); &#125;finally&#123; group.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception&#123; int port=8080; new EchoClient(port,&quot;127.0.0.1&quot;,1000).run(); 代码清单6 EchoClientHandler12345678910111213141516171819202122232425262728293031323334353637383940414243public class EchoClientHandler extends ChannelHandlerAdapter&#123; private final int sendNumber; private int counter; public EchoClientHandler(int sendNumber)&#123; this.sendNumber=sendNumber; &#125; @Override public void channelActive(ChannelHandlerContext ctx)&#123; UserInfo [] infos = UserInfo(); for(UserInfo infoE : infos)&#123; ctx.write(infoE); &#125; ctx.flush(); &#125; private UserInfo[] UserInfo()&#123; UserInfo [] userInfos=new UserInfo[sendNumber]; UserInfo userInfo=null; for(int i=0; i &lt; sendNumber; i++)&#123; userInfo=new UserInfo(); userInfo.setAge(i); userInfo.setName(&quot;ABCDEFG ---&gt;&quot;+i); userInfos[i]=userInfo; &#125; return userInfos; &#125; @Override public void channelRead(ChannelHandlerContext ctx,Object msg) throws Exception&#123; System.out.println(&quot;Client receive the msgpack message : &quot; + msg); ctx.write(msg); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx)throws Exception&#123; ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx,Throwable cause)&#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 服务端代码代码清单7 EchoServer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class EchoServer &#123; public void bind(int port)throws Exception&#123; //创建服务端的NIO线程组 EventLoopGroup bossGroup=new NioEventLoopGroup(); EventLoopGroup workerGroup=new NioEventLoopGroup(); try &#123; ServerBootstrap b=new ServerBootstrap(); b.group(bossGroup,workerGroup) .channel(NioServerSocketChannel.class).option(ChannelOption.SO_BACKLOG, 100) .childHandler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; // TODO Auto-generated method stub ch.pipeline().addLast(&quot;frameDecoder&quot;,new LengthFieldBasedFrameDecoder(65535,0,2,0,2)); ch.pipeline().addLast(&quot;msgpack decoder&quot;,new MsgPackDecoder()); //在ByteBuf之前增加2个字节的消息长度字段 ch.pipeline().addLast(&quot;frameEncoder&quot;,new LengthFieldPrepender(2)); ch.pipeline().addLast(&quot;msgpack encoder&quot;,new MsgpackEncoder()); ch.pipeline().addLast(new EchoServerHander()); &#125; &#125;); //绑定端口，同步等待成功 ChannelFuture f=b.bind(port).sync(); //等待服务端监听端口关闭 f.channel().closeFuture().sync(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception &#123; // TODO Auto-generated method stub int port=8080; if(args!=null&amp;&amp;args.length&gt;0)&#123; try &#123; port=Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // TODO: handle exception &#125; &#125; new EchoServer().bind(port); &#125;&#125; 代码清单8 EchoServerHandler12345678910111213141516171819@Sharablepublic class EchoServerHander extends ChannelHandlerAdapter &#123; int counter=0; @Override public void channelRead(ChannelHandlerContext ctx,Object msg)throws Exception&#123; System.out.println(&quot;Server receive the msgpack message : &quot; + msg); ctx.write(msg); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 运行结果分析没有进行粘包/半包处理，结果分析不进行处理就是去掉服务端与客户端中如下代码：12ch.pipeline().addLast(&quot;frameDecoder&quot;,new LengthFieldBasedFrameDecoder(65535,0,2,0,2));ch.pipeline().addLast(&quot;frameEncoder&quot;,new LengthFieldPrepender(2)); 客户端运行结果如下。 图1 客户端运行结果 服务端运行结果如下。 图2 服务端运行结果 没有进行粘包/半包的处理，我们开发的MessagePack编解码框架还不能正常工作，如下为粘包场景下测试结果。 图3 粘包场景下测试结果 粘包/半包支持下，运行结果分析在MessagePack编码器之前添加LengthFieldPrepender,它将在ByteBuf之前添加2个字节的消息长度字段，其原理如图1所示。 图4 LengthFieldPrepender原理示意图 在MessagePack解码器之前添加LengthFieldBaseFrameDecoder，用于处理半包消息，这样后面的MsgpackDecoder接收到的永远是整包消息，它的工作原理如图2所示。 图5 LengthFieldBaseFrameDecoder原理示意图 服务端运行结果如下。 图6 服务端运行结果 客户端运行结果如下。 图7 客户端运行结果]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java编解码中使用序列化的缺点]]></title>
    <url>%2F2015%2F03%2F01%2FJava%E7%BC%96%E8%A7%A3%E7%A0%81%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%BA%8F%E5%88%97%E5%8C%96%E7%9A%84%E7%BC%BA%E7%82%B9%2F</url>
    <content type="text"><![CDATA[Java 序列化的主要目的有两个，网络传输和对象持久化。Java序列化从JDK1.1版本就已经提供，它不需要添加额外的类库，只需实现java.io.Serializable并生产系列ID即可，因此，它从诞生之初就得到广泛的应用。但是在远程服务调用（RPC）时，很少直接使用Java序列化进行消息的编解码和传输，这又是什么原因呢？下面通过分析Java序列化的缺点找出答案。 无法跨语言无法跨语言，是Java序列化最致命的问题。对于跨进程的服务调用，服务提供者可能会使用C十＋或者其他语言开发，当我们需要和异构语言进程交互时Java序列化就难以胜任。 由于Java序列化技术是Java语言内部的私有协议，其他语言并不支持，对于用户来说它完全是黑盒。对于Java序列化后的字节数组，别的语言无法进行反序列化，这就严重阻碍了它的应用。事实上，目前几乎所有流行的JavaRCP通信框架，都没有使用Java序列化作为编解码框架，原肉就在于它无法跨语言，而这些RPC框架往往需要支持跨语言调用。 序列化后的码流太大下面我们通过一个实例看下Java序列化后的字节数组大小。代码清单1 Java序列化代码 POJO对象类UserInfo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class UserInfo implements Serializable &#123; private static final long serialVersionUID=1L; private String userName; private int userID; public UserInfo buildUserName(String userName)&#123; this.userName=userName; return this; &#125; public UserInfo buildUserID(int userID)&#123; this.userID=userID; return this; &#125; public final String getUserName() &#123; return userName; &#125; public final void setUserName(String userName) &#123; this.userName = userName; &#125; public final int getUserID() &#123; return userID; &#125; public final void setUserID(int userID) &#123; this.userID = userID; &#125; /* 使用基于ByteBuffer的通用二进制编解码技术对UserInfo对象进行编码， 编码结果仍然是byte数组，可以与传统的JDK序列化后的码流大小进行对比 */ public byte[] codeC()&#123; ByteBuffer buffer=ByteBuffer.allocate(1024); byte[] value=this.userName.getBytes(); buffer.putInt(value.length); buffer.put(value); buffer.putInt(this.userID); buffer.flip(); value=null; byte[] result=new byte[buffer.remaining()]; buffer.get(result); return result; &#125; public byte[] codeC(ByteBuffer buffer)&#123; buffer.clear(); byte[] value=this.userName.getBytes(); buffer.putInt(value.length); buffer.put(value); buffer.putInt(this.userID); buffer.flip(); value=null; byte[] result=new byte[buffer.remaining()]; buffer.get(result); return result; &#125;&#125; Userlnfo对象是个普通的POJO对象，它实现了java.io.SerializabIe接口，并且生成了一个默认的序列号serialVersionUID=lL，这说明UserInfo对象可以通过JDK默认的序列化机制进行序列化和反序列化。下面写一个测试程序，先调用两种编码接口对POJO对象编码，然后分别打印两者编码后的码流大小进行对比。 代码清单2 Java序列化代码 编码测试类 TestUserInfo1234567891011121314151617181920public class TestUserInfo &#123; public static void main(String[] args) throws IOException &#123; // TODO Auto-generated method stub UserInfo info=new UserInfo(); info.buildUserID(100).buildUserName(&quot;Welcome to Netty&quot;); ByteArrayOutputStream bos=new ByteArrayOutputStream(); ObjectOutputStream os=new ObjectOutputStream(bos); os.writeObject(info); os.flush(); os.close(); byte[] b=bos.toByteArray(); System.out.println(&quot;The jdk serializable length is:&quot;+b.length); bos.close(); System.out.println(&quot;---------------------------------------------&quot;); System.out.println(&quot;The byte serializable length is:&quot;+info.codeC().length); &#125;&#125; 测试结果如图1所示。 图1 测试结果 测试结果令人震惊，采用JDK 序列化机制编码后的二迸制数组大小竟然是二进制编码的5.29倍。我们评判一个编解码框架的优劣时，往往会考虑以下几个因素。 是否支持跨语言，支持的语言种类是否丰富； 编码后的码流大小： 编解码的性能； 类库是否小巧，API使用是否方便： 使用者需要手工开发的工作量和难度。 在同等情况下，编码后的字节数组越大，存储的时候就越占空间，存储的硬件成本就越高，并且在网络传输时更占带宽，导致系统的吞吐量降低。Java序列化后的码流偏大也一直被业界所垢病，导致它的应用范围受到了很大限制。 序列化性能太低下面我们从序列化的性能角度看下JDK的表现如何。 创建一个性能测试版本 的 PerformTestUserInfo测试程序 ，代码如下 。 代码清单3 Java序列化代码 编码性能测试类 PerformTestUserInfo12345678910111213141516171819202122232425262728293031323334public class PerformTestUserInfo &#123; public static void main(String[] args) throws IOException &#123; UserInfo info=new UserInfo(); info.buildUserID(100).buildUserName(&quot;Welcome to Netty&quot;); int loop=1000000; ByteArrayOutputStream bos=null; ObjectOutputStream os=null; long startTime=System.currentTimeMillis(); for(int i=0;i&lt;loop;i++)&#123; bos=new ByteArrayOutputStream(); os=new ObjectOutputStream(bos); os.writeObject(info); os.flush(); os.close(); byte[] b=bos.toByteArray(); bos.close(); &#125; long endTime=System.currentTimeMillis(); System.out.println(&quot;The jdk serializable cost time is :&quot;+ (endTime-startTime)+&quot;ms&quot;); System.out.println(&quot;---------------------------------------------&quot;); ByteBuffer buffer=ByteBuffer.allocate(1024); start[](http://)Time=System.currentTimeMillis(); for(int i=0;i&lt;loop;i++)&#123; byte[] b=info.codeC(buffer); &#125; endTime=System.currentTimeMillis(); System.out.println(&quot;The byte array serializable costtime is :&quot;+(endTime-startTime)+&quot;ms&quot;); &#125;&#125; 对Java序列化和二迸制编码分别进行性能测试，编码100万次，然后统计耗费的总时间，测试结果如图2所示。 图2 UserInfo编码性能测试结果 这个结果也非常令人惊讶：Java序列化的性能只有二进制编码的6.17%左右，可见Java原生序列化的性能实在太差。下面我们结合编码速度，综合对比一下Java序列化和二进制编码的性能差异，如图3所示。 图3 序列化性能对比图 从图3可以看出，无论是序列化后的码流大小，还是序列化的性能，JDK默认的序列化机制表现得都很差。因此，我们边常不会选择Java序列化作为远程跨节点调用的编解码框架。但是不使用JDK提供的默认序列化框架，自己开发编解码框架又是个非常复杂的工作，怎么办呢？不用着急，业界有很多优秀的编解码框架，它们在克服了JDK默认序列化框架缺点的基础上，还增加了很多亮点，下面让我们继续了解并学习业界流行的几款编解码框架，如MessagePack编解码、GoogleProtobuf编解码和JBossMarshalling编解码。]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AIO编程示例]]></title>
    <url>%2F2014%2F12%2F11%2FAIO%E7%BC%96%E7%A8%8B%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[NIO 2.0的异步套接字通道是真正的异步非阻塞I/O，对应于UNIX网络编程中的事件驱动I/O（AIO）。它不需要通过多路复用器（Seletor)对注册的通道进行轮询操作即可实现异步读写，从而简化了NIO的编程模型。 NIO 2.0引进了新的异步通道的概念，并提升了异步文件通道和异步套接字通道的实现。异步通道提供了以下两种方式获取操作结果。 通过java.util.concurrent.Future类来表示异步操作的结果。 在执行异步操作的时候传入一个java.nio.channels。 CompletionHandler接口的实现类作为操作完成的回调。 AIO服务端源码分析首先看下时间服务器的主函数 代码清单1 AIO时间服务器服务端 TimeClientHandle 12345678910111213141516171819public class TimeServer &#123; /** * @param args * @throws IOException */ public static void main(String[] args) throws IOException &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; AsyncTimeServerHandler timeServer = new AsyncTimeServerHandler(port); new Thread(timeServer, &quot;AIO-AsyncTimeServerHandler-001&quot;).start(); &#125;&#125; 我们直接从第16行开始看，首先创建异步的时间服务器处理类，然后启动线程将AsyncTimeServerHandler拉起，代码如下：代码清单2 AIO时间服务器服务端123456789101112131415161718192021222324252627282930313233343536373839404142public class AsyncTimeServerHandler implements Runnable &#123; private int port; CountDownLatch latch; AsynchronousServerSocketChannel asynchronousServerSocketChannel; public AsyncTimeServerHandler(int port) &#123; this.port = port; try &#123; asynchronousServerSocketChannel = AsynchronousServerSocketChannel .open(); asynchronousServerSocketChannel.bind(new InetSocketAddress(port)); System.out.println(&quot;The time server is start in port : &quot; + port); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; /* * (non-Javadoc) * * @see java.lang.Runnable#run() */ @Override public void run() &#123; latch = new CountDownLatch(1); doAccept(); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public void doAccept() &#123; asynchronousServerSocketChannel.accept(this, new AcceptCompletionHandler()); &#125;&#125; 服务端通道AsynchronousServerSocketChannel，然后调用它的bind方法绑定监听端口，如果端口合法且没被占用，绑定成功，打印启动成功提示到控制台。在线程的run方法中，第26行我们初始化CountDownLatch对象，它的作用是在完成一组正在执行的操作之前，允许当前的线程一直阻塞。在本例程中，我们让线程在此阻塞，防止服务端执行完成退出。在实际项目应用中，不需要启动独立的线程来处理AsynchronousServerSocketChannel，这里仅仅是个demo演示。第24行用于接收客户端的连接，由于是异步操作，我们可以传递一个CompletionHandler类型的handler实例接收accept操作成功的通知消息，在本例程中我们通过AcceptCompletionHandler实例作为handler接收通知消息，下面，我们继续对AcceptCompletionHandler进行分析：代码清单3 AIO时间服务器服务端AcceptCompletionHandler1234567891011121314151617public class AcceptCompletionHandler implements CompletionHandler&lt;AsynchronousSocketChannel, AsyncTimeServerHandler&gt; &#123; @Override public void completed(AsynchronousSocketChannel result, AsyncTimeServerHandler attachment) &#123; attachment.asynchronousServerSocketChannel.accept(attachment, this); ByteBuffer buffer = ByteBuffer.allocate(1024); result.read(buffer, buffer, new ReadCompletionHandler(result)); &#125; @Override public void failed(Throwable exc, AsyncTimeServerHandler attachment) &#123; exc.printStackTrace(); attachment.latch.countDown(); &#125;&#125; CompletionHandler有两个方法，分别是： 1) public void completed(AsynchronousSocketChannel result, AsyncTimeServerHandler attachment)； 2) public void failed(Throwable exc, AsyncTimeServerHandler attachment)； 下面我们分别对这两个接口的实现进行分析：首先看completed接口的实现，代码7-10行，我们从attachment获取成员变量AsynchronousServerSocketChannel，然后继续调用它的accept方法。可能读者在此可能会心存疑惑，既然已经接收客户端成功了，为什么还要再次调用accept方法呢？原因是这样的：当我们调用AsynchronousServerSocketChannel的accept方法后，如果有新的客户端连接接入，系统将回调我们传入的CompletionHandler实例的completed方法，表示新的客户端已经接入成功，因为一个AsynchronousServerSocketChannel可以接收成千上万个客户端，所以我们需要继续调用它的accept方法，接收其它的客户端连接，最终形成一个循环。每当接收一个客户读连接成功之后，再异步接收新的客户端连接。链路建立成功之后，服务端需要接收客户端的请求消息，代码第8行我们创建新的ByteBuffer，预分配1M的缓冲区。第8行我们通过调用AsynchronousSocketChannel的read方法进行异步读操作。下面我们看看异步read方法的参数： ByteBuffer dst：接收缓冲区，用于从异步Channel中读取数据包； A attachment：异步Channel携带的附件，通知回调的时候作为入参使用； CompletionHandler：接收通知回调的业务handler，本例程中为ReadCompletionHandler。 下面我们继续对ReadCompletionHandler进行分析：代码清单4 AIO时间服务器服务端 ReadCompletionHandler1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class ReadCompletionHandler implements CompletionHandler&lt;Integer, ByteBuffer&gt; &#123; private AsynchronousSocketChannel channel; public ReadCompletionHandler(AsynchronousSocketChannel channel) &#123; if (this.channel == null) this.channel = channel; &#125; @Override public void completed(Integer result, ByteBuffer attachment) &#123; attachment.flip(); byte[] body = new byte[attachment.remaining()]; attachment.get(body); try &#123; String req = new String(body, &quot;UTF-8&quot;); System.out.println(&quot;The time server receive order : &quot; + req); String currentTime = &quot;QUERY TIME ORDER&quot;.equalsIgnoreCase(req) ? new java.util.Date( System.currentTimeMillis()).toString() : &quot;BAD ORDER&quot;; doWrite(currentTime); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; private void doWrite(String currentTime) &#123; if (currentTime != null &amp;&amp; currentTime.trim().length() &gt; 0) &#123; byte[] bytes = (currentTime).getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(bytes.length); writeBuffer.put(bytes); writeBuffer.flip(); channel.write(writeBuffer, writeBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer buffer) &#123; // 如果没有发送完成，继续发送 if (buffer.hasRemaining()) channel.write(buffer, buffer, this); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; // ingnore on close &#125; &#125; &#125;); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; this.channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 首先看构造方法，我们将AsynchronousSocketChannel通过参数传递到ReadCompletionHandler中当作成员变量来使用，主要用于读取半包消息和发送应答。本例程不对半包读写进行具体解说，对此感兴趣的可以关注后续章节对Netty半包处理的专题介绍。我们继续看代码，第12-25行是读取到消息后的处理，首先对attachment进行flip操作，为后续从缓冲区读取数据做准备。根据缓冲区的可读字节数创建byte数组，然后通过new String方法创建请求消息，对请求消息进行判断，如果是”QUERY TIME ORDER”则获取当前系统服务器的时间，调用doWrite方法发送给客户端。下面我们对doWrite方法进行详细分析。 跳到代码第28行，首先对当前时间进行合法性校验，如果合法，调用字符串的解码方法将应答消息编码成字节数组，然后将它拷贝到发送缓冲区writeBuffer中，最后调用AsynchronousSocketChannel的异步write方法。正如前面介绍的异步read方法一样，它也有三个与read方法相同的参数，在本例程中我们直接实现write方法的异步回调接口CompletionHandler，代码跳到第24行，对发送的writeBuffer进行判断，如果还有剩余的字节可写，说明没有发送完成，需要继续发送，直到发送成功。 最后，我们关注下failed方法，它的实现很简单，就是当发生异常的时候，我们对异常Throwable进行判断，如果是IO异常，就关闭链路，释放资源，如果是其它异常，按照业务自己的逻辑进行处理。本例程作为简单demo，没有对异常进行分类判断，只要发生了读写异常，就关闭链路，释放资源。 异步非阻塞IO版本的时间服务器服务端已经介绍完毕，下面我们继续看客户端的实现。 AIO客户端源码分析首先看下客户端主函数的实现。代码清单5 AIO时间服务器客户端 TimeClient12345678910111213141516171819public class TimeClient &#123; /** * @param args */ public static void main(String[] args) &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; new Thread(new AsyncTimeClientHandler(&quot;127.0.0.1&quot;, port), &quot;AIO-AsyncTimeClientHandler-001&quot;).start(); &#125;&#125; 第15行我们通过一个独立的IO线程创建异步时间服务器客户端handler，在实际项目中，我们不需要独立的线程创建异步连接对象，因为底层都是通过JDK的系统回调实现的，在后面运行时间服务器程序的时候，我们会抓取线程调用堆栈给大家展示。继续看代码， AsyncTimeClientHandler的实现类源码如下：代码清单6 AIO时间服务器客户端 AsyncTimeClientHandler123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109public class AsyncTimeClientHandler implements CompletionHandler&lt;Void, AsyncTimeClientHandler&gt;, Runnable &#123; private AsynchronousSocketChannel client; private String host; private int port; private CountDownLatch latch; public AsyncTimeClientHandler(String host, int port) &#123; this.host = host; this.port = port; try &#123; client = AsynchronousSocketChannel.open(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; latch = new CountDownLatch(1); client.connect(new InetSocketAddress(host, port), this, this); try &#123; latch.await(); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; try &#123; client.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void completed(Void result, AsyncTimeClientHandler attachment) &#123; byte[] req = &quot;QUERY TIME ORDER&quot;.getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(req.length); writeBuffer.put(req); writeBuffer.flip(); client.write(writeBuffer, writeBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer buffer) &#123; if (buffer.hasRemaining()) &#123; client.write(buffer, buffer, this); &#125; else &#123; ByteBuffer readBuffer = ByteBuffer.allocate(1024); client.read( readBuffer, readBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer buffer) &#123; buffer.flip(); byte[] bytes = new byte[buffer .remaining()]; buffer.get(bytes); String body; try &#123; body = new String(bytes, &quot;UTF-8&quot;); System.out.println(&quot;Now is : &quot; + body); latch.countDown(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; client.close(); latch.countDown(); &#125; catch (IOException e) &#123; // ingnore on close &#125; &#125; &#125;); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; client.close(); latch.countDown(); &#125; catch (IOException e) &#123; // ingnore on close &#125; &#125; &#125;); &#125; @Override public void failed(Throwable exc, AsyncTimeClientHandler attachment) &#123; exc.printStackTrace(); try &#123; client.close(); latch.countDown(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 由于在AsyncTimeClientHandler中大量使用了内部匿名类，所以代码看起来稍微有些复杂，下面我们就对主要代码进行详细解说。 9-17行是构造方法，首先通过AsynchronousSocketChannel的open方法创建一个新的AsynchronousSocketChannel对象。然后跳到第36行，创建CountDownLatch进行等待，防止异步操作没有执行完成线程就退出。第37行通过connect方法发起异步操作，它有两个参数，分别如下： 1) A attachment : AsynchronousSocketChannel的附件，用于回调通知时作为入参被传递，调用者可以自定义； 2) CompletionHandler handler：异步操作回调通知接口，由调用者实现。 在本例程中，我们的两个参数都使用AsyncTimeClientHandler类本身，因为它实现了CompletionHandler接口。 接下来我们看异步连接成功之后的方法回调completed方法，代码第39行，我们创建请求消息体，对其进行编码，然后拷贝到发送缓冲区writeBuffer中，调用AsynchronousSocketChannel的write方法进行异步写，与服务端类似，我们可以实现CompletionHandler接口用于写操作完成后的回调，代码第45-47行，如果发送缓冲区中仍有尚未发送的字节，我们继续异步发送，如果已经发送完成，则执行异步读取操作。 代码第64-97行是客户端异步读取时间服务器服务端应答消息的处理逻辑，代码第49行我们调用AsynchronousSocketChannel的read方法异步读取服务端的响应消息，由于read操作是异步的，所以我们通过内部匿名类实现CompletionHandler接口，当读取完成被JDK回调时，我们构造应答消息。第56-63行我们从CompletionHandler的ByteBuffer中读取应答消息，然后打印结果。 第197-96行，当读取发生异常时，我们关闭链路，同时调用CountDownLatch的countDown方法让AsyncTimeClientHandler线程执行完毕，客户端退出执行。 需要指出的是，正如之前的NIO例程，我们并没有完整的处理网络的半包读写，当对例程进行功能测试的时候没有问题，但是，如果对代码稍加改造，进行压力或者性能测试，就会发现输出结果存在问题。 由于半包的读写会作为专门的小节在Netty的应用和源码分析章节进行详细讲解，在NIO的入门章节我们就不详细展开介绍，以便读者能够将注意力集中在NIO的入门知识上来。 AIO运行结果执行TimeServer，如图1所示 图1 执行TimeServer结果 执行TimeClient，如图2所示 图2 执行TimeServer结果]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java获得可用的处理器个数]]></title>
    <url>%2F2014%2F12%2F02%2FJava%E8%8E%B7%E5%BE%97%E5%8F%AF%E7%94%A8%E7%9A%84%E5%A4%84%E7%90%86%E5%99%A8%E4%B8%AA%E6%95%B0%2F</url>
    <content type="text"><![CDATA[要获取java虚拟机可用的处理器个数，可以通过Runtime类的availableProcessors()方法得到，即Runtime.getRuntime().availableProcessors()。 获取处理器数Runtime.getRuntime().availableProcessors()并非都能返回你所期望的数值。比如说，在我的双核1-2-1机器上，它返回的是2，这是对的。不过在我的1-4-2机器 上，也就是一个CPU插槽，4核，每个核2个超线程，这样的话会返回8。不过我其实只有4个核，如果代码的瓶颈是在CPU这块的话，我会有7个线程在同时 竞争CPU周期，而不是更合理的4个线程。如果我的瓶颈是在内存这的话，那这个测试我可以获得7倍的性能提升。 不过这还没完！Java Champions上的一个哥们发现了一种情况，他有一台16-4-2的机器 （也就是16个CPU插槽，每个CPU4个核，每核两个超线程，返回的值居然是16！从我的i7 Macbook pro上的结果来看，我觉得应该返回的是1642=128。在这台机器上运行Java 8的话，它只会将通用的FJ池的并发数设置成15。正如 Brian Goetz所指出的，“虚拟机其实不清楚什么是处理器，它只是去请求操作系统返回一个值。同样的，操作系统也不知道怎么回事，它是去问的硬件设备。硬件会告诉它一个值，通常来说是硬件线程数。操作系统相信硬件说的，而虚拟机又相信操作系统说的。” 实现过程要获得Runtime类的实例，需要调用其静态方法getRuntime(),如下例所示 123456789101112131415161718192021222324public class Main &#123; /** * Displays the number of processors available in the Java Virtual Machine */ public void displayAvailableProcessors() &#123; Runtime runtime = Runtime.getRuntime(); int nrOfProcessors = runtime.availableProcessors(); System.out.println(&quot;Number of processors available to the Java Virtual Machine: &quot; + nrOfProcessors); &#125; /** * Starts the program * * @param args the command line arguments */ public static void main(String[] args) &#123; new Main().displayAvailableProcessors(); &#125;&#125;]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty应用入门]]></title>
    <url>%2F2014%2F12%2F01%2FNetty%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[一个简单的NIO服务端程序，如果我们直接使用JDK的NIO类库进行开发，竟然需要经过烦琐的十多步操作才能完成最基本的信息读取和发送，这也是我们要选择Netty等NIO框架的原因了。 Netty服务端开发Netty时间服务器服务端代码清单1 Netty时间服务器服务端 TimeServer1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class TimeServer &#123; public void bind(int port) throws Exception &#123; // 配置服务端的NIO线程组,实际就是他们就是Reactor线程组 //一个用于服务端接受客户端的连接，另外一个用于进行SocketChannel的网络读写 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; //ServerBootstrap用于启动NIO服务端的辅助启动类，降低服务端的开发复杂度 ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) .childHandler(new ChildChannelHandler()); //ChildChannelHandler用于处理I/O事件 // 绑定端口，同步等待成功 ChannelFuture f = b.bind(port).sync(); // 调用相应方法进行阻塞，等待服务端监听端口关闭之后main函数才退出 f.channel().closeFuture().sync(); &#125; finally &#123; // 优雅退出，释放线程池资源 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; private class ChildChannelHandler extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel arg0) throws Exception &#123; arg0.pipeline().addLast(new TimeServerHandler()); &#125; &#125; /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; new TimeServer().bind(port); &#125;&#125; 代码清单2 Netty时间服务器服务端 TimeServerHandler1234567891011121314151617181920212223242526272829303132//继承自ChannelHandlerAdapter用于对网络的读写操作public class TimeServerHandler extends ChannelHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf buf = (ByteBuf) msg; //readableBytes获取缓冲区可读的字节数，根据可读的字节数创建byte数组 byte[] req = new byte[buf.readableBytes()]; //readBytes方法将缓冲区中的字节数组复制到新建的byte数组中 buf.readBytes(req); //通过new String 构造函数获取请求消息 String body = new String(req, &quot;UTF-8&quot;); System.out.println(&quot;The time server receive order : &quot; + body); String currentTime = &quot;QUERY TIME ORDER&quot;.equalsIgnoreCase(body) ? new java.util.Date( System.currentTimeMillis()).toString() : &quot;BAD ORDER&quot;; ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes()); //从性能考虑，为了防止频繁地唤醒Selector进行消息发送，Netty的write方法并不直接将消息写入SocketChannel中，调用write方法只是把待发送的消息放到发送缓冲区数组中，再通过调用flush方法，将发送缓冲区的消息全部写入到SocketChannel中。 ctx.write(resp); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; //flush方法的作用是将消息发送队列中的消息写入到SocketChannel中发送给对方 ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; ctx.close(); &#125;&#125; Netty客户端开发代码清单3 Netty时间服务器客户端 TimeClient123456789101112131415161718192021222324252627282930313233343536373839404142public class TimeClient &#123; public void connect(int port, String host) throws Exception &#123; // 配置客户端NIO线程组 EventLoopGroup group = new NioEventLoopGroup(); try &#123; //客户端辅助启动类Bootstrap，随后进行配置 Bootstrap b = new Bootstrap(); //客户端设置为NioSocketChannel，随后添加Handler b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new TimeClientHandler()); &#125; &#125;); // 发起异步连接操作 ChannelFuture f = b.connect(host, port).sync(); // 当代客户端链路关闭 f.channel().closeFuture().sync(); &#125; finally &#123; // 优雅退出，释放NIO线程组 group.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; new TimeClient().connect(port, &quot;127.0.0.1&quot;); &#125;&#125; 代码清单4 Netty时间服务器客户端 TimeClientHandler1234567891011121314151617181920212223242526272829303132333435363738394041public class TimeClientHandler extends ChannelHandlerAdapter &#123; private static final Logger logger = Logger .getLogger(TimeClientHandler.class.getName()); private final ByteBuf firstMessage; /** * Creates a client-side handler. */ public TimeClientHandler() &#123; byte[] req = &quot;QUERY TIME ORDER&quot;.getBytes(); firstMessage = Unpooled.buffer(req.length); firstMessage.writeBytes(req); &#125; //当客户端和服务端TCP链路建立成功之后，Netty的NIO线程会调用channelActive方法， //发送查询的时间的指令给服务端，调用ChannelHandlerContext的writeAndFlush方法将请求消息发送给服务端。 @Override public void channelActive(ChannelHandlerContext ctx) &#123; ctx.writeAndFlush(firstMessage); &#125; //当服务端返回应答消息时，channelRead方法被调用 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf buf = (ByteBuf) msg; byte[] req = new byte[buf.readableBytes()]; buf.readBytes(req); String body = new String(req, &quot;UTF-8&quot;); System.out.println(&quot;Now is : &quot; + body); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; // 当发生异常时，打印异常日志，释放客户端资源 logger.warning(&quot;Unexpected exception from downstream : &quot; + cause.getMessage()); ctx.close(); &#125;&#125; 运行结果服务端运行结果如图1。 图1 TimeServer运行结果 客户端运行结果如图2。 图2 TimeClient运行结果]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NIO编程示例]]></title>
    <url>%2F2014%2F11%2F11%2FNIO%E7%BC%96%E7%A8%8B%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[通过NIO编程的序列图和源代码分析来熟悉相关的概念。 NIO服务端NIO服务端序列图NIO服务端通信序列图如图1所示。 图1 NIO服务端通信序列图 NIO服务端的主要创建过程打开ServerSocketChannel，用于监听客户端的连接，它是所有客户端连接的父管道 1ServerSocketChannel acceptorSvr=ServerSocketChannel.open(); 绑定监听端口，设置连接为非阻塞模式 12acceptorSvr.configureBlocking(false);acceptorSvr.socket().bind(new InetSocketAddress(port), 1024); 创建Reactor线程，创建多路复用器并启动线程 12Selector selector=Selector.open();New Thread(new ReactorTask()).start(); 将ServerSocketChannel注册到Reactor线程的多路复用器Selector，监听ACCEPT事件 1SelectionKey key=acceptorSvr.register(selector,SelectionKey.OP_ACCEPT,ioHandler); 多路复用器在线程run方法的无限循环体内轮询准备就绪的key 1234567int num=selector.select();Set selectedKeys=selector.selectedKeys();Iterator it=selectedKeys.iterator();while (it.hasNext())&#123; SelectionKey key=(SelectionKey)it.next(); //...deal with I/O event ...&#125; 多路复用器监听到新的客户端接入，处理新的接入请求，完成TCP三次握手，建立物理链路 1SocketChannel channel=svrChannel.accept(); 设置客户端链路为非阻塞模式 123channel.configureBlocking(false);channel.socket.setReuseAddress(true);...... 将新接入的客户端连接注册到Reactor线程的多路复用器上，监听读操作，读取客户端发送的网络消息 1SelectionKey key=socketChannel.register(selector,SelectionKey.OP_READ,ioHandler); 异步读取客户端请求消息到缓冲区 1int readNumber = channel.read(receivedBuffer); 注意：如果发送区TCP缓冲区满，会导致写半包，此时，需要注册监听写操作位，循环写，直到整个包消息写入TCP缓冲区。对于这些内容此次暂不赘述，后续Netty源码分析章节会详细分析Netty的处理策略。 NIO创建的TimeServer源码分析我们将在TimeServer例程中给出完整的NIO创建的时间服务器源码。代码清单1 NIO时间服务器TimeServer12345678910111213141516171819public class TimeServer &#123; /** * @param args * @throws IOException */ public static void main(String[] args) throws IOException &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; MultiplexerTimeServer timeServer = new MultiplexerTimeServer(port); new Thread(timeServer, &quot;NIO-MultiplexerTimeServer-001&quot;).start(); &#125;&#125; 下面对NIO创建的TimeServer进行简单分析。第8~15行设置监听端口。第16~17行创建了一个被称为MultiplexerTimeServer的多路复用器，它是个一个独立的线程，负责轮询多路复用器Seletor,可以处理多个客户端的并发接入。现在我们继续看MultiplexerTimeServer的源码。代码清单2 NIO时间服务器MultiplexerTimeServer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121public class MultiplexerTimeServer implements Runnable &#123; private Selector selector; private ServerSocketChannel servChannel; private volatile boolean stop; /** * 初始化多路复用器、绑定监听端口 * * @param port */ public MultiplexerTimeServer(int port) &#123; try &#123; selector = Selector.open(); servChannel = ServerSocketChannel.open(); servChannel.configureBlocking(false); servChannel.socket().bind(new InetSocketAddress(port), 1024); servChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println(&quot;The time server is start in port : &quot; + port); &#125; catch (IOException e) &#123; e.printStackTrace(); System.exit(1); &#125; &#125; public void stop() &#123; this.stop = true; &#125; /* * (non-Javadoc) * * @see java.lang.Runnable#run() */ @Override public void run() &#123; while (!stop) &#123; try &#123; selector.select(1000); Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; it = selectedKeys.iterator(); SelectionKey key = null; while (it.hasNext()) &#123; key = it.next(); it.remove(); try &#123; handleInput(key); &#125; catch (Exception e) &#123; if (key != null) &#123; key.cancel(); if (key.channel() != null) key.channel().close(); &#125; &#125; &#125; &#125; catch (Throwable t) &#123; t.printStackTrace(); &#125; &#125; // 多路复用器关闭后，所有注册在上面的Channel和Pipe等资源都会被自动去注册并关闭，所以不需要重复释放资源 if (selector != null) try &#123; selector.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private void handleInput(SelectionKey key) throws IOException &#123; if (key.isValid()) &#123; // 处理新接入的请求消息 if (key.isAcceptable()) &#123; // Accept the new connection ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel sc = ssc.accept(); sc.configureBlocking(false); // Add the new connection to the selector sc.register(selector, SelectionKey.OP_READ); &#125; if (key.isReadable()) &#123; // Read the data SocketChannel sc = (SocketChannel) key.channel(); ByteBuffer readBuffer = ByteBuffer.allocate(1024); int readBytes = sc.read(readBuffer); if (readBytes &gt; 0) &#123; readBuffer.flip(); byte[] bytes = new byte[readBuffer.remaining()]; readBuffer.get(bytes); String body = new String(bytes, &quot;UTF-8&quot;); System.out.println(&quot;The time server receive order : &quot; + body); String currentTime = &quot;QUERY TIME ORDER&quot; .equalsIgnoreCase(body) ? new java.util.Date( System.currentTimeMillis()).toString() : &quot;BAD ORDER&quot;; doWrite(sc, currentTime); &#125; else if (readBytes &lt; 0) &#123; // 对端链路关闭 key.cancel(); sc.close(); &#125; else ; // 读到0字节，忽略 &#125; &#125; &#125; private void doWrite(SocketChannel channel, String response) throws IOException &#123; if (response != null &amp;&amp; response.trim().length() &gt; 0) &#123; byte[] bytes = response.getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(bytes.length); writeBuffer.put(bytes); writeBuffer.flip(); channel.write(writeBuffer); &#125; &#125;&#125; 由于这个类相比于传统的Socket编程稍微复杂一些，在此我们进行详细分析，我们从如下几个关键步骤讲解多路复用处理类： (1) 14-26行为构造方法，在构造方法中进行资源初始化，创建多路复用器Selector、ServerSocketChannel，对Channel和TCP参数进行配置，例如将ServerSocketChannel设置为异步非阻塞模式，它的backlog设置为1024。系统资源初始化成功后将ServerSocketChannel注册到Selector，监听SelectionKey.OP_ACCEPT操作位；如果资源初始化失败，例如端口被占用则退出 (2) 39-61行在线程的run方法的while循环体中循环遍历selector，它的休眠时间为1S，无论是否有读写等事件发生，selector每隔1S都被唤醒一次，selector也提供了一个无参的select方法。当有处于就绪状态的Channel时，selector将返回就绪状态的Channel的SelectionKey集合，我们通过对就绪状态的Channel集合进行迭代，就可以进行网络的异步读写操作 (3) 76-83行处理新接入的客户端请求消息，根据SelectionKey的操作位进行判断即可获知网络事件的类型，通过ServerSocketChannel的accept接收客户端的连接请求并创建SocketChannel实例，完成上述操作后，相当于完成了TCP的三次握手，TCP物理链路正式建立。注意，我们需要将新创建的SocketChannel设置为异步非阻塞，同时也可以对其TCP参数进行设置，例如TCP接收和发送缓冲区的大小等，作为入门的例子，例程没有进行额外的参数设置 (4) 84-109行用于读取客户端的请求消息，首先创建一个ByteBuffer，由于我们事先无法得知客户端发送的码流大小，作为例程，我们开辟一个1M的缓冲区。然后调用SocketChannel的read方法读取请求码流，注意，由于我们已经将SocketChannel设置为异步非阻塞模式，因此它的read是非阻塞的。使用返回值进行判断，看读取到的字节数，返回值有三种可能的结果： 返回值大于0：读到了字节，对字节进行编解码； 返回值等于0：没有读取到字节，属于正常场景，忽略； 返回值为-1：链路已经关闭，需要关闭SocketChannel，释放资源。 当读取到码流以后，我们进行解码，首先对readBuffer进行flip操作，它的作用是将缓冲区当前的limit设置为position，position设置为0，用于后续对缓冲区的读取操作。然后根据缓冲区可读的字节个数创建字节数组，调用ByteBuffer的get操作将缓冲区可读的字节数组拷贝到新创建的字节数组中，最后调用字符串的构造函数创建请求消息体并打印。如果请求指令是”QUERY TIME ORDER”则把服务器的当前时间编码后返回给客户端，下面我们看看如果异步发送应答消息给客户端。 (5) 111-119行将应答消息异步发送给客户端，我们看下关键代码，首先将字符串编码成字节数组，根据字节数组的容量创建ByteBuffer，调用ByteBuffer的put操作将字节数组拷贝到缓冲区中，然后对缓冲区进行flip操作，最后调用SocketChannel的write方法将缓冲区中的字节数组发送出去。需要指出的是，由于SocketChannel是异步非阻塞的，它并不保证一次能够把需要发送的字节数组发送完，此时会出现“写半包”问题，我们需要注册写操作，不断轮询Selector将没有发送完的ByteBuffer发送完毕，可以通过ByteBuffer的hasRemain()方法判断消息是否发送完成。此处仅仅是个简单的入门级例程，没有演示如何处理“写半包”场景，后续的章节会有详细说明。 使用NIO创建TimeServer服务器完成之后，我们继续学习如何创建NIO客户端。首先还是通过时序图了解关键步骤和过程，然后结合代码进行详细分析。 NIO客户端NIO服务端序列图NIO客户端端通信序列图如图2所示。 图2 NIO客户端通信序列图 NIO客户端的主要创建过程打开SocketChannel，绑定客户端本地地址（可选，默认系统会随机分配一个可用的本地地址）1SocketChannel clientChannel = SocketChannel.open();  设置SocketChannel为非阻塞模式，同时设置客户端连接的TCP参数1234clientChannel.configureBlocking(false); socket.setReuseAddress(true); socket.setReceiveBufferSize(BUFFER_SIZE); socket.setSendBufferSize(BUFFER_SIZE);  异步连接服务端1boolean connected=clientChannel.connect(new InetSocketAddress(“ip”,port));  判断是否连接成功，如果连接成功，则直接注册读状态位到多路复用器中，如果当前没有连接成功（异步连接，返回false，说明客户端已经发送sync包，服务端没有返回ack包，物理链路还没有建立）12345678if (connected) &#123; clientChannel.register( selector, SelectionKey.OP_READ, ioHandler); &#125; else &#123; clientChannel.register( selector, SelectionKey.OP_CONNECT, ioHandler); &#125;  向Reactor线程的多路复用器注册OP_CONNECT状态位，监听服务端的TCP ACK应答1clientChannel.register( selector, SelectionKey.OP_CONNECT, ioHandler);  创建Reactor线程，创建多路复用器并启动线程12Selector selector = Selector.open(); New Thread(new ReactorTask()).start();  多路复用器在线程run方法的无限循环体内轮询准备就绪的Key1234567int num = selector.select(); Set selectedKeys = selector.selectedKeys(); Iterator it = selectedKeys.iterator(); while (it.hasNext()) &#123; SelectionKey key = (SelectionKey)it.next(); // ... deal with I/O event ... &#125;  接收connect事件进行处理12if (key.isConnectable()) //handlerConnect();  判断连接结果，如果连接成功，注册读事件到多路复用器12if (channel.finishConnect()) registerRead();  注册读事件到多路复用器1clientChannel.register( selector, SelectionKey.OP_READ, ioHandler);  异步读客户端请求消息到缓冲区1int readNumber = channel.read(receivedBuffer);  对ByteBuffer进行编解码，如果有半包消息接收缓冲区Reset，继续读取后续的报文，将解码成功的消息封装成Task，投递到业务线程池中，进行业务逻辑编排123456789101112131415161718192021Object message = null; while(buffer.hasRemain()) &#123; byteBuffer.mark(); Object message = decode(byteBuffer); if (message == null) &#123; byteBuffer.reset(); break; &#125; messageList.add(message ); &#125; if (!byteBuffer.hasRemain()) byteBuffer.clear(); else byteBuffer.compact(); if (messageList != null &amp; !messageList.isEmpty()) &#123; for(Object messageE : messageList) handlerTask(messageE); &#125;  将POJO对象encode成ByteBuffer，调用SocketChannel的异步write接口，将消息异步发送给客户端1socketChannel.write(buffer); 通过序列图和关键代码的解说，相信大家对创建NIO客户端程序已经有了一个初步的了解，下面就跟随着我们的脚步，继续看看如何使用NIO改造之前的时间服务器客户端TimeClient吧。 NIO创建的TimeClient源码分析代码清单3 NIO时间服务器客户端 TimeClient123456789101112131415161718public class TimeClient &#123; /** * @param args */ public static void main(String[] args) &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; try &#123; port = Integer.valueOf(args[0]); &#125; catch (NumberFormatException e) &#123; // 采用默认值 &#125; &#125; new Thread(new TimeClientHandle(&quot;127.0.0.1&quot;, port), &quot;TimeClient-001&quot;) .start(); &#125;&#125; 通过创建TimeClientHandle线程来处理异步连接和读写操作。代码清单4 NIO时间服务器客户端 TimeClientHandle123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119public class TimeClientHandle implements Runnable &#123; private String host; private int port; private Selector selector; private SocketChannel socketChannel; private volatile boolean stop; public TimeClientHandle(String host, int port) &#123; this.host = host == null ? &quot;127.0.0.1&quot; : host; this.port = port; try &#123; selector = Selector.open(); socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); &#125; catch (IOException e) &#123; e.printStackTrace(); System.exit(1); &#125; &#125; /* * (non-Javadoc) * * @see java.lang.Runnable#run() */ @Override public void run() &#123; try &#123; doConnect(); &#125; catch (IOException e) &#123; e.printStackTrace(); System.exit(1); &#125; while (!stop) &#123; try &#123; selector.select(1000); Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; it = selectedKeys.iterator(); SelectionKey key = null; while (it.hasNext()) &#123; key = it.next(); it.remove(); try &#123; handleInput(key); &#125; catch (Exception e) &#123; if (key != null) &#123; key.cancel(); if (key.channel() != null) key.channel().close(); &#125; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); System.exit(1); &#125; &#125; // 多路复用器关闭后，所有注册在上面的Channel和Pipe等资源都会被自动去注册并关闭，所以不需要重复释放资源 if (selector != null) try &#123; selector.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private void handleInput(SelectionKey key) throws IOException &#123; if (key.isValid()) &#123; // 判断是否连接成功 SocketChannel sc = (SocketChannel) key.channel(); if (key.isConnectable()) &#123; if (sc.finishConnect()) &#123; sc.register(selector, SelectionKey.OP_READ); doWrite(sc); &#125; else System.exit(1);// 连接失败，进程退出 &#125; if (key.isReadable()) &#123; ByteBuffer readBuffer = ByteBuffer.allocate(1024); int readBytes = sc.read(readBuffer); if (readBytes &gt; 0) &#123; readBuffer.flip(); byte[] bytes = new byte[readBuffer.remaining()]; readBuffer.get(bytes); String body = new String(bytes, &quot;UTF-8&quot;); System.out.println(&quot;Now is : &quot; + body); this.stop = true; &#125; else if (readBytes &lt; 0) &#123; // 对端链路关闭 key.cancel(); sc.close(); &#125; else ; // 读到0字节，忽略 &#125; &#125; &#125; private void doConnect() throws IOException &#123; // 如果直接连接成功，则注册到多路复用器上，发送请求消息，读应答 if (socketChannel.connect(new InetSocketAddress(host, port))) &#123; socketChannel.register(selector, SelectionKey.OP_READ); doWrite(socketChannel); &#125; else socketChannel.register(selector, SelectionKey.OP_CONNECT); &#125; private void doWrite(SocketChannel sc) throws IOException &#123; byte[] req = &quot;QUERY TIME ORDER&quot;.getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(req.length); writeBuffer.put(req); writeBuffer.flip(); sc.write(writeBuffer); if (!writeBuffer.hasRemaining()) System.out.println(&quot;Send order 2 server succeed.&quot;); &#125;&#125; 与服务端类似，我们通过对关键步骤的源码进行分析和解读，让大家深入了解如何创建NIO客户端以及如何使用NIO的API。 (1) 8-19行构造函数用于初始化NIO的多路复用器和SocketChannel对象，需要注意的是创建SocketChannel之后，需要将其设置为异步非阻塞模式。就像在2.3.3章节中所讲的，我们可以设置SocketChannel的TCP参数，例如接收和发送的TCP缓冲区大小(2) 28-33行用于发送连接请求，作为示例，连接是成功的，所以不需要做重连操作，因此将其放到循环之前。下面我们具体看看doConnect的实现，代码跳到第116-123行，首先对SocketChannel的connect()操作进行判断，如果连接成功，则将SocketChannel注册到多路复用器Selector上，注册SelectionKey.OP_READ，如果没有直接连接成功，说明服务端没有返回TCP握手应答消息，这并不代表连接失败，我们需要将SocketChannel注册到多路复用器Selector上，注册SelectionKey.OP_CONNECT，当服务端返回TCP syn-ack消息后，Selector就能够轮询到这个SocketChannel处于连接就绪状态(3) 34-67行在循环体中轮询多路复用器Selector，当有就绪的Channel时，执行第59行的handleInput(key)方法，下面我们就对handleInput方法进行分析。 (4) 跳到第68行，我们首先对SelectionKey进行判断，看它处于什么状态。如果是处于连接状态，说明服务端已经返回ACK应答消息，我们需要对连接结果进行判断，调用SocketChannel的finishConnect()方法，如果返回值为true，说明客户端连接成功，如果返回值为false或者直接抛出IOException,说明连接失败。在本例程中，返回值为true，说明连接成功。将SocketChannel注册到多路复用器上，注册SelectionKey.OP_READ操作位，监听网络读操作。然后发送请求消息给服务端，下面我们对doWrite(sc)进行分析。代码跳到110行，我们构造请求消息体，然后对其编码，写入到发送缓冲区中，最后调用SocketChannel的write方法进行发送，由于发送是异步的，所以会存在“半包写”问题，此处不再赘述。最后通过hasRemaining()方法对发送结果进行判断，如果缓冲区中的消息全部发送完成，打印”Send order 2 server succeed. (5) 代码返回第80行，我们继续分析下客户端是如何读取时间服务器应答消息的。如果客户端接收到了服务端的应答消息，则SocketChannel是可读的，由于无法事先判断应答码流的大小，我们就预分配1M的接收缓冲区用于读取应答消息，调用SocketChannel的read()方法进行异步读取操作，由于是异步操作，所以必须对读取的结果进行判断，这部分的处理逻辑已经在2.3.3章节详细介绍过，此处不再赘述。如果读取到了消息，则对消息进行解码，最后打印结果。执行完成后将stop置为true，线程退出循环(6) 线程退出循环后，我们需要对连接资源进行释放，以实现“优雅退出”。60-66行用于多路复用器的资源释放，由于多路复用器上可能注册成千上万的Channel或者pipe，如果一一对这些资源进行释放显然不合适。因此，JDK底层会自动释放所有跟此多路复用器关联的资源，JDK的API DOC如下： 图3 多路复用器Selector的资源释放 到此为止，我们已经将时间服务器通过NIO完成了改造，并对源码进行了分析和解读。 运行结果下面分别执行时间服务器的服务端和客户端，看执行结果。 服务端执行结果： 图4 NIO时间服务器客户端执行结果 客户端执行结果： 图5 NIO时间服务器客户端执行结果 通过源码对比分析，我们发现NIO编程难度确实比同步阻塞BIO大很多，我们的NIO例程并没有考虑“半包读”和“半包写”，如果加上这些，代码将会更加复杂。NIO代码既然这么复杂，为什么它的应用却越来越广泛呢，使用NIO编程的优点总结如下： 1) 客户端发起的连接操作是异步的，可以通过在多路复用器注册OP_CONNECT等待后续结果，不需要像之前的客户端那样被同步阻塞； 2) SocketChannel的读写操作都是异步的，如果没有可读写的数据它不会同步等待，直接返回，这样IO通信线程就可以处理其它的链路，不需要同步等待这个链路可用； 3) 线程模型的优化：由于JDK的Selector在Linux等主流操作系统上通过epoll实现，它没有连接句柄数的限制（只受限于操作系统的最大句柄数或者对单个进程的句柄限制），这意味着一个Selector线程可以同时处理成千上万个客户端连接，而且性能不会随着客户端的增加而线性下降，因此，它非常适合做高性能、高负载的网络服务器。 JDK1.7升级了NIO类库，升级后的NIO类库被称为NIO2.0，引人注目的是Java正式提供了异步文件IO操作，同时提供了与Unix网络编程事件驱动IO对应的AIO，下面的2.4章节我们学习下如何利用NIO2.0编写AIO程序，我们还是以时间服务器为例进行讲解。]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Selector全面深入理解]]></title>
    <url>%2F2014%2F11%2F11%2FSelector%E5%85%A8%E9%9D%A2%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[最近在学习java NIO，发现java nio selector 相对 channel ,buffer 这两个概念是比较难理解的 ,把学习理解的东西以文字的东西记录下来，就像从内存落地到硬盘，把内存中内容换成该知识点的索引。 在介绍Selector之前先明确以下的问题：1、selector的作用是什么？2、selector如何做到网络通信的？下面就针对上面的2个问题来展开介绍： Selector（选择器）是Java NIO中能够检测一到多个NIO渠道，并能够知晓渠道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。 selector 操作的过程首先创建Selector1Selector selector = Selector.open(); 向selector注册channel,和感兴趣的事件，12channel.configureBlocking(false);SelectionKey key = channel.register(selector,Selectionkey.OP_READ); 注意register()方法的第二个参数， 这是一个interest集合，意思是在通过Selector监听Channel时对什么事件感兴趣。可以监听以下4中不同类型的事件： 服务端接收客户端连接事件 SelectionKey.OP_ACCEPT 客户端连接服务端事件 SelectionKey.OP_CONNECT 读事件 SelectionKey.OP_READ 写事件 SelectionKey.OP_WRITE 如果你对不止一种事件感兴趣，那么可以用“位或”操作符将常量连接起来如下：1SelectionKey key = channel.register(selector,Selectionkey.OP_READ|SelectionKey.OP_WRITE); 当向Selector注册Channel时，registor()方法会返回一个SelectorKey对象。这个对象包含了一些你感兴趣的属性。 interest集合ready集合ChannelSelector附加的对象(可选) interest集合就像向Selector注册通道一节中所描述的，interest集合是你所选择的感兴趣的事件集合。可以通过SelectionKey读写interest集合，像这样:12345int interestSet = selectionKey.interestOps();boolean isInterestedInAccept = interestSet &amp; SelectionKey.OP_ACCEPT; boolean isInterestedInConnect = interestSet &amp; SelectionKey.OP_CONNECT; boolean isInterestedInRead = interestSet &amp; SelectionKey.OP_READ; boolean isInterestedInWrite = interestSet &amp; SelectionKey.OP_WRITE; 可以看到，用“位与”操作interest 集合和给定的SelectionKey常量，可以确定某个确定的事件是否在interest集合中。 ready集合ready 集合是通道已经准备就绪的操作的集合。在一次选择(Selection)之后，你会首先访问这个ready set。Selection将在下一小节进行解释。可以这样访问ready集合：1int readySet = selectionKey.readyOps(); 可以用像检测interest集合那样的方法，来检测channel中什么事件或操作已经就绪。但是，也可以使用以下四个方法，它们都会返回一个布尔类型：1234selectionKey.isAcceptable(); selectionKey.isConnectable(); selectionKey.isReadable(); selectionKey.isWritable(); Channel + Selector从SelectionKey访问Channel和Selector很简单。如下：12Channel channel = selectionKey.channel(); Selector selector = selectionKey.selector(); 附加对象 可以将一个对象或者更多信息附着到SelectionKey上，这样就能方便的识别某个给定的通道。例如，可以附加 与通道一起使用的Buffer，或是包含聚集数据的某个对象。使用方法如下：selectionKey.attach(theObject); Object attachedObj = selectionKey.attachment();还可以在用register()方法向Selector注册Channel的时候附加对象。如：SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 通过Selector选择通道一旦向Selector注册了一或多个通道，就可以调用几个重载的select()方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道。换句话说，如果你对“读就绪”的通道感兴趣，select()方法会返回读事件已经就绪的那些通道。 下面是select()方法：（该方法是阻塞方法）int select()int select(long timeout)int selectNow()select()阻塞到至少有一个通道在你注册的事件上就绪了。select(long timeout)和select()一样，除了最长会阻塞timeout毫秒(参数)。selectNow()不会阻塞，不管什么通道就绪都立刻返回（译者注：此方法执行非阻塞的选择操作。如果自从前一次选择操作后，没有通道变成可选择的，则此方法直接返回零。）。select()方法返回的int值表示有多少通道已经就绪。亦即，自上次调用select()方法后有多少通道变成就绪状态。如果调用select()方法，因为有一个通道变成就绪状态，返回了1，若再次调用select()方法，如果另一个通道就绪了，它会再次返回1。如果对第一个就绪的channel没有做任何操作，现在就有两个就绪的通道，但在每次select()方法调用之间，只有一个通道就绪了。 selectedKeys()一旦调用了select()方法，并且返回值表明有一个或更多个通道就绪了，然后可以通过调用selector的selectedKeys()方法，访问“已选择键集（selected key set）”中的就绪通道。如下所示：1Set selectedKeys = selector.selectedKeys(); 当像Selector注册Channel时，Channel.register()方法会返回一个SelectionKey 对象。这个对象代表了注册到该Selector的通道。可以通过SelectionKey的selectedKeySet()方法访问这些对象。可以遍历这个已选择的键集合来访问就绪的通道。如下：12345678910111213141516Set selectedKeys = selector.selectedKeys(); Iterator keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) &#123; electionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove(); &#125; 这个循环遍历已选择键集中的每个键，并检测各个键所对应的通道的就绪事件。注意每次迭代末尾的keyIterator.remove()调用。Selector不会自己从已选择键集中移除SelectionKey实例。必须在处理完通道时自己移除。下次该通道变成就绪时，Selector会再次将其放入已选择键集中。 SelectionKey.channel()方法返回的通道需要转型成你要处理的类型，如ServerSocketChannel或SocketChannel等。 wakeUp()某个线程调用select()方法后阻塞了，即使没有通道已经就绪，也有办法让其从select()方法返回。只要让其它线程在第一个线程调用select()方法的那个对象上调用Selector.wakeup()方法即可。阻塞在select()方法上的线程会立马返回。如果有其它线程调用了wakeup()方法，但当前没有线程阻塞在select()方法上，下个调用select()方法的线程会立即“醒来（wake up）”。 close()用完Selector后调用其close()方法会关闭该Selector，且使注册到该Selector上的所有SelectionKey实例无效。通道本身并不会关闭。 转载于 http://blog.csdn.net/lw305080/article/details/51205545]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通道Channel]]></title>
    <url>%2F2014%2F10%2F11%2F%E9%80%9A%E9%81%93Channel%2F</url>
    <content type="text"><![CDATA[Channel 是一个对象，可以通过它读取和写入数据。 Channel概述Channel就是一个通道，它就像自来水管一样，网络数据通过Channel读取和写入。通道与流的不同之处在于通道是双向的，流只是一个方向上移动（一个流必须是InputStream或者OutPutStream的子类），而通道可以用于读、写或者二者同时进行。因为Channel是双向工的，所以它可以比流更好地映射底层操作系统的API。特别是UNIX网络编程模型中，底层操作系统的通道都是全双工的，同时支持读写操作。 Channel的类继承关系Channel的类图继承关系如图1所示。 图1 Channel的类图继承关系 自顶向下看，前三层主要是Channel接口，用于定义它的功能，后面是一些具体的功能类（抽象类）。从类图可以看出，实际上Channel可以分为两大类：用于网络读写SelectableChannel和用于文件操作的FileChannel。ServerSocketChannel和SocketChannel都是SelectableChannel的子类。 Channel的方法通道可处于打开或关闭状态。创建通道时它处于打开状态，一旦将其关闭，则保持关闭状态。一旦关闭了某个通道，试图对其调用 I/O 操作就会导致 ClosedChannelException 被抛出。通过调用通道的 isOpen 方法可测试通道是否处于打开状态。 方法 描述 void close() 关闭此通道。 boolean isOpen() 判断此通道是否处于打开状态。]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ByteBuf工作原理]]></title>
    <url>%2F2014%2F10%2F11%2FByteBuf%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[ByteBuf依然是个Byte数组的缓冲区，它的基本功能与JDK的ByteBuffer一致。 功能分析ByteBuffer完全可以满足NIO编程的需要，但是由于NIO编程的复杂性，ByteBuffer也有其局限性，它的主要缺点如下。 ByteBuffer长度固定，一旦分配完成，它的容量不能动态扩展和收缩，当需要编码的POJO对象大于ByteBuffer的容量时，会发生索引越界异常； ByteBuffer只有一个标识位置的指针position，读写的时候需要手工调用flip()和rewind()等，使用者必须小心谨慎地处理这些API，否则很容易导致程序处理失败； ByteBuffer的API功能有限，一些高级和实用的特性它不支持，需要使用者自己编程实现。 为弥补这些不足，Netty提供了自己的ByteBuffer实现——ByteBuf。ByteBuf依然是个Byte数组的缓冲区，它的基本功能应该与JDK的ByteBuffer一致，提供以下几类基本功能： 7种Java基础类型、byte数组、ByteBuffer等的读写； 缓冲区自身的copy和slice等； 设置网络字节序； 构造缓冲区实例； 操作位置指针等方法。 由于JDK的ByteBuffer已经提供了这些基础能力的实现，因此，Netty ByteBuf的实现可以有两种策略。 参考JDK ByteBuffer的实现，增加额外的功能，解决原ByteBuffer的缺点。 聚合JDK ByteBuffer，通过Facade模式对其进行包装，可以减少自身的代码量，减低实现的成本。 缓冲区工作过程JDK ByteBuffer由于只有一个位置指针用于处理读写操作，因此每次进行读写的时候都需要额外调用filp()和clear()等方法，否则功能将出错，他的典型用法如下。 1234567ByteBuffer buffer=ByteBuffer.allocate(88);String value =&quot;Netty 权威指南&quot;;buffer.put(value.getByte());buffer.filp();byte[] vArray=new byte[buffer.remaining];buffer.get(vArray);String decodeValue=new String(vArray); 我们看下调用filp()操作前后的对比。 图1 ByteBuffer filp()操作之前 如图2 所示，如果不做filp操作，读取到的将是position到capacity之间的错误内容。当执行filp()操作之后，他的limit被设置为position,position设置为0，capacity不变。由于读取的内容是从position到limit之间，因此，他能够正确地读到之前写入缓冲区的内容。如图3所示 图2 ByteBuffer filp()操作之后 ByteBuf通过两个位置指针来协助缓冲区的读写操作，读操作使用readerIndex，写操作使用writeIndex。 readerIndex和writeIndex的取值一开始都是0，随着数据的写入writeIndex会增加，读取数据会使readIndex增加，但是它不会超过writeIndex。在读取之后，0~readerIndex被视为discard的，调用discardReadBytes方法，可以释放这部分空间，它的作用类似ByteBuffer的compact方法。ReaderIndex与writeIndex之间的数据是可读取的，等价于ByteBuffer position 和limit之间的数据。writeIndex与capacity之间的空间是可写的，等价于ByteBuffer limit和capacity之间的可用空间**。由于写操作不修改readerIndex指针，读操作不修改writeIndex指针，因此读写之间不再需要调整位置指针，这极大低简化了缓冲区的读写操作，避免了由于遗漏或者，不熟悉filp()操作导致的功能异常。初始分配的ByteBuf如图4所示。 图3 初始分配的ByteBuf 写入N个字节之后ByteBuf如图5所示。 图4 写入N个字节后的ByteBuf 读取M(&lt; N)个字节之后的ByteBuf如图6所示。 图5 读取M个字节后的ByteBuf 调用disacardReadBytes操作之后的ByteBuf如图7所示。 图6 discardReadByte操作之后的ByteBuf 调用clear操作之后的ByteBuf如图8所示。 图7 clear操作之后的ByteBuf]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Buffer缓冲区]]></title>
    <url>%2F2014%2F09%2F11%2FBuffer%E7%BC%93%E5%86%B2%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[Buffer是一个对象，它包含一些要写入或者要读出的数据。在NIO类库中加入Buffer对象，体现了新库与原I/O的一个重要区别。在面向流的I/O中，可以将数据直接写入或者将数据直接读到Stream对象中。 Buffer缓冲区类型在NIO库中，所有数据都是用缓冲区处理的。在读写数据时，它是直接读到缓冲区中的。缓冲区实质就是一个数组，通常它是一个字节数组（ByteBuffer）,但是也有其他种类数组，类型及继承关系如图1所示。缓冲区还提供了对数据的结构化访问以及维护读写位置（limit）等信息。 图1 缓冲区类型及继承关系 事实上，对于每个非 boolean 基本类型，此类都有一个子类与之对应，每一个Buffer类都是Buffer接口的一个子实例。除了ByteBuffer，每个Buffer类都有完全一样的操作。大多数标准I/O操作都使用ByteBuffer，所以它在具有一般缓冲区的操作之外还提供了一些特有的操作，以方便网络读写。 Buffer的功能一个用于特定基本类型数据的容器。 缓冲区是特定基本类型元素的线性有限序列。除内容外，缓冲区的基本属性还包括容量、限制和位置： 缓冲区的容量capacity 是它所包含的元素的数量。缓冲区的容量不能为负并且不能更改。 缓冲区的限制limit 是第一个不应该读取或写入的元素的索引。缓冲区的限制不能为负，并且不能大于其容量。 缓冲区的位置position 是下一个要读取或写入的元素的索引。缓冲区的位置不能为负，并且不能大于其限制。 传输数据此类的每个子类都定义了两种获取和放置操作： 相对 操作读取或写入一个或多个元素，它从当前位置开始，然后将位置增加所传输的元素数。如果请求的传输超出限制，则相对获取 操作将抛出 BufferUnderflowException，相对放置 操作将抛出 BufferOverflowException；这两种情况下，都没有数据被传输。 绝对 操作采用显式元素索引，该操作不影响位置。如果索引参数超出限制，绝对获取 操作和放置 操作将抛出 IndexOutOfBoundsException。 当然，通过适当通道的 I/O 操作（通常与当前位置有关）也可以将数据传输到缓冲区或从缓冲区传出数据。 做标记和重置缓冲区的标记 是一个索引，在调用 reset 方法时会将缓冲区的位置重置为该索引。并非总是需要定义标记，但在定义标记时，不能将其定义为负数，并且不能让它大于位置。如果定义了标记，则在将位置或限制调整为小于该标记的值时，该标记将被丢弃。如果未定义标记，那么调用 reset 方法将导致抛出 InvalidMarkException。 不变式标记、位置、限制和容量值遵守以下不变式： 0 &lt;= 标记 &lt;= 位置 &lt;= 限制 &lt;= 容量新创建的缓冲区总有一个 0 位置和一个未定义的标记。初始限制可以为 0，也可以为其他值，这取决于缓冲区类型及其构建方式。一般情况下，缓冲区的初始内容是未定义的。 清除、反转和重绕除了访问位置、限制、容量值的方法以及做标记和重置的方法外，此类还定义了以下可对缓冲区进行的操作： clear() 使缓冲区为一系列新的通道读取或相对放置 操作做好准备：它将限制设置为容量大小，将位置设置为 0。 flip() 使缓冲区为一系列新的通道写入或相对获取 操作做好准备：它将限制设置为当前位置，然后将位置设置为 0。 rewind() 使缓冲区为重新读取已包含的数据做好准备：它使限制保持不变，将位置设置为 0。 只读缓冲区每个缓冲区都是可读取的，但并非每个缓冲区都是可写入的。每个缓冲区类的转变方法都被指定为可选操作，当对只读缓冲区调用时，将抛出 ReadOnlyBufferException。只读缓冲区不允许更改其内容，但其标记、位置和限制值是可变的。可以调用其 isReadOnly 方法确定缓冲区是否为只读。 线程安全多个当前线程使用缓冲区是不安全的。如果一个缓冲区由不止一个线程使用，则应该通过适当的同步来控制对该缓冲区的访问。 调用链指定此类中的方法返回调用它们的缓冲区（否则它们不会返回任何值）。此操作允许将方法调用组成一个链；例如，语句序列 b.flip(); b.position(23); b.limit(42); 可以由以下更紧凑的一个语句代替 b.flip().position(23).limit(42); 方法摘要 类型 方法 描述 abstract Object array() 返回此缓冲区的底层实现数组（可选操作）。 abstract int arrayOffset() 返回此缓冲区的底层实现数组中第一个缓冲区元素的偏移量（可选操作）。 int capacity() 返回此缓冲区的容量。 Buffer clear() 清除此缓冲区。 Buffer flip() 反转此缓冲区。 abstract boolean hasArray() 告知此缓冲区是否具有可访问的底层实现数组。 boolean hasRemaining() 告知在当前位置和限制之间是否有元素。 abstract boolean isDirect() 告知此缓冲区是否为直接缓冲区。 abstract boolean isReadOnly() 告知此缓冲区是否为只读缓冲区。 int limit() 返回此缓冲区的限制。 Buffer limit(int newLimit) 设置此缓冲区的限制。 Buffer mark() 在此缓冲区的位置设置标记。 int position() 返回此缓冲区的位置。 Buffer position(int newPosition) 设置此缓冲区的位置。 int remaining() 返回当前位置与限制之间的元素数。 Buffer reset() 将此缓冲区的位置重置为以前标记的位置。 Buffer rewind() 重绕此缓冲区。 缓冲区操作细节开辟缓冲区 图2 开辟缓冲区 向缓冲区中增加一个数据 图3 向缓冲区中增加一个数据 向缓冲区中增加一组数据 图4 向缓冲区中增加一组数据 执行flip()方法，limit设置为position，position设置为0 图5 执行flip()方法]]></content>
      <categories>
        <category>Netty:The Definitive Guide</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
</search>
